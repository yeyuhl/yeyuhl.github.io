<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>SimpleDB | 随便写写</title><meta name="author" content="夜语"><meta name="copyright" content="夜语"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="SimpleDB基于Java 1.8开发，本质上是CS186 Projects的实验，README将结合MySQL相关知识。注意，需要安装JavaCC，来对输入的SQL语句进行语法分析。此外，由于一些bug，在proj4和proj5实现后的数据库中，delete和update会出现promote锁失败的情况，但是在测试中是正常通过的。一些测试语句如下： 123456create index on">
<meta property="og:type" content="article">
<meta property="og:title" content="SimpleDB">
<meta property="og:url" content="https://yeyuhl.github.io/2023/09/13/SimpleDB/index.html">
<meta property="og:site_name" content="随便写写">
<meta property="og:description" content="SimpleDB基于Java 1.8开发，本质上是CS186 Projects的实验，README将结合MySQL相关知识。注意，需要安装JavaCC，来对输入的SQL语句进行语法分析。此外，由于一些bug，在proj4和proj5实现后的数据库中，delete和update会出现promote锁失败的情况，但是在测试中是正常通过的。一些测试语句如下： 123456create index on">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/1a14e4eeedd428147c921881097b3aed8a932201.jpg%40942w_942h_progressive.webp">
<meta property="article:published_time" content="2023-09-13T08:16:35.000Z">
<meta property="article:modified_time" content="2023-09-13T08:17:47.281Z">
<meta property="article:author" content="夜语">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/1a14e4eeedd428147c921881097b3aed8a932201.jpg%40942w_942h_progressive.webp"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://yeyuhl.github.io/2023/09/13/SimpleDB/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'SimpleDB',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-09-13 16:17:47'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/1a14e4eeedd428147c921881097b3aed8a932201.jpg%40942w_942h_progressive.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/wallhaven-p9woe3.png')"><nav id="nav"><span id="blog-info"><a href="/" title="随便写写"><span class="site-name">随便写写</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">SimpleDB</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-09-13T08:16:35.000Z" title="发表于 2023-09-13 16:16:35">2023-09-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-09-13T08:17:47.281Z" title="更新于 2023-09-13 16:17:47">2023-09-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%A1%B9%E7%9B%AE/">项目</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="SimpleDB"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>SimpleDB基于Java 1.8开发，本质上是<a target="_blank" rel="noopener" href="https://cs186.gitbook.io/project/">CS186 Projects</a>的实验，README将结合MySQL相关知识。注意，需要安装JavaCC，来对输入的SQL语句进行语法分析。此外，由于一些bug，在proj4和proj5实现后的数据库中，delete和update会出现promote锁失败的情况，但是在测试中是正常通过的。一些测试语句如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> index <span class="keyword">on</span> courses (cid);</span><br><span class="line"><span class="keyword">drop</span> index courses (cid);</span><br><span class="line"><span class="keyword">select</span> students.name <span class="keyword">from</span> students <span class="keyword">join</span> enrollments <span class="keyword">on</span> enrollments.sid <span class="operator">=</span> students.sid <span class="keyword">join</span> courses <span class="keyword">on</span> courses.cid <span class="operator">=</span> enrollments.cid <span class="keyword">where</span> courses.name <span class="operator">=</span> <span class="string">&#x27;CS 186&#x27;</span>;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses <span class="keyword">values</span> (<span class="number">16</span>, <span class="string">&#x27;CS 188&#x27;</span>, <span class="string">&#x27;Computer Science&#x27;</span>);</span><br><span class="line"><span class="keyword">update</span> courses <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;CS 189&#x27;</span> <span class="keyword">where</span> cid <span class="operator">=</span> <span class="number">16</span>;</span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> courses <span class="keyword">where</span> cid <span class="operator">=</span> <span class="number">16</span>;</span><br></pre></td></tr></table></figure>
</blockquote>
<h1 id="MySQL存储相关"><a href="#MySQL存储相关" class="headerlink" title="MySQL存储相关"></a>MySQL存储相关</h1><h3 id="数据存放"><a href="#数据存放" class="headerlink" title="数据存放"></a>数据存放</h3><p>这里讨论的是InnoDB存储引擎如何存放文件。每当我们创建一个 database（数据库） 都会在 &#x2F;var&#x2F;lib&#x2F;mysql&#x2F; 目录里面创建一个以 database 为名的目录，然后保存表结构和表数据的文件都会存放在这个目录里。比如，创建名为 my_test 的 database，该 database 里有一张名为 t_order 数据库表。进入 &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;my_test 目录可以看到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">db.opt  </span><br><span class="line">t_order.frm  </span><br><span class="line">t_order.ibd</span><br></pre></td></tr></table></figure>

<p>可以看到，共有三个文件，这三个文件分别代表着：</p>
<ul>
<li>db.opt，用来存储当前数据库的默认字符集和字符校验规则。</li>
<li>t_order.frm ，t_order 的<strong>表结构</strong>会保存在这个文件。在 MySQL 中建立一张表都会生成一个.frm 文件，该文件是用来保存每个表的元数据信息的，主要包含表结构定义。</li>
<li>t_order.ibd，t_order 的<strong>表数据</strong>会保存在这个文件。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.ibd）。这个行为是由参数 innodb_file_per_table 控制的，若设置了参数 innodb_file_per_table 为 1，则会将存储的数据、索引等信息单独存储在一个独占表空间，从 MySQL 5.6.6 版本开始，它的默认值就是 1 了，因此从这个版本之后， MySQL 中每一张表的数据都存放在一个独立的 .ibd 文件。</li>
</ul>
<p>好了，现在我们知道了一张数据库表的数据是保存在「 表名字.ibd 」的文件里的，这个文件也称为独占表空间文件。</p>
<h3 id="表空间文件结构组成"><a href="#表空间文件结构组成" class="headerlink" title="表空间文件结构组成"></a>表空间文件结构组成</h3><p><strong>表空间由段（segment）、区（extent）、页（page）、行（row）组成</strong>，InnoDB存储引擎的逻辑存储结构大致如下图：<img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904100343.png"></p>
<ul>
<li><p><strong>行（row）</strong>：数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式：</p>
<ul>
<li><p>Redundant 是很古老的行格式了， MySQL 5.0 版本之前用的行格式，现在基本没人用了。</p>
</li>
<li><p>由于 Redundant 不是一种紧凑的行格式，所以 MySQL 5.0 之后引入了 Compact 行记录存储方式，Compact 是一种紧凑的行格式，设计的初衷就是为了让一个数据页中可以存放更多的行记录，从 MySQL 5.1 版本之后，行格式默认设置成 Compact。</p>
</li>
<li><p>Dynamic 和 Compressed 两个都是紧凑的行格式，它们的行格式都和 Compact 差不多，因为都是基于 Compact 改进一点东西。从 MySQL5.7 版本之后，默认使用 Dynamic 行格式。</p>
</li>
</ul>
</li>
</ul>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904102443.png"></p>
<ul>
<li><p><strong>页（page）</strong>：记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I&#x2F;O 操作）只能处理一行数据，效率会非常低。因此，<strong>InnoDB 的数据是按「页」为单位来读写的</strong>，也就是说，当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存。<strong>默认每个页的大小为 16KB</strong>，也就是最多能保证 16KB 的连续存储空间。</p>
<p>页是 InnoDB 存储引擎磁盘管理的最小单元，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。页的类型有很多，常见的有数据页、undo 日志页、溢出页等等。数据表中的行记录是用「数据页」来管理的，数据页的结构这里此处不再细说了，总之知道表中的记录存储在「数据页」里面就行。</p>
</li>
<li><p><strong>区（extent）</strong>：我们知道 InnoDB 存储引擎是用 B+ 树来组织数据的。B+ 树中每一层都是通过双向链表连接起来的，如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，可能离得非常远，那么磁盘查询时就会有大量的随机I&#x2F;O，随机 I&#x2F;O 是非常慢的。</p>
<p>解决这个问题也很简单，就是让链表中相邻的页的物理位置也相邻，这样就可以使用顺序 I&#x2F;O 了，那么在范围查询（扫描叶子节点）的时候性能就会很高。那具体怎么解决呢？<strong>在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I&#x2F;O 了</strong>。</p>
</li>
<li><p><strong>段（segment）</strong>：表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。</p>
<ul>
<li><p>索引段：存放 B + 树的非叶子节点的区的集合；</p>
</li>
<li><p>数据段：存放 B + 树的叶子节点的区的集合；</p>
</li>
<li><p>回滚段：存放的是回滚数据的区的集合， MVCC 就是利用了回滚段实现了多版本查询数据。</p>
</li>
</ul>
</li>
</ul>
<h2 id="B-树与数据页"><a href="#B-树与数据页" class="headerlink" title="B+树与数据页"></a>B+树与数据页</h2><p>数据库的 I&#x2F;O 操作的最小单位是页，<strong>InnoDB 数据页的默认大小是 16KB</strong>，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904103846.png"></p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904103902.png"></p>
<p>在 File Header 中有两个指针，分别指向上一个数据页和下一个数据页，连接起来的页相当于一个双向的链表，如下图所示：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904103921.png"></p>
<p>采用链表的结构是让数据页之间不需要是物理上的连续的，而是逻辑上的连续。</p>
<p>数据页的主要作用是存储记录，也就是数据库的数据，所以重点说一下数据页中的 User Records 是怎么组织数据的。<strong>数据页中的记录按照「主键」顺序组成单向链表</strong>，单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索。</p>
<p>因此，数据页中有一个<strong>页目录</strong>，起到记录的索引作用，就像我们书那样，针对书中内容的每个章节设立了一个目录，想看某个章节的时候，可以查看目录，快速找到对应的章节的页数，而数据页中的页目录就是为了能快速找到记录。页目录与记录的关系如下图：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904104220.png"></p>
<p>页目录创建的过程如下：</p>
<ol>
<li>将所有的记录划分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录；</li>
<li>每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为 n_owned 字段（上图中粉红色字段）</li>
<li>页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），<strong>每个槽相当于指针指向了不同组的最后一个记录</strong>。</li>
</ol>
<p>从图可以看到，<strong>页目录就是由多个槽组成的，槽相当于分组记录的索引</strong>。然后，因为记录是按照「主键值」从小到大排序的，所以<strong>我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录</strong>，无需从最小记录开始遍历整个页中的记录链表。</p>
<p>以上面那张图举个例子，5 个槽的编号分别为 0，1，2，3，4，我想查找主键为 11 的用户记录：</p>
<ul>
<li>先二分得出槽中间位是 (0+4)&#x2F;2&#x3D;2 ，2号槽里最大的记录为 8。因为 11 &gt; 8，所以需要从 2 号槽后继续搜索记录；</li>
<li>再使用二分搜索出 2 号和 4 槽的中间位是 (2+4)&#x2F;2&#x3D; 3，3 号槽里最大的记录为 12。因为 11 &lt; 12，所以主键为 11 的记录在 3 号槽里；</li>
<li>这里有个问题，<strong>「槽对应的值都是这个组的主键最大的记录，如何找到组里最小的记录」</strong>？比如槽 3 对应最大主键是 12 的记录，那如何找到最小记录 9。解决办法是：通过槽 3 找到 槽 2 对应的记录，也就是主键为 8 的记录。主键为 8 的记录的下一条记录就是槽 3 当中主键最小的 9 记录，然后开始向下搜索 2 次，定位到主键为 11 的记录，取出该条记录的信息即为我们想要查找的内容。</li>
</ul>
<p>看到第三步的时候，可能有的同学会疑问，如果某个槽内的记录很多，然后因为记录都是单向链表串起来的，那这样在槽内查找某个记录的时间复杂度不就是 O(n) 了吗？</p>
<p>这点不用担心，InnoDB 对每个分组中的记录条数都是有规定的，槽内的记录就只有几条：</p>
<ul>
<li>第一个分组中的记录只能有 1 条记录；</li>
<li>最后一个分组中的记录条数范围只能在 1-8 条之间；</li>
<li>剩下的分组中记录条数范围只能在 4-8 条之间。</li>
</ul>
<p>上面我们都是在说一个数据页中的记录检索，因为一个数据页中的记录是有限的，且主键值是有序的，所以通过对所有记录进行分组，然后将组号（槽号）存储到页目录，使其起到索引作用，通过二分查找的方法快速检索到记录在哪个分组，来降低检索的时间复杂度。</p>
<p>但是，当我们需要存储大量的记录时，就需要多个数据页，这时我们就需要考虑如何建立合适的索引，才能方便定位记录所在的页。</p>
<p>为了解决这个问题，<strong>InnoDB 采用了 B+ 树作为索引</strong>。磁盘的 I&#x2F;O 操作次数对索引的使用效率至关重要，因此在构造索引的时候，我们更倾向于采用“矮胖”的 B+ 树数据结构，这样所需要进行的磁盘 I&#x2F;O 次数更少，而且 B+ 树 更适合进行关键字的范围查询。</p>
<p>InnoDB 里的 B+ 树中的<strong>每个节点都是一个数据页</strong>，结构示意图如下：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904105401.png"></p>
<p>通过上图，我们看出 B+ 树的特点：</p>
<ul>
<li><strong>只有叶子节点才存放了数据</strong>，非叶子节点仅用来存放目录项作为索引。</li>
<li>非叶子节点分为不同层次，通过分层来降低每一层的搜索量；</li>
<li>所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；</li>
</ul>
<p>我们再看看 B+ 树如何实现快速查找主键为 6 的记录，以上图为例子：</p>
<ul>
<li>从根节点开始，通过二分法快速定位到符合页内范围包含查询值的页，因为查询的主键值为 6，在[1, 7)范围之间，所以到页 30 中查找更详细的目录项；</li>
<li>在非叶子节点（页30）中，继续通过二分法快速定位到符合页内范围包含查询值的页，主键值大于 5，所以就到叶子节点（页16）查找记录；</li>
<li>接着，在叶子节点（页16）中，通过槽查找记录时，使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到主键为 6 的记录。</li>
</ul>
<p>可以看到，在定位记录所在哪一个页时，也是通过二分法快速定位到包含该记录的页。定位到该页后，又会在该页内进行二分法快速定位记录所在的分组（槽号），最后在分组内进行遍历查找。</p>
<h3 id="索引分类"><a href="#索引分类" class="headerlink" title="索引分类"></a>索引分类</h3><p>另外，索引又可以分成<strong>聚簇索引</strong>和<strong>非聚簇索引</strong>（二级索引），它们区别就在于叶子节点存放的是什么数据：</p>
<ul>
<li><strong>聚簇索引</strong>：聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点，主键索引就是聚簇索引；</li>
<li><strong>非聚簇索引</strong>：二级索引的叶子节点存放的是主键值，而不是实际数据。</li>
</ul>
<p>因为表的数据都是存放在聚簇索引的叶子节点里，所以 InnoDB 存储引擎一定会为表创建一个聚簇索引，且由于数据在物理上只会保存一份，所以<strong>聚簇索引只能有一个</strong>。</p>
<p>InnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引：</p>
<ul>
<li>如果有主键，默认会使用主键作为聚簇索引的索引键；</li>
<li>如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键；</li>
<li>在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键；</li>
</ul>
<p>一张表只能有一个聚簇索引，那为了实现非主键字段的快速搜索，就引出了二级索引（非聚簇索引&#x2F;辅助索引），它也是利用了 B+ 树的数据结构，但是二级索引的叶子节点存放的是主键值，不是实际数据。</p>
<p>二级索引的 B+ 树如下图，数据部分为主键值：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904114508.png"></p>
<p>因此，如果某个查询语句使用了二级索引，但是查询的数据不是主键值，这时在二级索引找到主键值后，需要去聚簇索引中获得数据行，这个过程就叫作「<strong>回表</strong>」，也就是说要查两个 B+ 树才能查到数据。不过，当查询的数据是主键值时，因为只在二级索引就能查询到，不用再去聚簇索引查，这个过程就叫作「<strong>索引覆盖</strong>」，也就是只需要查一个 B+ 树就能找到数据。</p>
<p>使用表中的多个字段创建索引，就是 <strong>联合索引</strong>，也叫 <strong>组合索引</strong> 或 <strong>复合索引</strong>。</p>
<p>以 <code>score</code> 和 <code>name</code> 两个字段建立联合索引：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> `cus_order` <span class="keyword">ADD</span> INDEX id_score_name(score, name);</span><br></pre></td></tr></table></figure>

<p>使用联合索引的时候，MySQL会按照<strong>最左前缀匹配原则</strong>来查找。所谓最左前缀匹配原则，就是MySQL会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，如果查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成，或者在执行过程中遇到范围查询（如 **<code>&gt;</code><strong>、</strong><code>&lt;</code>**）才会停止匹配。对于 <strong><code>&gt;=</code><strong>、</strong><code>&lt;=</code><strong>、</strong><code>BETWEEN</code><strong>、</strong><code>like</code></strong> 前缀匹配的范围查询，并不会停止匹配。所以，我们在使用联合索引时，可以将区分度高的字段放在最左边，这也可以过滤更多数据。</p>
<p>比如，如果创建了一个 (a, b, c) 联合索引，如果查询条件是以下这几种，就可以利用联合索引：</p>
<ul>
<li><p>where a&#x3D;1；</p>
</li>
<li><p>where a&#x3D;1 and b&#x3D;2 and c&#x3D;3；</p>
</li>
<li><p>where a&#x3D;1 and b&#x3D;2；</p>
</li>
</ul>
<p>需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效:</p>
<ul>
<li><p>where b&#x3D;2；</p>
</li>
<li><p>where c&#x3D;3；</p>
</li>
<li><p>where b&#x3D;2 and c&#x3D;3；</p>
</li>
</ul>
<p>上面这些查询条件之所以会失效，是因为(a, b, c) 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，<strong>b 和 c 是全局无序，局部相对有序的</strong>，即只有在a &#x3D; 1的情况下，这时候再去查询b才会是有序的。这样在没有遵循最左匹配原则的情况下，是无法利用到索引的。</p>
<p>再举一个例子：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_table <span class="keyword">where</span> a <span class="operator">&gt;</span> <span class="number">1</span> <span class="keyword">and</span> b <span class="operator">=</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>由于联合索引（二级索引）是先按照 a 字段的值排序的，所以符合 a &gt; 1 条件的二级索引记录肯定是相邻的，于是在进行索引扫描的时候，可以定位到符合 a &gt; 1 条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合 a &gt; 1 条件位置。所以 a 字段可以在联合索引的 B+Tree 中进行索引查询。<strong>但是在符合 a &gt; 1 条件的二级索引记录的范围里，b 字段的值是无序的</strong>。</p>
<p>比如下图的联合索引的 B+ Tree 里：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230912151445.png"></p>
<p>下面这三条记录的 a 字段的值都符合 a &gt; 1 查询条件，而 b 字段的值是无序的：</p>
<ul>
<li><p>a 字段值为 5 的记录，该记录的 b 字段值为 8；</p>
</li>
<li><p>a 字段值为 6 的记录，该记录的 b 字段值为 10；</p>
</li>
<li><p>a 字段值为 7 的记录，该记录的 b 字段值为 5；</p>
</li>
</ul>
<p>因此，我们不能根据查询条件 b &#x3D; 2 来进一步减少需要扫描的记录数量（b 字段无法利用联合索引进行索引查询的意思）。</p>
<p>所以在执行 Q1 这条查询语句的时候，对应的扫描区间是 (2, + ∞)，形成该扫描区间的边界条件是 a &gt; 1，与 b &#x3D; 2 无关。</p>
<p>因此，<strong>Q1 这条查询语句只有 a 字段用到了联合索引进行索引查询，而 b 字段并没有使用到联合索引</strong>。</p>
<p>我们也可以在执行计划中的 key_len 知道这一点，在使用联合索引进行查询的时候，<strong>通过 key_len 我们可以知道优化器具体使用了多少个字段的查询条件来形成扫描区间的边界条件</strong>。下图中可以看到 key_len 为 4 字节（如果字段允许为 NULL，就在字段类型占用的字节数上加 1，也就是 5 字节），说明只有 a 字段用到了联合索引进行索引查询，而且可以看到，即使 b 字段没用到联合索引，key 为 idx_a_b，说明 Q1 查询语句使用了 idx_a_b 联合索引。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230912151557.png"></p>
<p>其余常见的索引失效情况如下：</p>
<ul>
<li><code>SELECT *</code> 不会直接导致索引失效（如果不走索引大概率是因为 where 查询范围过大导致的），但它可能会带来一些其他的性能问题比如造成网络传输和数据处理的浪费、无法使用索引覆盖;</li>
<li>创建了组合索引，但查询条件未遵守最左匹配原则;</li>
<li>在索引列上进行计算、函数、类型转换等操作;</li>
<li>以 <code>%</code> 开头的 LIKE 查询比如 <code>like &#39;%abc&#39;</code>，这个是否使用索引会看所选字段;</li>
<li>查询条件中使用 or，且 or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到;</li>
<li>发生隐式转换，即操作符<strong>左右两边的数据类型不一致</strong>。</li>
</ul>
<h2 id="Buffer-Pool"><a href="#Buffer-Pool" class="headerlink" title="Buffer Pool"></a>Buffer Pool</h2><h3 id="Buffer-Pool的作用"><a href="#Buffer-Pool的作用" class="headerlink" title="Buffer Pool的作用"></a>Buffer Pool的作用</h3><p>虽然说 MySQL 的数据是存储在磁盘里的，但也不能每次都从磁盘里面读取数据，这样性能是极差的。要想提升查询性能，就要用到缓存。所以，当数据从磁盘中取出后，缓存在内存中，下次查询同样的数据的时候，直接从内存中读取。为此，Innodb 存储引擎设计了一个<strong>缓冲池（<em>Buffer Pool</em>）</strong>，来提高数据库的读写性能。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904152520.png"></p>
<p>有了缓冲池后：</p>
<ul>
<li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。</li>
<li>当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。</li>
</ul>
<p>在 MySQL 启动的时候，<strong>InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的<code>16KB</code>的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页</strong>。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。</p>
<p>所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，接着将虚拟地址和物理地址建立映射关系。</p>
<p>Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。</p>
<p>为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个<strong>控制块</strong>，这跟操作系统的分页机制是及其相似的。控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页，由于二者不一定会将连续空间填满，空出来的部分称为碎片空间（灰色部分），如下图：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904152937.png"></p>
<h3 id="如何管理Buffer-Pool"><a href="#如何管理Buffer-Pool" class="headerlink" title="如何管理Buffer Pool"></a>如何管理Buffer Pool</h3><h4 id="空闲页"><a href="#空闲页" class="headerlink" title="空闲页"></a>空闲页</h4><p>Buffer Pool使用一段时间后，里面既有空闲空间，也有已经被使用的。当我们从磁盘读取数据到Buffer Pool的时候，需要快速找到空闲空间。为了能实现这个目标，我们可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 <strong>Free 链表</strong>（空闲链表）。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904153712.png"></p>
<p>Free 链表上除了有控制块，还有一个头节点，该头节点包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。</p>
<p>Free 链表节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于 Free 链表节点都对应一个空闲的缓存页。</p>
<p>有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。</p>
<h4 id="脏页"><a href="#脏页" class="headerlink" title="脏页"></a>脏页</h4><p>空闲链表提高了磁盘的读性能，那么<strong>Flush 链表</strong>（脏页链表）则提高了磁盘的写性能。更新数据的时候，不需要每次都要写入磁盘， Buffer Pool 会将对应的缓存页标记为<strong>脏页</strong>，然后再由后台线程将脏页写入到磁盘。</p>
<p>那为了能快速知道哪些缓存页是脏的，于是就设计出 Flush 链表，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904154202.png"></p>
<p>为了避免数据丢失，InnoDB的更新操作采用WAL策略（会在Recovery部分详细说明），即先写日志再写入磁盘，下面几种情况会触发脏页的刷新：</p>
<ul>
<li>当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘；</li>
<li>Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；</li>
<li>MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘；</li>
<li>MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；</li>
</ul>
<p>在我们开启了慢 SQL 监控后，如果你发现「偶尔」会出现一些用时稍长的 SQL ，这可能是因为脏页在刷新到磁盘时可能会给数据库带来性能开销，导致数据库操作抖动。</p>
<p>如果间断出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小。</p>
<h4 id="缓存命中率"><a href="#缓存命中率" class="headerlink" title="缓存命中率"></a>缓存命中率</h4><p>由于缓存是有限的，为了提高缓存命中率，我们需要定期清除掉Buffer Pool中最少访问的一批的缓冲页。可以采用LRU（Least recently used）算法，保留最近使用（链表头部），剔除最久没被使用的（链表末尾）。</p>
<p>简单的 LRU 算法的实现思路是这样的：</p>
<ul>
<li>当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。</li>
<li>当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点。</li>
</ul>
<p>但简单 LRU 算法又会带来新的问题：</p>
<ul>
<li>预读失效；</li>
<li>Buffer Pool 污染；</li>
</ul>
<p>MySQL的预读机制，是基于程序的<strong>空间局部性原理</strong>，即程序访问了某个存储单元，则不久之后，其附近的存储单元大概率也将被访问。MySQL在加载数据页的时候，会提前把它相邻的数据页一并加载进来，目的是为了减少磁盘 IO。</p>
<p>但可能这些<strong>被提前加载进来的数据页，并没有被访问到</strong>，相当于这个预读就白做了，即<strong>预读失效</strong>。如果使用简单的 LRU 算法，就会把预读页放到 LRU 链表头部，而当 Buffer Pool 空间不够的时候，还需要把末尾的页淘汰掉。如果这些占用了 LRU 链表前排的位置的预读页一直不会被访问到，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。</p>
<p>为了避免预读失效所带来的影响，最好的做法就是<strong>让预读的页停留在 Buffer Pool 里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在 Buffer Pool 里的时间尽可能长</strong>。</p>
<p>MySQL 将 LRU 划分了 2 个区域：<strong>old 区域 和 young 区域</strong>。young 区域在 LRU 链表的前半部分，old 区域则是在后半部分，如下图：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230904162927.png"></p>
<p>old 区域占整个 LRU 链表长度的比例可以通过 <code>innodb_old_blocks_pct</code> 参数来设置，默认是 37，代表整个 LRU 链表中 young 区域与 old 区域比例是 63:37。<strong>划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部</strong>。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。</p>
<p>而<strong>Buffer Pool 污染</strong>是指：当某一个 SQL 语句<strong>扫描了大量的数据</strong>时，在 Buffer Pool 空间比较有限的情况下，可能会将 <strong>Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了</strong>，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降。</p>
<p>注意， Buffer Pool 污染并不只是查询语句查询出了大量的数据才出现的问题，即使查询出来的结果集很小，也会造成 Buffer Pool 污染。比如执行了下面的语句：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_user <span class="keyword">where</span> name <span class="keyword">like</span> &quot;%123%&quot;;</span><br></pre></td></tr></table></figure>

<p>像上面这种全表扫描的查询，很多缓冲页其实只会被访问一次，但是它却只因为被访问了一次而进入到 young 区域，从而导致热点数据被替换了。因此只要我们提高进入到 young 区域的门槛，就能有效地保证 young 区域里的热点数据不会被替换掉。</p>
<p>MySQL 对进入到 young 区域增加了一个<strong>停留在 old 区域的时间判断</strong>。在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间：</p>
<ul>
<li>如果后续的访问时间与第一次访问的时间<strong>在某个时间间隔内</strong>，那么<strong>该缓存页就不会被从 old 区域移动到 young 区域的头部</strong>；</li>
<li>如果后续的访问时间与第一次访问的时间<strong>不在某个时间间隔内</strong>，那么<strong>该缓存页移动到 young 区域的头部</strong>；</li>
</ul>
<p>这个间隔时间是由 <code>innodb_old_blocks_time</code> 控制的，默认是 1000 ms。</p>
<p>也就说，<strong>只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部</strong>，这样就解决了 Buffer Pool 污染的问题 。</p>
<p>另外，MySQL 针对 young 区域其实做了一个优化，为了防止 young 区域节点频繁移动到头部。young 区域前面 1&#x2F;4 被访问不会移动到链表头部，只有后面的 3&#x2F;4 被访问了才会。</p>
<h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><h2 id="DataBox"><a href="#DataBox" class="headerlink" title="DataBox"></a>DataBox</h2><p>现代数据库都支持在record（元组）中使用多种数据类型，SimpleDB也不例外。为了一致性和便利性，我们选择在实现语言的默认设置之上构建自己的数据类型内部表示，并用databox表示他们。</p>
<p>一个databox可以容纳以下类型的数据：</p>
<ul>
<li><p>Boolean（1 byte）</p>
</li>
<li><p>Int（4 bytes）</p>
</li>
<li><p>Float（4 bytes）</p>
</li>
<li><p>Long （8 bytes）</p>
</li>
<li><p>String(N)（N bytes）</p>
</li>
</ul>
<h2 id="RecordId"><a href="#RecordId" class="headerlink" title="RecordId"></a>RecordId</h2><p>一个表中的record，由其page number（页码）和entry number（条目码）唯一标识。因此我们可以用(pageNum, entryNum)组成一个RecordId，在SimpleDB中，我们将在我们的叶节点使用RecordId作为指向数据页中记录的指针。</p>
<h2 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h2><p>在SimpleDB中使用B+ Tree作为索引结构，而索引结构的选择有很多，比如Hash表，BST，AVL树，红黑树，B树和B+树等。</p>
<ul>
<li><p><strong>Hash表</strong>可以通过键(key)即可快速取出对应的值(value)，虽然Hash表查询速度很快，但是不支持顺序和范围查询。假如我们要对表中的数据进行排序或者进行范围查询，那 Hash 索引就不能实现。并且，每次 IO 只能取一个。</p>
</li>
<li><p><strong>BST</strong>，即二叉查找树，其特点为：左子树所有节点的值均小于根节点的值；右子树所有节点的值均大于根节点的值；左右子树也分别为二叉查找树。BST在不平衡的时候，会退化成线性链表，查询效率也急剧下降，因此不适合作为索引。</p>
</li>
<li><p><strong>AVL树</strong>，针对不平衡的现象，人们发明了AVL树，即自平衡二叉查找树，通过旋转操作来保持平衡。但是AVL树需要频繁的进行旋转操作来保持平衡，因此会有较大的计算开销进而降低了查询性能。并且， 在使用 AVL 树时，每个树节点仅存储一个数据，而每次进行磁盘 IO 时只能读取一个节点的数据，如果需要查询的数据分布在多个节点上，那么就需要进行多次磁盘 IO，由于磁盘IO十分耗时，因此AVL树也不适用于索引。</p>
</li>
<li><p><strong>红黑树</strong>，红黑树也是一种自平衡二叉查找树，通过插入和删除节点时进行颜色变换和旋转操作，使得树始终保持平衡状态，其特点为：每个节点非红即黑；根节点总是黑色的；每个叶子节点都是黑色的空节点（NIL 节点）；如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。但红黑树追求的是大致的平衡，树的高度较高，这可能会导致一些数据需要进行多次磁盘 IO 操作才能查询到，这也是 MySQL 没有选择红黑树作为的主要原因。不过红黑树的插入和删除操作效率大大提高了，因为红黑树在插入和删除节点时只需进行 O(1) 次数的旋转和变色操作，即可保持基本平衡状态，它在内存方面应用较多。比如说Java里的HashMap的实现就用到了红黑树。</p>
</li>
<li><p><strong>B 树 &amp; B+树</strong>，B 树也称 B-树，全称为 <strong>多路平衡查找树</strong> ，B+ 树是 B 树的一种变体。B 树和 B+树中的 B 是 <code>Balanced</code> （平衡）的意思。目前大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构。</p>
<p>比如Mongodb的索引早期就是用B树作为索引结果，之所以是B树是因为比起关系型数据库Mongodb对于遍历数据的需求没有那么大，更多是对单个文档的查询，使用B树更高效，当然Mongodb也支持多个文档的查询。后面Mongodb默认的存储引擎改为 WiredTiger 存储引擎后，WiredTiger也使用B+树作为索引结构了。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGov2-7a83d0068331c5fe82ae2557b97e52d8_1440w.webp"></p>
<p><strong>B 树&amp; B+树两者有何异同呢？</strong></p>
<ul>
<li>B 树的所有节点既存放键(key) 也存放数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。</li>
<li>B 树的叶子节点都是独立的；B+树的叶子节点有一条引用链指向与它相邻的叶子节点。</li>
<li>B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。</li>
<li>在 B 树中进行范围查询时，首先找到要查找的下限，然后对 B 树进行中序遍历，直到找到查找的上限；而B+树的范围查询，只需要对链表进行遍历即可。</li>
</ul>
<p>综上，B+树与 B 树相比，具备更少的 IO 次数、更稳定的查询效率和更适于范围查询这些优势。</p>
</li>
</ul>
<p>在 MySQL 中，MyISAM 引擎和 InnoDB 引擎也都是使用 B+ Tree 作为索引结构，但是，两者的实现方式不太一样。</p>
<blockquote>
<p>MyISAM 引擎中，B+Tree 叶节点的 data 域存放的是数据记录的地址。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“<strong>非聚簇索引（非聚集索引）</strong>”。</p>
<p>InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。这被称为“<strong>聚簇索引（聚集索引）</strong>”，而其余的索引都作为 <strong>辅助索引</strong> ，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。</p>
</blockquote>
<p>回到SimpleDB中，我们需要实现以下重要类来构建index：</p>
<ul>
<li><p><strong>BPlusTree</strong>：该文件包含管理 B+ 树结构的类。每个 B+ 树都将 DataBox 类型的键（表中的单个值或“单元格”）映射到 RecordId 类型的值（数据页上记录的标识符）。</p>
</li>
<li><p><strong>BPlusNode</strong>：一个B+节点表示B+树中的一个节点，包含与BPlusTree类似的get、put、delete等方法。 BPlusNode 是一个抽象类，实现为 LeafNode 或 InnerNode。</p>
<ul>
<li><p><strong>LeafNode</strong>：叶节点是没有后代的节点，它包含一个&lt; key, recordID &gt;的键值对，以及指向其右兄弟节点的指针。</p>
</li>
<li><p><strong>InnerNode</strong>：内部节点是存储自身的key和指向子节点的指针（即page number）的节点。</p>
</li>
</ul>
</li>
<li><p><strong>BPlusTreeMetadata</strong>：index文件夹下包含的一个类，用于存储树的顺序和高度等有用信息。可以使用上面列出的所有类中可用的 this.metadata 实例变量来访问此类的实例。</p>
</li>
</ul>
<p>此外有一些实现的注意事项：</p>
<ul>
<li><p>一般来说，B+树是支持重复键的。但是，我们实现的 B+ 树要做到不支持重复键。每当插入重复键时，都需要抛出异常。</p>
</li>
<li><p>我们实现的B+树，仅假设内部节点和叶节点可以在单个page（数据页）上序列化，不用考虑多个pages的情况。</p>
</li>
<li><p>在SimpleDB中，delete不会重新平衡树。因此，对于d阶B+树中的所有非根叶节点，d和2d的条目之间的不变量（invariant）被打破。实际的B+树在删除后会重新平衡，但为了简单起见，我们不会在该数据库中对树重新平衡。</p>
</li>
</ul>
<p>由于BPlusNdoe是LeafNode和InnerNode的父类，因此关键在于在子类中实现BPlusNode的如下方法：</p>
<p><strong>public abstract LeafNode get(DataBox key);</strong></p>
<p>理解get的核心就是通过key获取LeafNode后，就能很简单的实现其功能。如果是InnerNode的话，那么根据key获得pagenum，创建新的临时节点，调用其get方法，这样层层递进，最后肯定是叶节点调用自身的get，而叶节点就是要返回的对象，直接返回this即可。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * node.get(k)返回对node进行查询时，k可能所在的叶节点</span></span><br><span class="line"><span class="comment"> * 例如，考虑以下B+树（为简洁起见，只显示键；省略了记录id）。</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> *                               inner</span></span><br><span class="line"><span class="comment"> *                               +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *                               | 10 | 20 |    |    |</span></span><br><span class="line"><span class="comment"> *                               +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *                              /     |     \</span></span><br><span class="line"><span class="comment"> *                         ____/      |      \____</span></span><br><span class="line"><span class="comment"> *                        /           |           \</span></span><br><span class="line"><span class="comment"> *   +----+----+----+----+  +----+----+----+----+  +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *   |  1 |  2 |  3 |    |-&gt;| 11 | 12 | 13 |    |-&gt;| 21 | 22 | 23 |    |</span></span><br><span class="line"><span class="comment"> *   +----+----+----+----+  +----+----+----+----+  +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *   leaf0                  leaf1                  leaf2</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * inner.get(x)应该返回：</span></span><br><span class="line"><span class="comment"> * leaf0 when x &lt; 10</span></span><br><span class="line"><span class="comment"> * leaf1 when 10 &lt;= x &lt; 20</span></span><br><span class="line"><span class="comment"> * leaf2 when x &gt;= 20</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<p><strong>public abstract LeafNode getLeftmostLeaf();</strong></p>
<p>对于InnerNode，就是获取子结点中pagenum最小的节点，同样的创建临时节点调用getLeftmostLeaf方法，最后叶节点调用自身getLeftmostLeaf，返回this。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * node.getLeftmostLeaf()返回以node为根的子树中最左边的叶子节点</span></span><br><span class="line"><span class="comment"> * 在上面的例子中，inner.getLeftmostLeaf()将返回leaf0 ，而leaf1.getLeftmostLeaf()将返回leaf1</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<p><strong>public abstract Optional&lt;Pair&lt; DataBox, Long &gt;&gt; put(DataBox key, RecordId rid);</strong></p>
<p>需要考虑溢出问题。对于InnerNode，首先通过key判断要插入的entry要插到哪里；把entry插入后，判断有无溢出(keys.size()是否超过了2d)；如果溢出，则分裂，左节点为原节点，保存前d条entries，右节点为新节点存储d+2及之后的entries，在keys中索引为d的split_key将存储到更上一层的节点，最后更新page；如果没有溢出，则更新page。而LeafNode总体流程基本一致，就是分裂阶段存在不同，分裂成两个叶节点，左节点保存前d条entries，而右节点保存d+1及之后的entries。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * node.put(k, rid)将键值对（k，rid）插入到以node为根的子树中，并且需要考虑以下两种情况：</span></span><br><span class="line"><span class="comment"> * 1.如果插入后不会导致node溢出，则返回Optional.empty()</span></span><br><span class="line"><span class="comment"> * 2.如果插入后会导致node溢出，那么node就会被分割为一个左节点和右节点并返回一对(split_key, right_node_page_num)，</span></span><br><span class="line"><span class="comment"> * 其中right_node_page_num是新创建的右节点的页码，而split_key取决于node是一个内部节点还是一个叶子节点</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 举个例子：</span></span><br><span class="line"><span class="comment"> * 1.往前面的B+树中插入key为4的entry，满足情况1，插入后的B+树如下：</span></span><br><span class="line"><span class="comment"> *                               inner</span></span><br><span class="line"><span class="comment"> *                               +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *                               | 10 | 20 |    |    |</span></span><br><span class="line"><span class="comment"> *                               +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *                              /     |     \</span></span><br><span class="line"><span class="comment"> *                         ____/      |      \____</span></span><br><span class="line"><span class="comment"> *                        /           |           \</span></span><br><span class="line"><span class="comment"> *   +----+----+----+----+  +----+----+----+----+  +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *   |  1 |  2 |  3 |  4 |-&gt;| 11 | 12 | 13 |    |-&gt;| 21 | 22 | 23 |    |</span></span><br><span class="line"><span class="comment"> *   +----+----+----+----+  +----+----+----+----+  +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *   leaf0                  leaf1                  leaf2</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 2.在上面的基础上，在插入key为5的entry，满足情况2，插入后的B+树如下：</span></span><br><span class="line"><span class="comment"> *                          inner</span></span><br><span class="line"><span class="comment"> *                          +--+--+--+--+</span></span><br><span class="line"><span class="comment"> *                          | 3|10|20|  |</span></span><br><span class="line"><span class="comment"> *                          +--+--+--+--+</span></span><br><span class="line"><span class="comment"> *                         /   |  |   \</span></span><br><span class="line"><span class="comment"> *                 _______/    |  |    \_________</span></span><br><span class="line"><span class="comment"> *                /            |   \             \</span></span><br><span class="line"><span class="comment"> *   +--+--+--+--+  +--+--+--+--+  +--+--+--+--+  +--+--+--+--+</span></span><br><span class="line"><span class="comment"> *   | 1| 2|  |  |-&gt;| 3| 4| 5|  |-&gt;|11|12|13|  |-&gt;|21|22|23|  |</span></span><br><span class="line"><span class="comment"> *   +--+--+--+--+  +--+--+--+--+  +--+--+--+--+  +--+--+--+--+</span></span><br><span class="line"><span class="comment"> *   leaf0          leaf3          leaf1          leaf2</span></span><br><span class="line"><span class="comment"> * 可以看到leaf0由于溢出，创建了一个新的兄弟节点leaf3，d个entries在leaf0(d是5/2=2)，d+1及之后的entries在leaf3</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * 当一个内部节点分裂时，前d个entries在原来节点，最后d个entries在新创建的节点，而中间的entries则向上移动（不是复制）</span></span><br><span class="line"><span class="comment"> * 举个例子：</span></span><br><span class="line"><span class="comment"> * +---+---+---+---+</span></span><br><span class="line"><span class="comment"> * | 1 | 2 | 3 | 4 | 5</span></span><br><span class="line"><span class="comment"> * +---+---+---+---+</span></span><br><span class="line"><span class="comment"> * 分裂后：</span></span><br><span class="line"><span class="comment"> * +---+---+---+---+  +---+---+---+---+</span></span><br><span class="line"><span class="comment"> * | 1 | 2 |   |   |  | 4 | 5 |   |   |</span></span><br><span class="line"><span class="comment"> * +---+---+---+---+  +---+---+---+---+</span></span><br><span class="line"><span class="comment"> * 此时split_key为3</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * 除了以上提及的情况，不要以任何其他方式重新分配entries，例如不要在节点之间移动entries以避免拆分</span></span><br><span class="line"><span class="comment"> * 此外，SimpleDB不支持具有相同key的两条重复entries，如果有重复的key插入到一个叶子节点中，B+树并不会发生改变并且会抛出BPlusTreeException</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<p><strong>public abstract Optional&lt;Pair&lt; DataBox, Long &gt;&gt; bulkLoad(Iterator&lt;Pair&lt; DataBox, RecordId &gt;&gt; data, float fillFactor);</strong></p>
<p>跟get方法十分类似，但是涉及到fillFactor会有所不同。对于InnerNode，实际上调用的是叶节点的bulkLoad，把entries填充到最右边的叶节点。InnerNode的bulkLoad更多是用来检测InnerNode在这个过程是否溢出，如果溢出就要分裂。对于LeafNode，关键是用fillFactor控制每个LeafNode中entries的占比，比如fillFactor为0.5，说明叶节点只有一半的空间能装载entries。一边加载数据一边检测是否到达这个界限，如果触及就分裂节点。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * node.bulkLoad(data, fillFactor)是按照填充因子fillFactor将data中的record批量加载到以node为根的子树中的方法</span></span><br><span class="line"><span class="comment"> * 这个方法十分类似于node.put，但有些地方不同：</span></span><br><span class="line"><span class="comment"> * 1.叶子节点不是填充到2*d+1然后分裂，而是填充到比fillFactor多1条记录，然后通过创建一个只包含一条记录的右边兄弟节点来 &quot;分裂&quot;（留下具有所需填充系数的原始节点）</span></span><br><span class="line"><span class="comment"> * 2.内部节点应该反复尝试批量加载到最右边的子节点，直到内部节点已经满了（在这种情况下，它应该分裂）或者没有更多的数据了</span></span><br><span class="line"><span class="comment"> * fillFactor用来表示叶节点有多满，假如fillFactor为1，意味着叶节点应该完全填满，如果fillFactor为0.5，意味着叶节点应该填满一半</span></span><br><span class="line"><span class="comment"> * fillFactor高则范围查询性能更好，但会增加访问特定record的I/O成本，计算叶节点多满应该向上取整，d=5，fillFactor=0.75，叶节点应该4/5满</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<p><strong>public abstract void remove(DataBox key);</strong></p>
<p>由于不考虑重新平衡B+树，因此remove实现起来十分简单，查询哪个叶节点有对应key，然后从删除叶节点中的的key和对应的record id。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * node.remove(key)从以node为根的子树中删除键值对（key，rid）</span></span><br><span class="line"><span class="comment"> * 如果key不在子树中，那么不做任何操作，并且remove后不用重新平衡树，只需删除（key，rid）即可</span></span><br><span class="line"><span class="comment"> * 举个例子：</span></span><br><span class="line"><span class="comment"> * 对一开始出现的子树调用inner.remove(2)后，子树变为：</span></span><br><span class="line"><span class="comment"> *                               inner</span></span><br><span class="line"><span class="comment"> *                               +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *                               | 10 | 20 |    |    |</span></span><br><span class="line"><span class="comment"> *                               +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *                              /     |     \</span></span><br><span class="line"><span class="comment"> *                         ____/      |      \____</span></span><br><span class="line"><span class="comment"> *                        /           |           \</span></span><br><span class="line"><span class="comment"> *   +----+----+----+----+  +----+----+----+----+  +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *   |  1 |  3 |    |    |-&gt;| 11 | 12 | 13 |    |-&gt;| 21 | 22 | 23 |    |</span></span><br><span class="line"><span class="comment"> *   +----+----+----+----+  +----+----+----+----+  +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *   leaf0                  leaf1                  leaf2</span></span><br><span class="line"><span class="comment"> * 再接连调用inner.remove(1)和inner.remove(3)后，子树变为：</span></span><br><span class="line"><span class="comment"> *                               inner</span></span><br><span class="line"><span class="comment"> *                               +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *                               | 10 | 20 |    |    |</span></span><br><span class="line"><span class="comment"> *                               +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *                              /     |     \</span></span><br><span class="line"><span class="comment"> *                         ____/      |      \____</span></span><br><span class="line"><span class="comment"> *                        /           |           \</span></span><br><span class="line"><span class="comment"> *   +----+----+----+----+  +----+----+----+----+  +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *   |    |    |    |    |-&gt;| 11 | 12 | 13 |    |-&gt;| 21 | 22 | 23 |    |</span></span><br><span class="line"><span class="comment"> *   +----+----+----+----+  +----+----+----+----+  +----+----+----+----+</span></span><br><span class="line"><span class="comment"> *   leaf0                  leaf1                  leaf2</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>

<p>这一部分的框架图如下所示：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo20230619164330.png"></p>
<h1 id="MySQL查询相关"><a href="#MySQL查询相关" class="headerlink" title="MySQL查询相关"></a>MySQL查询相关</h1><h2 id="select语句执行流程"><a href="#select语句执行流程" class="headerlink" title="select语句执行流程"></a>select语句执行流程</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> product <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>当我们执行上面的查询语句时，在 MySQL 中发生了：</p>
<ul>
<li><strong>连接器</strong>：基于TCP建立连接，管理连接、校验用户身份；</li>
<li><strong>查询缓存</strong>：如果 SQL 是查询语句（select 语句），MySQL 就会先去查询缓存（ Query Cache ）里查找缓存数据，看看之前有没有执行过这一条命令，这个查询缓存是以 key-value 形式保存在内存中的，key 为 SQL 查询语句，value 为 SQL 语句查询的结果。如果命中则返回value，否则继续往下执行。由于查询缓存命中率很低，只要有一个表有更新操作，那么这个表的查询缓存就会被清空，因此MySQL 8.0 已删除该模块；</li>
<li><strong>解析 SQL</strong>：通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；</li>
<li><strong>执行 SQL</strong>：执行 SQL 共有三个阶段：<ul>
<li>预处理阶段：检查表或字段是否存在；将 <code>select *</code> 中的 <code>*</code> 符号扩展为表上的所有列。</li>
<li>优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；</li>
<li>执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；</li>
</ul>
</li>
</ul>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905095134.png"></p>
<p>此处重点讲一下<strong>执行阶段</strong>的执行方式，一般来说就三种：</p>
<ul>
<li><p>主键索引查询：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> product <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>这条查询语句的查询条件用到了主键索引，而且是等值查询，同时主键 id 是唯一，不会有 id 相同的记录，所以优化器决定选用访问类型为 const (访问类型，由优化器决定) 进行查询，也就是使用主键索引查询一条记录。</p>
<ul>
<li><p>执行器第一次查询，会调用 read_first_record 函数指针指向的函数，因为优化器选择的访问类型为 const，这个函数指针被指向为 InnoDB 引擎索引查询的接口，把条件 <code>id = 1</code> 交给存储引擎，<strong>让存储引擎定位符合条件的第一条记录</strong>。</p>
</li>
<li><p>存储引擎通过主键索引的 B+ 树结构定位到 id &#x3D; 1的第一条记录，如果记录是不存在的，就会向执行器上报记录找不到的错误，然后查询结束。如果记录是存在的，就会将记录返回给执行器；</p>
</li>
<li><p>执行器从存储引擎读到记录后，接着判断记录是否符合查询条件，如果符合则发送给客户端，如果不符合则跳过该记录。</p>
</li>
<li><p>执行器查询的过程是一个 while 循环，所以还会再查一次，但是这次因为不是第一次查询了，所以会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 const，这个函数指针被指向为一个永远返回 - 1 的函数，所以当调用该函数的时候，执行器就退出循环，也就是结束查询了。</p>
</li>
</ul>
</li>
<li><p>全表扫描：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> product <span class="keyword">where</span> name <span class="operator">=</span> <span class="string">&#x27;iphone&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>这条查询语句的查询条件没有用到索引，所以优化器决定选用访问类型为 ALL 进行查询，也就是全表扫描的方式查询。</p>
<ul>
<li><p>执行器第一次查询，会调用 read_first_record 函数指针指向的函数，因为优化器选择的访问类型为 all，这个函数指针被指向为 InnoDB 引擎全扫描的接口，<strong>让存储引擎读取表中的第一条记录</strong>；</p>
</li>
<li><p>执行器会判断读到的这条记录的 name 是不是 iphone，如果不是则跳过；如果是则将记录发给客户的（是的没错，Server 层每从存储引擎读到一条记录就会发送给客户端，之所以客户端显示的时候是直接显示所有记录的，是因为客户端是等查询语句查询完成后，才会显示出所有的记录）。</p>
</li>
<li><p>执行器查询的过程是一个 while 循环，所以还会再查一次，会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 all，read_record 函数指针指向的还是 InnoDB 引擎全扫描的接口，所以接着向存储引擎层要求继续读刚才那条记录的下一条记录，存储引擎把下一条记录取出后就将其返回给执行器（Server层），执行器继续判断条件，不符合查询条件即跳过该记录，否则发送到客户端；</p>
</li>
<li><p>一直重复上述过程，直到存储引擎把表中的所有记录读完，然后向执行器（Server层） 返回了读取完毕的信息；</p>
</li>
<li><p>执行器收到存储引擎报告的查询完毕的信息，退出循环，停止查询。</p>
</li>
</ul>
</li>
<li><p>索引下推：</p>
<p>索引下推能够减少<strong>二级索引</strong>在查询时的回表操作，提高查询的效率，因为它将 Server 层部分负责的事情，交给存储引擎层去处理了。假如下图中，我们对age和reward字段建立联合索引。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905101535.png"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_user <span class="keyword">where</span> age <span class="operator">&gt;</span> <span class="number">20</span> <span class="keyword">and</span> reward <span class="operator">=</span> <span class="number">100000</span>;</span><br></pre></td></tr></table></figure>

<p>联合索引当遇到范围查询 (&gt;、&lt;) 就会停止匹配，也就是 <strong>age 字段能用到联合索引，但是 reward 字段则无法利用到索引</strong>。</p>
<p>假如不使用索引下推：</p>
<ul>
<li><p>Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age &gt; 20 的第一条记录；</p>
</li>
<li><p>存储引擎根据二级索引的 B+ 树快速定位到这条记录后，获取主键值，然后<strong>进行回表操作</strong>，将完整的记录返回给 Server 层；</p>
</li>
<li><p>Server 层在判断该记录的 reward 是否等于 100000，如果成立则将其发送给客户端；否则跳过该记录；</p>
</li>
<li><p>接着，继续向存储引擎索要下一条记录，存储引擎在二级索引定位到记录后，获取主键值，然后回表操作，将完整的记录返回给 Server 层；</p>
</li>
<li><p>如此往复，直到存储引擎把表中的所有记录读完。</p>
</li>
</ul>
</li>
</ul>
<p>如果不使用索引下推，每查询到一条二级索引记录，都要进行回表操作，将记录返回给Server，然后Server再判断该记录的reward是否等于100000。</p>
<p>假如使用索引下推：</p>
<ul>
<li><p>Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age &gt; 20 的第一条记录；</p>
</li>
<li><p>存储引擎定位到二级索引后，<strong>先不执行回表</strong>操作，而是先判断一下该索引中包含的列（reward列）的条件（reward 是否等于 100000）是否成立。如果<strong>条件不成立</strong>，则直接<strong>跳过该二级索引</strong>。如果<strong>成立</strong>，则<strong>执行回表</strong>操作，将完成记录返回给 Server 层。</p>
</li>
<li><p>Server 层在判断其他的查询条件（本次查询没有其他条件）是否成立，如果成立则将其发送给客户端；否则跳过该记录，然后向存储引擎索要下一条记录。</p>
</li>
<li><p>如此往复，直到存储引擎把表中的所有记录读完。</p>
</li>
</ul>
<p>可以看到，使用了索引下推后，虽然 reward 列无法使用到联合索引，但是因为它包含在联合索引（age，reward）里，所以直接在存储引擎过滤出满足 reward &#x3D; 100000 的记录后，才去执行回表操作获取整个记录。相比于没有使用索引下推，节省了很多回表操作。</p>
<h2 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h2><p>JOIN 是“连接”的意思，顾名思义，SQL JOIN 子句用于将两个或者多个表联合起来进行查询。</p>
<p>连接表时需要在每个表中选择一个字段，并对这些字段的值进行比较，值相同的两条记录将合并为一条。<strong>连接表的本质就是将不同表的记录合并起来，形成一张新表。当然，这张新表只是临时的，它仅存在于本次查询期间</strong>。</p>
<p>使用 <code>JOIN</code> 连接两个表的基本语法如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> table1.column1, table2.column2...</span><br><span class="line"><span class="keyword">from</span> table1</span><br><span class="line"><span class="keyword">join</span> table2</span><br><span class="line"><span class="keyword">on</span> table1.common_column1 <span class="operator">=</span> table2.common_column2;</span><br></pre></td></tr></table></figure>

<p><code>table1.common_column1 = table2.common_column2</code> 是连接条件，只有满足此条件的记录才会合并为一行。也可以使用多个运算符来连接表，例如 &#x3D;、&gt;、&lt;、&lt;&gt;、&lt;&#x3D;、&gt;&#x3D;、!&#x3D;、<code>between</code>、<code>like</code> 或者 <code>not</code>，但是最常见的是使用 &#x3D;。</p>
<p>当两个表中有同名的字段时，为了帮助数据库引擎区分是哪个表的字段，在书写同名字段名时需要加上表名。当然，如果书写的字段名在两个表中是唯一的，也可以不使用以上格式，只写字段名即可。</p>
<p>另外，如果两张表的关联字段名相同，也可以使用 <code>USING</code>子句来代替 <code>ON</code>，举个例子：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># join....on</span><br><span class="line"><span class="keyword">select</span> c.cust_name, o.order_num</span><br><span class="line"><span class="keyword">from</span> Customers c</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> Orders o</span><br><span class="line"><span class="keyword">on</span> c.cust_id <span class="operator">=</span> o.cust_id</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> c.cust_name;</span><br><span class="line"></span><br><span class="line"># 如果两张表的关联字段名相同，也可以使用<span class="keyword">USING</span>子句：join....using()</span><br><span class="line"><span class="keyword">select</span> c.cust_name, o.order_num</span><br><span class="line"><span class="keyword">from</span> Customers c</span><br><span class="line"><span class="keyword">inner</span> <span class="keyword">join</span> Orders o</span><br><span class="line"><span class="keyword">using</span>(cust_id)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> c.cust_name;</span><br></pre></td></tr></table></figure>

<p><strong><code>ON</code> 和 <code>WHERE</code> 的区别</strong>：</p>
<ul>
<li>连接表时，SQL 会根据连接条件生成一张新的临时表。<code>ON</code> 就是连接条件，它决定临时表的生成。</li>
<li><code>WHERE</code> 是在临时表生成以后，再对临时表中的数据进行过滤，生成最终的结果集，这个时候已经没有 JOIN-ON 了。</li>
</ul>
<p>所以总结来说就是：<strong>SQL 先根据 ON 生成一张临时表，然后再根据 WHERE 对临时表进行筛选</strong>。</p>
<p>SQL 允许在 <code>JOIN</code> 左边加上一些修饰性的关键词，从而形成不同类型的连接，如下表所示：</p>
<table>
<thead>
<tr>
<th>连接类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>INNER JOIN 内连接</td>
<td>（默认连接方式）只有当两个表都存在满足条件的记录时才会返回行。</td>
</tr>
<tr>
<td>LEFT JOIN &#x2F; LEFT OUTER JOIN 左(外)连接</td>
<td>返回左表中的所有行，即使右表中没有满足条件的行也是如此。</td>
</tr>
<tr>
<td>RIGHT JOIN &#x2F; RIGHT OUTER JOIN 右(外)连接</td>
<td>返回右表中的所有行，即使左表中没有满足条件的行也是如此。</td>
</tr>
<tr>
<td>FULL JOIN &#x2F; FULL OUTER JOIN 全(外)连接</td>
<td>只要其中有一个表存在满足条件的记录，就返回行。</td>
</tr>
<tr>
<td>SELF JOIN</td>
<td>将一个表连接到自身，就像该表是两个表一样。为了区分两个表，在 SQL 语句中需要至少重命名一个表。</td>
</tr>
<tr>
<td>CROSS JOIN</td>
<td>交叉连接，从两个或者多个连接表中返回记录集的笛卡尔积。</td>
</tr>
</tbody></table>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905103002.png"></p>
<p>如果不加任何修饰词，只写 <code>JOIN</code>，那么默认为 <code>INNER JOIIN</code></p>
<p>对于 <code>INNER JOIIN</code> 来说，还有一种隐式的写法，称为 “<strong>隐式内连接</strong>”，也就是没有 <code>INNER JOIIN</code> 关键字，使用 <code>WHERE</code> 语句实现内连接的功能。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 隐式内连接</span><br><span class="line"><span class="keyword">select</span> c.cust_name, o.order_num</span><br><span class="line"><span class="keyword">from</span> Customers c, Orders o</span><br><span class="line"><span class="keyword">where</span> c.cust_id <span class="operator">=</span> o.cust_id</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> c.cust_name;</span><br><span class="line"></span><br><span class="line"># 显式内连接</span><br><span class="line"><span class="keyword">select</span> c.cust_name, o.order_num</span><br><span class="line"><span class="keyword">from</span> Customers c <span class="keyword">inner</span> <span class="keyword">join</span> Orders o</span><br><span class="line"><span class="keyword">using</span>(cust_id)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> c.cust_name;</span><br></pre></td></tr></table></figure>

<h2 id="执行计划"><a href="#执行计划" class="headerlink" title="执行计划"></a>执行计划</h2><p><strong>执行计划</strong> 是指一条 SQL 语句在经过 <strong>MySQL 查询优化器</strong> 的优化会后，具体的执行方式。执行计划通常用于 SQL 性能分析、优化等场景。通过 <code>EXPLAIN</code> 的结果，可以了解到如数据表的查询顺序、数据查询操作的操作类型、哪些索引可以被命中、哪些索引实际会命中、每个数据表有多少行记录被查询等信息。</p>
<p>MySQL 为我们提供了 <code>EXPLAIN</code> 命令，来获取执行计划的相关信息。</p>
<p>需要注意的是，<code>EXPLAIN</code> 语句并不会真的去执行相关的语句，而是通过查询优化器对语句进行分析，找出最优的查询方案，并显示对应的信息。</p>
<p><code>EXPLAIN</code> 执行计划支持 <code>SELECT</code>、<code>DELETE</code>、<code>INSERT</code>、<code>REPLACE</code> 以及 <code>UPDATE</code> 语句。我们一般多用于分析 <code>SELECT</code> 查询语句，使用起来非常简单，语法如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN <span class="operator">+</span> <span class="keyword">SELECT</span> 查询语句；</span><br></pre></td></tr></table></figure>

<p>举个例子：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> explain <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> dept_emp <span class="keyword">WHERE</span> emp_no <span class="keyword">IN</span> (<span class="keyword">SELECT</span> emp_no <span class="keyword">FROM</span> dept_emp <span class="keyword">GROUP</span> <span class="keyword">BY</span> emp_no <span class="keyword">HAVING</span> <span class="built_in">COUNT</span>(emp_no)<span class="operator">&gt;</span><span class="number">1</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">----+-------------+----------+------------+-------+-----------------+---------+---------+------+--------+----------+-------------+</span></span><br><span class="line"><span class="operator">|</span> id <span class="operator">|</span> select_type <span class="operator">|</span> <span class="keyword">table</span>    <span class="operator">|</span> partitions <span class="operator">|</span> type  <span class="operator">|</span> possible_keys   <span class="operator">|</span> key     <span class="operator">|</span> key_len <span class="operator">|</span> <span class="keyword">ref</span>  <span class="operator">|</span> <span class="keyword">rows</span>   <span class="operator">|</span> filtered <span class="operator">|</span> Extra       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+-------------+----------+------------+-------+-----------------+---------+---------+------+--------+----------+-------------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">1</span> <span class="operator">|</span> <span class="keyword">PRIMARY</span>     <span class="operator">|</span> dept_emp <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">ALL</span>   <span class="operator">|</span> <span class="keyword">NULL</span>            <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span> <span class="keyword">NULL</span> <span class="operator">|</span> <span class="number">331143</span> <span class="operator">|</span>   <span class="number">100.00</span> <span class="operator">|</span> <span class="keyword">Using</span> <span class="keyword">where</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">2</span> <span class="operator">|</span> SUBQUERY    <span class="operator">|</span> dept_emp <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> index <span class="operator">|</span> <span class="keyword">PRIMARY</span>,dept_no <span class="operator">|</span> <span class="keyword">PRIMARY</span> <span class="operator">|</span> <span class="number">16</span>      <span class="operator">|</span> <span class="keyword">NULL</span> <span class="operator">|</span> <span class="number">331143</span> <span class="operator">|</span>   <span class="number">100.00</span> <span class="operator">|</span> <span class="keyword">Using</span> index <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+-------------+----------+------------+-------+-----------------+---------+---------+------+--------+----------+-------------+</span></span><br></pre></td></tr></table></figure>

<p>可以看到，执行计划结果中共有 12 列，各列代表的含义总结如下表：</p>
<table>
<thead>
<tr>
<th><strong>列名</strong></th>
<th><strong>含义</strong></th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>SELECT 查询的序列标识符</td>
</tr>
<tr>
<td>select_type</td>
<td>SELECT 关键字对应的查询类型</td>
</tr>
<tr>
<td>table</td>
<td>用到的表名</td>
</tr>
<tr>
<td>partitions</td>
<td>匹配的分区，对于未分区的表，值为 NULL</td>
</tr>
<tr>
<td>type</td>
<td>表的访问方法</td>
</tr>
<tr>
<td>possible_keys</td>
<td>可能用到的索引</td>
</tr>
<tr>
<td>key</td>
<td>实际用到的索引</td>
</tr>
<tr>
<td>key_len</td>
<td>所选索引的长度</td>
</tr>
<tr>
<td>ref</td>
<td>当使用索引等值查询时，与索引作比较的列或常量</td>
</tr>
<tr>
<td>rows</td>
<td>预计要读取的行数</td>
</tr>
<tr>
<td>filtered</td>
<td>按表条件过滤后，留存的记录数的百分比</td>
</tr>
<tr>
<td>Extra</td>
<td>附加信息</td>
</tr>
</tbody></table>
<h3 id="type（重要）"><a href="#type（重要）" class="headerlink" title="type（重要）"></a>type（重要）</h3><p>查询执行的类型，描述了查询是如何执行的。所有值的顺序从最优到最差排序为：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL</p>
<p>常见的几种类型具体含义如下：</p>
<ul>
<li><strong>system</strong>：如果表使用的引擎对于表行数统计是精确的（如：MyISAM），且表中只有一行记录的情况下，访问方法是 system ，是 const 的一种特例。</li>
<li><strong>const</strong>：表中最多只有一行匹配的记录，一次查询就可以找到，常用于使用主键或唯一索引的所有字段作为查询条件。</li>
<li><strong>eq_ref</strong>：当连表查询时，前一张表的行在当前这张表中只有一行与之对应。是除了 system 与 const 之外最好的 join 方式，常用于使用主键或唯一索引的所有字段作为连表条件。</li>
<li><strong>ref</strong>：使用普通索引作为查询条件，查询结果可能找到多个符合条件的行。</li>
<li><strong>index_merge</strong>：当查询条件使用了多个索引时，表示开启了 Index Merge 优化，此时执行计划中的 key 列列出了使用到的索引。</li>
<li><strong>range</strong>：对索引列进行范围查询，执行计划中的 key 列表示哪个索引被使用了。</li>
<li><strong>index</strong>：查询遍历了整棵索引树，与 ALL 类似，只不过扫描的是索引，而索引一般在内存中，速度更快。</li>
<li><strong>ALL</strong>：全表扫描。</li>
</ul>
<h3 id="Extra（重要）"><a href="#Extra（重要）" class="headerlink" title="Extra（重要）"></a>Extra（重要）</h3><p>这列包含了 MySQL 解析查询的额外信息，通过这些信息，可以更准确的理解 MySQL 到底是如何执行查询的。常见的值如下：</p>
<ul>
<li><strong>Using filesort</strong>：在排序时使用了外部的索引排序，没有用到表内索引进行排序。</li>
<li><strong>Using temporary</strong>：MySQL 需要创建临时表来存储查询的结果，常见于 ORDER BY 和 GROUP BY。</li>
<li><strong>Using index</strong>：表明查询使用了覆盖索引，不用回表，查询效率非常高。</li>
<li><strong>Using index condition</strong>：表示查询优化器选择使用了索引条件下推这个特性。</li>
<li><strong>Using where</strong>：表明查询使用了 WHERE 子句进行条件过滤。一般在没有使用到索引的时候会出现。</li>
<li>**Using join buffer (Block Nested Loop)**：连表查询的方式，表示当被驱动表的没有使用索引的时候，MySQL 会先将驱动表读出来放到 join buffer 中，再遍历被驱动表与驱动表进行查询。</li>
</ul>
<p>这里提醒下，当 Extra 列包含 Using filesort 或 Using temporary 时，MySQL 的性能可能会存在问题，需要尽可能避免</p>
<h1 id="连接和查询优化"><a href="#连接和查询优化" class="headerlink" title="连接和查询优化"></a>连接和查询优化</h1><h2 id="common-x2F-iterator"><a href="#common-x2F-iterator" class="headerlink" title="common&#x2F;iterator"></a>common&#x2F;iterator</h2><p>common&#x2F;iterator目录中包含一个称为BacktrackingIterator（回溯迭代器）的接口。实现这个接口的迭代器，可以在迭代期间标记一个点，并且通过重置到这个标记点。</p>
<p>举个例子：迭代[1,2,3]</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">BackTrackingIterator&lt;Integer&gt; iter = <span class="keyword">new</span> <span class="title class_">BackTrackingIteratorImplementation</span>();</span><br><span class="line">iter.next();     <span class="comment">// returns 1</span></span><br><span class="line">iter.next();     <span class="comment">// returns 2</span></span><br><span class="line">iter.markPrev(); <span class="comment">// marks the previously returned value, 2</span></span><br><span class="line">iter.next();     <span class="comment">// returns 3</span></span><br><span class="line">iter.hasNext();  <span class="comment">// returns false</span></span><br><span class="line">iter.reset();    <span class="comment">// reset to the marked value (line 5)</span></span><br><span class="line">iter.hasNext();  <span class="comment">// returns true</span></span><br><span class="line">iter.next();     <span class="comment">// returns 2</span></span><br><span class="line">iter.markNext(); <span class="comment">// mark the value to be returned next, 3</span></span><br><span class="line">iter.next();     <span class="comment">// returns 3</span></span><br><span class="line">iter.hasNext();  <span class="comment">// returns false</span></span><br><span class="line">iter.reset();    <span class="comment">// reset to the marked value (line 11)</span></span><br><span class="line">iter.hasNext();  <span class="comment">// returns true</span></span><br><span class="line">iter.next();     <span class="comment">// returns 3</span></span><br></pre></td></tr></table></figure>

<h2 id="query-x2F-QueryOperator-java"><a href="#query-x2F-QueryOperator-java" class="headerlink" title="query&#x2F;QueryOperator.java"></a>query&#x2F;QueryOperator.java</h2><blockquote>
<p>参考来源<a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/6314.6315">Join processing in database systems with large main memories</a></p>
</blockquote>
<p>query目录包含所谓的<strong>QueryOperator（查询运算符）</strong>。对数据库的单一查询可以表示为这些运算符的组合。所有操作符都扩展了QueryOperator类，并实现了Iterable&lt; Record &gt;接口。Scan Operators（扫描运算符）从一个表中获取数据。其余的运算符接受一个或多个输入运算符，对输入进行转换或组合（例如，投射列、排序、连接），并返回一个records的集合。</p>
<h3 id="Join-Operators"><a href="#Join-Operators" class="headerlink" title="Join Operators"></a>Join Operators</h3><p>JoinOperator.java是所有连接运算符的基类。实现连接算法时，不应该直接处理Table对象或TransactionContext对象（除了将它们传递到需要它们的方法中）。</p>
<h4 id="1-Nested-Loop-Joins（嵌套循环连接）"><a href="#1-Nested-Loop-Joins（嵌套循环连接）" class="headerlink" title="1. Nested Loop Joins（嵌套循环连接）"></a>1. Nested Loop Joins（嵌套循环连接）</h4><p>嵌套循环连接（Nested Loop Join）是一种最基本的连接实现算法。它先从<strong>外部表</strong>（驱动表）中获取满足条件的数据，然后为每一行数据遍历一次<strong>内部表</strong>（被驱动表），获取所有匹配的数据。值得注意的是，DBMS总是希望外部表是较小的表，这样在内存中缓存尽量多的外部表，在遍历内部表时也可以使用索引加速。</p>
<p><strong>1）Simple Nested Loop Join (SNLJ)</strong></p>
<p>SNLJ的简单之处在于实现起来简单，假设我们有两个表R(外)和S(内)，从R中取出record ri，然后从S中遍历，找出与之匹配的Sj，找到后返回连接后的record。伪代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for each record ri in R:</span><br><span class="line">    for each record sj in S:</span><br><span class="line">        if θ(ri,sj):</span><br><span class="line">            yield&lt;ri,sj&gt;</span><br></pre></td></tr></table></figure>

<p><strong>2）Page Nested Loop Join (PNLJ)</strong></p>
<p>SNLJ的弊端很明显，我们并不希望对S所有pages进行扫描，那么我们可以按page为大小来进行扫描。先从R中读取一个page，再从S中读取一个page，然后两个page之间匹配，如果S没有匹配完R的page，那么从S中获取下一个page，如此重复，即为<strong>页面嵌套循环连接</strong>(Page Nested Loop Join)。伪代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for each page pr in R:</span><br><span class="line">    for each page ps in S:</span><br><span class="line">        for each record ri in pr:</span><br><span class="line">            for each record sj in ps:</span><br><span class="line">                if θ(ri,sj):</span><br><span class="line">                    yield&lt;ri,sj&gt;</span><br></pre></td></tr></table></figure>

<p><strong>3）Block Nested Loop Join (BNLJ)</strong></p>
<p>PNLJ虽然对SNLJ进行了优化，但是没有充分利用buffer。假如我们有B个buffer pages，但PNLJ实际上只用了三个，一个给R，一个给S，一个是output buffer。由于我们希望尽可能减少S的读取次数，因此我们保留两个buffer pages给S和output buffer，其余B-2个pages全部分配给R。这就是<strong>块嵌套循环连接</strong>（Block Nested Loop Join），其核心思想在于，希望利用缓冲区来降低IO成本，因此我们为一个R中的块保留尽可能多的pages，每个块只在S的每个page读取一次，较大的块带来更低的IO。而对于R的每个块，将S中的所有records与块中所有records进行匹配。伪代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for each block of B-2 pages Br in R:</span><br><span class="line">    for each page ps in S:</span><br><span class="line">        for each record ri in Br:</span><br><span class="line">            for each record sj in ps:</span><br><span class="line">                if θ(ri,sj):</span><br><span class="line">                    yield&lt;ri,sj&gt;</span><br></pre></td></tr></table></figure>

<p>在实现中，需要关注以下三个方法：</p>
<ul>
<li><p><strong>fetchNextLeftBlock</strong>：从 leftSourceIterator 获取左表页面的下一个非空块。</p>
</li>
<li><p><strong>fetchNextRightPage</strong>：从 rightSourceIterator 获取右表的下一个非空页面。</p>
</li>
<li><p><strong>fetchNextRecord</strong>：获取连接输出的下一条record，并且要考虑以下四种情况：</p>
<ul>
<li><p>遍历完右page中的records，都没匹配上左block当前的record，获取左Block下一条record</p>
</li>
<li><p>遍历完右page中的records，左block中所有records没有与之匹配的，获取右表中的下一个page</p>
</li>
<li><p>遍历完右表中的records，左block中所有records没有与之匹配的，获取左表中的下一个block</p>
</li>
<li><p>两表剩下的records都匹配不上</p>
</li>
</ul>
</li>
</ul>
<p><strong>4）Index Nested Loop Join(INLJ)</strong></p>
<p>虽然该数据库并不实现INLJ，但是可以介绍一下。有时候BNLJ并不是最好的方法，比如说S上有一个索引，而这个索引刚好在我们要连接的字段上，此时在S中查找匹配的字段就会非常快，这被称为<strong>索引嵌套循环连接</strong>(Index Nested Loop Join)，其伪代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for each record ri in R:</span><br><span class="line">    for each record sj in S where θ(ri,sj)==true:</span><br><span class="line">        yield&lt;ri,sj&gt;</span><br></pre></td></tr></table></figure>

<h4 id="2-Hash-Joins（哈希连接）"><a href="#2-Hash-Joins（哈希连接）" class="headerlink" title="2. Hash Joins（哈希连接）"></a>2. Hash Joins（哈希连接）</h4><p>由于hash函数可以只通过一次运算就将任意键值映射到固定大小、固定值域的hash值，因此也是一种实现连接的方法。在实践中，针对等值 join 所需的等值比较，一般数据库系统会仔细选择和优化 hash 函数或函数簇，使其能够快速缩小需要和一个键值进行等值比较的其它键值的数量或范围，从而实现了通过减少计算量、内外存访问量等手段来降低 join 算法的执行开销。</p>
<p><strong>1）Simple Hash Join (SHJ)</strong></p>
<p>一般分为两步，建立阶段（build phase)和探测阶段（probe phase)：</p>
<ul>
<li><strong>Build</strong>：选择两个表中较小的一个，即外部表R（一般称其为build relation），使用一个或一簇 hash 函数将其中的每一条record中连接两张表的那一列的值计算为一个 hash 值，然后根据 hash 值将该record插入到一张表中，这张表就叫做 hash 表。</li>
<li><strong>Probe</strong>：选择两个表中较大的一个，即内部表S（一般称为probe relation），针对其中的每一条record，使用和 build 中相同的 hash 函数，计算出相应的 hash 值，然后根据 hash 值在 hash 表中寻找到需要比较的record，逐一比较，如果找到匹配项则输出。</li>
</ul>
<p><strong>2）Grace Hash Join (GHJ)</strong></p>
<p>假如R的哈希表太大，内存放不下，DBMS可能会随机将哈希表页换出，性能将大打折扣。所以我们要考虑对其进行分区。</p>
<p>首先对两个表进行分区，然后对连接两张表的那一列的值进行哈希处理，并将其添加到正确的分区中。最后对指定的分区执行<strong>Build</strong>和<strong>Probe</strong>，如果该分区不能执行（getNumPages()大于B - 2，即超出约束的内存），则需要递归地应用GHJO来进一步来划分分区直至能执行<strong>Build</strong>和<strong>Probe</strong>为止。</p>
<h4 id="3-External-Sort"><a href="#3-External-Sort" class="headerlink" title="3. External Sort"></a>3. External Sort</h4><p><strong>Sort Merge Join</strong>的第一步是对两个输入关系进行排序。因此，在实现Sort Merge Join 之前，必须首先实现外部排序算法。</p>
<p>下面和代码中提及的“run”，仅仅是外部合并排序中已排序的records的序列。这在 SortOperator 中由 Run 类表示。由于外部合并排序中的runs可以跨越许多页（并最终跨越整个表），因此 Run 类不会将其所有数据保留在内存中。相反，它创建一个临时表并将其所有数据写入临时表（由缓冲区管理器自行决定将其具体化到磁盘）。</p>
<p>需要实现的核心方法如下：</p>
<ul>
<li><p>**sortRun(run)**：在内存中对传入的数据进行排序。</p>
</li>
<li><p>**mergeSortedRuns(runs)**：在给定排序后的runs列表的情况下返回新run。</p>
</li>
<li><p>**mergePass(runs)**：执行外部合并排序的单个合并过程，给出前一个过程中所有已排序runs的列表。</p>
</li>
<li><p>**sort()**：从头到尾运行外部合并排序，并返回最终运行的排序数据。</p>
</li>
</ul>
<h4 id="4-Sort-Merge-Join"><a href="#4-Sort-Merge-Join" class="headerlink" title="4. Sort Merge Join"></a>4. Sort Merge Join</h4><p>有时我们希望连接表在指定列上进行排序，此时<strong>排序合并连接</strong> (Sort Merge Join)就十分有用。首先对R和S进行排序，排序完后：</p>
<ul>
<li><p>对于R和S中的records，如果ri &lt; sj，那么优先遍历R；如果ri &gt; sj，那么优先遍历S。即两者小的先遍历，直到匹配成功。</p>
</li>
<li><p>假设上面匹配成功，那么我们得到&lt; ri, sj &gt;，我们对sj这个点进行标记**marked(S)**。然后检查紧随其后的records(sj, sj+1, sj+2, etc)，直到我们找到与ri不匹配的record（即读取S中所有和ri匹配的records）。</p>
</li>
<li><p>现在我们可以读取R的下一条record，并且S回溯到marked(S)，重新进行步骤1。由于R和S都是有序的，因此R中未来任何records如果成功匹配，就不可能是与 marked(S) 之前的records匹配成功。</p>
</li>
</ul>
<p>其伪代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">do &#123;</span><br><span class="line">    if (!mark) &#123;</span><br><span class="line">        while (r &lt; s) &#123; advance r &#125;</span><br><span class="line">        while (r &gt; s) &#123; advance s &#125;</span><br><span class="line">        // mark start of “block” of S</span><br><span class="line">        mark = s</span><br><span class="line">     &#125;</span><br><span class="line">    if (r == s) &#123;</span><br><span class="line">        result = &lt;r, s&gt;</span><br><span class="line">        advance s</span><br><span class="line">        yield result</span><br><span class="line">    &#125;</span><br><span class="line">    else &#123;</span><br><span class="line">        reset s to mark</span><br><span class="line">        advance r</span><br><span class="line">        mark = NULL</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>为简单起见，实现SMJ不应该对其进行优化（排序的最终合并过程与连接同时发生）。因此，在SMJ的排序阶段应该使用SortOperator进行排序。需要实现 <strong>SortMergeOperator</strong> 以及其内部类 <strong>SortMergeIterator</strong> 。此外提一嘴，其合并体现在有序records的合并。</p>
<h3 id="Scan-Operators"><a href="#Scan-Operators" class="headerlink" title="Scan Operators"></a>Scan Operators</h3><p>扫描运算符用于直接从表中获取数据。</p>
<p><strong>SequentialScanOperator.java</strong>：用来获取表名并提供该表包含所有records的迭代器。<strong>IndexScanOperator.java</strong>：用来获取表名、列名、PredicateOperator (&gt;、&lt;、&lt;&#x3D;、&gt;&#x3D;、&#x3D;) 和一个值。指定的列必须有索引才能使该运算符起作用。如果有索引，索引扫描将利用索引有效地生成该列中满足给定谓词和值（例如 salaries.yearid &gt;&#x3D; 2000）的records。</p>
<h3 id="Special-Operators"><a href="#Special-Operators" class="headerlink" title="Special Operators"></a>Special Operators</h3><p>其余的运算符不属于特定类别，而是执行某些特定目的。</p>
<p><strong>​SelectOperator.java</strong>：相当于关系代数的 σ 运算符。该运算符获取列名、PredicateOperator（&gt;、&lt;、&lt;&#x3D;、&gt;&#x3D;、&#x3D;、!&#x3D;）和一个值。它只会从满足谓词的源运算符生成records，例如 (yearid &gt;&#x3D; 2000)。</p>
<p><strong>ProjectOperator.java</strong>：相当于关系代数的π运算符。该运算符获取列名列表并过滤掉未列出的任何列。</p>
<p><strong>​SortOperator.java</strong>：按排序顺序从源运算符中生成records。</p>
<h3 id="Other-Operators"><a href="#Other-Operators" class="headerlink" title="Other Operators"></a>Other Operators</h3><p><strong>​MaterializeOperator.java</strong>：将源运算符物化（存储）到临时表中，然后对临时表进行顺序扫描。主要用于测试控制IO何时发生。</p>
<p><strong>GroupByOperator.java</strong>：该运算符接收列名并生成源运算符的records，但records按其值分组，并且每个record由标记record分隔。例如，如果源运算符具有单例record[0,1,2,1,2,0,1]，则 group by 运算符可能会生成 [0,0,M,1,1,1,M,2,2]其中 M 是标记record。</p>
<h2 id="query-x2F-QueryPlan"><a href="#query-x2F-QueryPlan" class="headerlink" title="query&#x2F;QueryPlan"></a>query&#x2F;QueryPlan</h2><p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo20230628101842.png"></p>
<p>这是<strong>火山模型</strong>(volcano model)，其中运算符彼此分层，每个运算符在需要生成下一个输出元组时向输入运算符请求元组。请注意，每个运算符仅根据需要从其输入运算符中获取元组，而不是一次全部获取！</p>
<p><strong>QueryPlan</strong>是查询运算符的组合，它描述了查询的执行方式。回想一下，SQL 是一种声明性语言，即用户不指定查询如何运行，而只指定查询应返回什么。因此，对于给定的查询通常有许多可能的查询计划。</p>
<p>QueryPlan类代表一个查询。数据库的用户使用公共方法（例如 join()、select() 等）创建查询，然后调用执行来生成查询的查询计划，并返回结果数据集上的迭代器（这不是完全具体化：迭代器根据请求生成每个元组）。</p>
<h3 id="SelectPredicate"><a href="#SelectPredicate" class="headerlink" title="SelectPredicate"></a>SelectPredicate</h3><p>SelectPredicate 是 QueryPlan.java 中的一个辅助类，它存储有关用户已应用的选择谓词的信息，例如someTable.col1 &lt; 186。选择谓词有四个可以访问的值：</p>
<ul>
<li><p>tableName和columnName指定谓词适用于哪个表的哪一列。</p>
</li>
<li><p>运算符表示正在使用的运算符的类型（例如 &lt;、&lt;&#x3D;、&gt; 等…）。</p>
</li>
<li><p>value 是一个 DataBox，其中包含一个常量值，应根据该常量值对列进行评估（在上面的示例中，该值是 186）。</p>
</li>
</ul>
<p>查询涉及到的所有选择谓词都存储在 selectPredicates 实例变量中。</p>
<h3 id="JoinPredicate"><a href="#JoinPredicate" class="headerlink" title="JoinPredicate"></a>JoinPredicate</h3><p>JoinPredicate 是 QueryPlan.java 中的一个辅助类，它存储有关表连接在一起的条件的信息，例如：leftTable.leftColumn &#x3D; rightTable.rightColumn。该数据库中的所有联接都是等值联接。 JoinPredicates 有五个值：</p>
<ul>
<li><p>joinTable：要加入的表之一的名称，仅用于 toString()。</p>
</li>
<li><p>leftTable：等式左边的表名。</p>
</li>
<li><p>leftColumn：等式左边的列名。</p>
</li>
<li><p>rightTable：等式右边的表名。</p>
</li>
<li><p>rightColumn：等式右边的列名。</p>
</li>
</ul>
<p>查询涉及到的所有连接谓词都存储在 joinPredicates 实例变量中。</p>
<h2 id="Query-Optimization"><a href="#Query-Optimization" class="headerlink" title="Query Optimization"></a>Query Optimization</h2><p>首先看如下流程图：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo20230630101454.png"></p>
<p>前面说过，一个QueryPlan只是一个操作序列，比如上面，它将两个表连接在一起，然后过滤掉行，最后仅投影它想要的列。这种方式能保证获取正确的查询结果，但事实上，数据库可能并不按照这样的顺序工作，它会改变操作的执行顺序，已获得最佳性能。在这里，我们用IO次数来衡量性能，查询优化就是找到一个IO次数最小的QueryPlan。</p>
<h3 id="Common-Heuristics-启发式"><a href="#Common-Heuristics-启发式" class="headerlink" title="Common Heuristics(启发式)"></a>Common Heuristics(启发式)</h3><p>对于复杂的查询而言，查询计划太多无法全部分析。因此我们需要某种方法来减少我们实际考虑的计划数量，所以我们需要使用一些启发式规则：</p>
<ul>
<li><p>对于projects(π)和selects(σ)尽可能往下推（pass），即投影运算和选择运算尽可能先做</p>
</li>
<li><p>仅考虑left deep plans</p>
</li>
<li><p>不考虑cross joins，除非这是唯一选择</p>
</li>
</ul>
<p>对于第一条启发式规则，之所以要先做投影运算和选择运算，这是为了减少其他运算符要处理的pages数目。project消除了列，select减少了要查询的行数，这样一来行变小了，在一个page上能装下更多行，要处理的pages也减少了。</p>
<p>对于第二条启发式规则，仅考虑left deep plans中的left deep plans是指一个连接中所有的右表都是基表的计划（即右边永远不是连接本身的结果，只能是原始表之一），如下图给出了什么是left deep plans，什么不是left deep plans：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo20230630154731.png"></p>
<p>仅考虑left deep plans的好处在于，一是可以大大减少计划空间。计划空间是关系数的阶乘，仅考虑left deep plans比起考虑每个计划时计划空间要小得多。二是这些计划可以被完全流水线化，这意味着我们可以将页面一个一个地传递给下一个连接操作者——我们实际上不需要将连接的结果写入磁盘。</p>
<p>对于第三条启发式规则，不使用cross joins是因为cross joins会产生大量的pages，这使得cross joins上面的运算符要执行许多IO，这无疑是高成本的。</p>
<h3 id="Single-Table-Access-Selection（Pass-1）"><a href="#Single-Table-Access-Selection（Pass-1）" class="headerlink" title="Single Table Access Selection（Pass 1）"></a>Single Table Access Selection（Pass 1）</h3><p>想要实现优化，先考虑单表的情况。在SimpleDB中，只考虑两种类型的表扫描：全表顺序扫描（SequentialScanOperator）和索引扫描（IndexScanOperator），后者需要一个索引和对列的过滤谓词。</p>
<p>首先要计算顺序扫描的预估I&#x2F;O成本，因为我们默认首选顺序扫描。然后，如果表的任一索引在选择谓词所应用的列上，计算对该列进行索引扫描的预估I&#x2F;O成本。如果其中有任何一个比顺序扫描更有效，就选择最好的一个。</p>
<p>根据I&#x2F;O成本，选择如下：</p>
<ol>
<li><p>Full Scan players (100 I&#x2F;Os)</p>
</li>
<li><p>Index Scan players.age (90 I&#x2F;Os)</p>
</li>
<li><p>Index Scan players.teamid (120 I&#x2F;Os)</p>
</li>
<li><p>Full Scan teams (300 I&#x2F;Os)</p>
</li>
<li><p>Index Scan teams.record (400 I&#x2F;Os)</p>
</li>
</ol>
<p>当然还有基于启发式规则的优化，即</p>
<ul>
<li><p>对于小关系，使用全表顺序扫描，即使选择列上有索引。</p>
</li>
<li><p>对于大关系，如果选择条件是“主码&#x3D;值”的查询，查询结果最多是一个元组，可以选择主码索引。</p>
</li>
<li><p>对于大关系，如果选择条件是“非主属性&#x3D;值”的查询，并且选择列上有索引，则要估算查询结果的元组数目，如果比例较小(&lt;10%)则使用索引扫描方法，否则就使用全表顺序扫描。</p>
</li>
<li><p>对于大关系，如果选择条件是属性上的非等值查询或者范围查询，并且选择列上有索引，同样要估算查询结果的元组数目，如果选择率&lt;10%可以使用索引扫描方法，否则使用全表顺序扫描。</p>
</li>
<li><p>对于大关系，如果用AND连接的合取选择条件，有设计这些属性的组合索引，则优先采用组合索引扫描方法；如果某些属性上有一般索引，则可以用索引扫描方法，否则使用全表顺序扫描。</p>
</li>
<li><p>对于大关系，如果用OR连接的析取选择条件，一般使用全表顺序扫描。</p>
</li>
</ul>
<p><strong>QueryOperator</strong>中有一个stimateIOCost方法，用来估计执行此查询运算符的 IO 成本，在子类中会实现，在实现<strong>QueryPlan</strong>的<strong>minCostSingleAccess</strong>方法时会用到。</p>
<h3 id="Join-Selection-Pass-i-gt-1"><a href="#Join-Selection-Pass-i-gt-1" class="headerlink" title="Join Selection (Pass i &gt; 1)"></a>Join Selection (Pass i &gt; 1)</h3><p>对于每一个pass i，我们尝试将i个表连接在一起，使用pass i-1和pass 1的结果。例如，在pass 2时，我们将尝试将两个表连接在一起，每个表都来自pass 2。在pass 5时，我们将尝试将总共5个表连接在一起。我们将从pass 4中得到其中的4张表（它知道如何将4张表连接在一起），我们将从pass 1中得到剩余的表。请注意，这执行了我们的left deep plans启发式。我们总是用一个基础表来连接一组连接的表。</p>
<p>Pass i将为所有长度为i的表集产生至少一个查询计划，这些表集可以在没有交叉连接的情况下被连接（假设至少有一个这样的表集）。就像在pass 1中一样，它将推进每个集合的最优计划，以及每个集合的每个interesting顺序的最优计划（如果存在）。当试图用pass 1的一张表连接一组表时，我们考虑数据库已经实现每个连接。</p>
<p>这些连接中只有一个会产生排好序的输出——SMJ，所以要想有一个interesting的顺序，唯一的办法就是对这组中的最后一个连接使用SMJ。SMJ的输出将根据连接条件中的列进行排序。</p>
<p>然而，SNLJ和INLJ都可以保留左边关系的排序顺序。因为这两种方法在转移到左边关系的下一个元组之前对左边关系的单个元组执行了所有的连接，所以左边关系的排序被保留了。</p>
<p>GHJ、PNLJ和BNLJ从未产生interesting的顺序。GHJ的输出顺序是基于探测关系中元组的顺序，因为我们遍历了探测关系中的每个元组以便在另一个关系的内存哈希表中找到匹配。然而，由于探测关系本身已经通过哈希进行了分区，所以不能保证探测关系在各分区中是否有序，从而不能保证输出的整体顺序。PNLJ和BNLJ类似于SNLJ，但是它们在转到左边关系中的下一个元组之前不会生成左边关系中单个元组的所有连接输出。相反，它们从左侧关系中读取元组的范围，并在这些范围上与右侧关系中的元组块进行匹配，所以它们不保留顺序。</p>
<p>举个例子：</p>
<p>SELECT *<br>from a inner join b<br>ON A.aid &#x3D; B.bid<br>INNER JOIN C<br>ON b.did &#x3D; c.cid<br>ORDER BY c.cid；</p>
<p>在pass 2中，我们将返回哪些表集的查询计划？在这一pass中，我们将考虑的唯一表集是{A，B}和{B，C}。因为没有连接条件，所以我们不考虑{A, C}，并且我们的启发式规则也规定不要使用交叉连接。为了简化问题，假设数据库中只实现了SMJ和BNLJ，并且pass 1只为每个表返回一个全表扫描。将考虑的以下连接（成本是为问题而制定的。在实践中，将使用选择性估计和连接成本公式）：</p>
<ol>
<li><p>A BNLJ B (估计成本：1000)</p>
</li>
<li><p>B BNLJ A (估计成本：1500)</p>
</li>
<li><p>A SMJ B (估计成本：2000)</p>
</li>
<li><p>B BNLJ C (估计成本：800)</p>
</li>
<li><p>C BNLJ B (估计成本：600)</p>
</li>
<li><p>C SMJ B (估计费用：1000)</p>
</li>
</ol>
<p>连接1、5和6将被推进。1是集合{A，B}的最佳连接。5对集合{B，C}来说是最优的。6是一个interesting的顺序，因为有一个ORDER BY c.cid。之所以不推进3，是因为A.aid和B.bid在这个连接之后没有被使用，所以这个顺序并不interesting。</p>
<p>现在让我们进入pass 3。我们将考虑以下的连接（同样是连接成本的构成）：</p>
<p>join1 {A，B} BNLJ C (估计成本：10,000)</p>
<p>join1 {A，B} SMJ C (估计成本：12,000)</p>
<p>join5 {B，C} BNLJ A (估计成本：8,000)</p>
<p>join5 {B，C} SMJ A (估计成本：20,000)</p>
<p>join6 {B，C} BNLJ A (估计成本：22,000)</p>
<p>join6 {B，C} SMJ A (估计成本：18,000)</p>
<p>注意，现在我们不能改变连接顺序，因为我们只考虑left deep plan，所以基础表必须在右边。</p>
<p>现在唯一能推进的计划是2和3。对于所有3个表的集合来说，3是最佳的整体。2对于所有3个表的集合来说是最优的，在C.cid上有一个interesting的顺序（这仍然是interesting的，因为我们还没有评估ORDER BY子句）。2产生在C.cid上排序的输出的原因是连接条件是B.did &#x3D; C.cid，所以输出将在B.did和C.cid上排序（因为它们是一样的）。4和6不会产生在C.cid上排序的输出，因为它们将把A加入到连接表的集合中，所以条件将是A.aid &#x3D; B.bid。A.aid和B.bid都没有在查询的其他地方使用，所以它们的排序对我们来说没有意义。</p>
<p>对于i&gt;1，动态编程算法的第i次传递吸收了所有可能的i-1个连接表的最优计划（除了那些涉及笛卡尔积的），并返回所有可能的i个连接表的最优计划（同样不包括那些笛卡尔积的）。</p>
<p>我们将两次传递之间的状态表示为从字符串集（表名）到相应的最优查询操作器的映射。需要实现<strong>QueryPlan</strong>的<strong>minCostJoins</strong>方法，以实现上述搜索算法的第i遍（i&gt;1）的逻辑。</p>
<p>该方法给定一个从i-1个表的集合到连接这些i-1个表的最佳计划的映射，返回一个从i个表的集合到连接所有i个表的集合的最佳左深计划的映射（除了那些有笛卡尔积）。当用户调用QueryPlan的join方法时，应添加的显式连接条件列表来识别潜在的连接。</p>
<h3 id="Optimal-Plan-Selection"><a href="#Optimal-Plan-Selection" class="headerlink" title="Optimal Plan Selection"></a>Optimal Plan Selection</h3><p>最后的最后，要实现optimizer的最外层驱动方法——QueryPlan中的execute方法。该方法会利用到前面实现的两个方法，并且需要添加剩余的group by和project运算符，这些运算符是查询的一部分，但是还没添加到查询计划中。值得注意的是，QueryPlan中的表被保存在变量tableNames中。</p>
<h1 id="MySQL并发控制"><a href="#MySQL并发控制" class="headerlink" title="MySQL并发控制"></a>MySQL并发控制</h1><h2 id="事务及其特性"><a href="#事务及其特性" class="headerlink" title="事务及其特性"></a>事务及其特性</h2><p>假设这么一种情况，我的银行余额为100元，现在要向朋友B转账50元，那么转账完之后我的银行余额应该少了50元，朋友B的余额多了50元。但是转账这个过程涉及到一系列操作，从数据库读取我的数据，修改我的余额，读取朋友B的数据，修改朋友B的余额。假如在修改朋友B的余额这个步骤，银行的系统崩溃了，这时候系统重启后，我的钱确实被扣了，但我的转账却没到账。</p>
<p>为了解决这种问题，我们要确保数据库的操作是不可分割的，要么全部执行成功 ，要么全部失败，不允许出现中间状态的数据。因此我们提出了<strong>事务</strong>这一概念，即用户定义的一个数据库操作序列，要么做要么不做，不存在你中间状态，是一个不可分割的工作单位。定义事务的语句一般有三条：<strong>BEGIN TRANSACTION、COMMIT、ROLLBACK</strong>，事务通常是以BEGIN TRANSACTION开始，以COMMIT或ROLLBACK结束。COMMIT是提交，即提交事务的所有操作。而ROLLBACK是回滚，即事务不能继续执行，将已经完成的操作全部撤销，回滚到事务开始时的状态。</p>
<p>事务可以是一条SQL语句、一组SQL语句或者整个程序。事务有四个特性：<strong>原子性</strong>、<strong>一致性</strong>、<strong>隔离性</strong>、<strong>持续性</strong>。</p>
<ul>
<li><strong>原子性（Atomicity）</strong>：事务中的操作要么做要么不做。</li>
<li><strong>一致性（Consistency）</strong>：数据库必须从一个一致性状态变到另一个一致性状态，当数据库只包含成功事务提交的结果时称该数据库处于一致性状态。</li>
<li><strong>隔离性（Isolation）</strong>：一个事务的执行不能被其他事务干扰。</li>
<li><strong>持续性（Durability）</strong>：也称永久性，事务一旦提交，它对数据库中的数据的改变是永久性的。</li>
</ul>
<p>InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？</p>
<ul>
<li>持久性是通过 redo log （重做日志）来保证的；</li>
<li>原子性是通过 undo log（回滚日志） 来保证的；</li>
<li>隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；</li>
<li>一致性则是通过持久性+原子性+隔离性来保证；</li>
</ul>
<p>这里我们将重点讨论事务的隔离性。</p>
<h2 id="事务的隔离性"><a href="#事务的隔离性" class="headerlink" title="事务的隔离性"></a>事务的隔离性</h2><p>假设有多个事务同时在执行，对某一数据进行读写，则会产生以下问题：</p>
<ul>
<li><p><strong>脏读</strong>：读到其他事务未提交的数据；</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905203206.png"></p>
</li>
<li><p><strong>不可重复读</strong>：前后读取的数据不一致；</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905203220.png"></p>
</li>
<li><p><strong>幻读</strong>：前后读取的记录数量不一致。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905203240.png"></p>
</li>
</ul>
<p>这三个现象的严重性排序如下：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905201656.png"></p>
<p>SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下：</p>
<ul>
<li><strong>读未提交（<em>read uncommitted</em>）</strong>：指一个事务还没提交时，它做的变更就能被其他事务看到；</li>
<li><strong>读提交（<em>read committed</em>）</strong>：指一个事务提交之后，它做的变更才能被其他事务看到；</li>
<li><strong>可重复读（<em>repeatable read</em>）</strong>：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，<strong>MySQL InnoDB 引擎的默认隔离级别</strong>；</li>
<li><strong>串行化（<em>serializable</em> ）</strong>：会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；</li>
</ul>
<p>按隔离水平高低排序如下：</p>
<p><img src="https://cdn.xiaolincoding.com//mysql/other/cce766a69dea725cd8f19b90db2d0430.png" alt="图片"></p>
<table>
<thead>
<tr>
<th>隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody><tr>
<td>READ-UNCOMMITTED</td>
<td>√</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>READ-COMMITTED</td>
<td>×</td>
<td>√</td>
<td>√</td>
</tr>
<tr>
<td>REPEATABLE-READ</td>
<td>×</td>
<td>×</td>
<td>√</td>
</tr>
<tr>
<td>SERIALIZABLE</td>
<td>×</td>
<td>×</td>
<td>×</td>
</tr>
</tbody></table>
<p>不同的数据库厂商对 SQL 标准中规定的 4 种隔离级别的支持不一样，有的数据库只实现了其中几种隔离级别，<strong>我们讨论的 MySQL 虽然支持 4 种隔离级别，但是与SQL标准中规定的各级隔离级别允许发生的现象却有些出入</strong>。</p>
<p>MySQL 在「可重复读」隔离级别下，可以很大程度上避免幻读现象的发生（注意是很大程度避免，并不是彻底避免），所以 MySQL 并不会使用「串行化」隔离级别来避免幻读现象的发生，因为使用「串行化」隔离级别会影响性能。</p>
<p>InnoDB 实现的 「可重复读」隔离级别，解决幻读问题发生方法主要有两种：</p>
<ul>
<li><p>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong>，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</p>
</li>
<li><p>针对<strong>当前读</strong>（select … for update 等语句），是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong>，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。</p>
</li>
</ul>
<p>举个具体，有一张账户余额表，里面有一条账户余额为 100 万的记录。然后有两个并发的事务，事务 A 只负责查询余额，事务 B 则会将我的余额改成 200 万，下面是按照时间顺序执行两个事务的行为：</p>
<p><img src="https://cdn.xiaolincoding.com//mysql/other/d5de450e901ed926d0b5278c8b65b9fe.png" alt="图片"></p>
<p>在不同隔离级别下，事务 A 执行过程中查询到的余额可能会不同：</p>
<ul>
<li>在「读未提交」隔离级别下，事务 B 修改余额后，虽然没有提交事务，但是此时的余额已经可以被事务 A 看见了，于是事务 A 中余额 V1 查询的值是 200 万，余额 V2、V3 自然也是 200 万了；</li>
<li>在「读提交」隔离级别下，事务 B 修改余额后，因为没有提交事务，所以事务 A 中余额 V1 的值还是 100 万，等事务 B 提交完后，最新的余额数据才能被事务 A 看见，因此额 V2、V3 都是 200 万；</li>
<li>在「可重复读」隔离级别下，事务 A 只能看见启动事务时的数据，所以余额 V1、余额 V2 的值都是 100 万，当事务 A 提交事务后，就能看见最新的余额数据了，所以余额 V3 的值是 200 万；</li>
<li>在「串行化」隔离级别下，事务 B 在执行将余额 100 万修改为 200 万时，由于此前事务 A 执行了读操作，这样就发生了读写冲突，于是就会被锁住，直到事务 A 提交后，事务 B 才可以继续执行，所以从 A 的角度看，余额 V1、V2 的值是 100 万，余额 V3 的值是 200万。</li>
</ul>
<p>这四种隔离级别具体是如何实现的呢？</p>
<ul>
<li>对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；</li>
<li>对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；</li>
<li>对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 <strong>Read View</strong>来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个<strong>数据快照</strong>，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。</li>
</ul>
<p>注意，执行「开始事务」命令，并不意味着启动了事务。在 MySQL 有两种开启事务的命令，分别是：</p>
<ul>
<li>第一种：begin&#x2F;start transaction 命令；</li>
<li>第二种：start transaction with consistent snapshot 命令；</li>
</ul>
<p>这两种开启事务的命令，事务的启动时机是不同的：</p>
<ul>
<li>执行了 begin&#x2F;start transaction 命令后，并不代表事务启动了。只有在执行这个命令后，执行了增删查改操作的 SQL 语句，才是事务真正启动的时机；</li>
<li>执行了 start transaction with consistent snapshot 命令，就会马上启动事务。</li>
</ul>
<p>MySQL 中并发事务的控制方式无非就两种：<strong>锁</strong> 和 <strong>MVCC</strong>。锁可以看作是悲观控制的模式，多版本并发控制（MVCC，Multiversion concurrency control）可以看作是乐观控制的模式。</p>
<h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><p>MVCC 是一种并发控制机制，用于在多个并发事务同时读写数据库时保持数据的一致性和隔离性。它是通过在每个数据行上维护多个版本的数据来实现的。当一个事务要对数据库中的数据进行修改时，MVCC 会为该事务创建一个数据快照，而不是直接修改实际的数据行。</p>
<p>1、读操作（SELECT）：</p>
<p>当一个事务执行读操作时，它会使用快照读取。快照读取是基于事务开始时数据库中的状态创建的，因此事务不会读取其他事务尚未提交的修改。具体工作情况如下：</p>
<ul>
<li>对于读取操作，事务会查找符合条件的数据行，并选择符合其事务开始时间的数据版本进行读取。</li>
<li>如果某个数据行有多个版本，事务会选择不晚于其开始时间的最新版本，确保事务只读取在它开始之前已经存在的数据。</li>
<li>事务读取的是快照数据，因此其他并发事务对数据行的修改不会影响当前事务的读取操作。</li>
</ul>
<p>2、写操作（INSERT、UPDATE、DELETE）：</p>
<p>当一个事务执行写操作时，它会生成一个新的数据版本，并将修改后的数据写入数据库。具体工作情况如下：</p>
<ul>
<li>对于写操作，事务会为要修改的数据行创建一个新的版本，并将修改后的数据写入新版本。</li>
<li>新版本的数据会带有当前事务的版本号，以便其他事务能够正确读取相应版本的数据。</li>
<li>原始版本的数据仍然存在，供其他事务使用快照读取，这保证了其他事务不受当前事务的写操作影响。</li>
</ul>
<p>3、事务提交和回滚：</p>
<ul>
<li>当一个事务提交时，它所做的修改将成为数据库的最新版本，并且对其他事务可见。</li>
<li>当一个事务回滚时，它所做的修改将被撤销，对其他事务不可见。</li>
</ul>
<p>4、版本的回收：</p>
<p>为了防止数据库中的版本无限增长，MVCC 会定期进行版本的回收。回收机制会删除已经不再需要的旧版本数据，从而释放空间。</p>
<p>MVCC 通过创建数据的多个版本和使用快照读取来实现并发控制。读操作使用旧版本数据的快照，写操作创建新版本，并确保原始版本仍然可用。这样，不同的事务可以在一定程度上并发执行，而不会相互干扰，从而提高了数据库的并发性能和数据一致性。</p>
<h4 id="MVCC的实现"><a href="#MVCC的实现" class="headerlink" title="MVCC的实现"></a>MVCC的实现</h4><p><code>MVCC</code> 的实现依赖于：<strong>隐藏字段、Read View、undo log</strong>。在内部实现中，<code>InnoDB</code> 通过数据行的 <code>DB_TRX_ID</code> 和 <code>Read View</code> 来判断数据的可见性，如不可见，则通过数据行的 <code>DB_ROLL_PTR</code> 找到 <code>undo log</code> 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 <code>Read View</code> 之前已经提交的修改和该事务本身做的修改。</p>
<p><strong>隐藏字段</strong></p>
<p>在内部，<code>InnoDB</code> 存储引擎为每行数据添加了三个 <a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/refman/5.7/en/innodb-multi-versioning.html">隐藏字段</a>：</p>
<ul>
<li><code>DB_TRX_ID（6字节）</code>：表示最后一次插入或更新该行的事务 id。此外，<code>delete</code> 操作在内部被视为更新，只不过会在记录头 <code>Record header</code> 中的 <code>deleted_flag</code> 字段将其标记为已删除。</li>
<li><code>DB_ROLL_PTR（7字节）</code> 回滚指针，指向该行的 <code>undo log</code> 。如果该行未被更新，则为空。</li>
<li><code>DB_ROW_ID（6字节）</code>：如果没有设置主键且该表没有唯一非空索引时，<code>InnoDB</code> 会使用该 id 来生成聚簇索引。</li>
</ul>
<p><strong>ReadView</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReadView</span> &#123;</span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="type">trx_id_t</span> m_low_limit_id;      <span class="comment">/* 大于等于这个 ID 的事务均不可见 */</span></span><br><span class="line"></span><br><span class="line">  <span class="type">trx_id_t</span> m_up_limit_id;       <span class="comment">/* 小于这个 ID 的事务均可见 */</span></span><br><span class="line"></span><br><span class="line">  <span class="type">trx_id_t</span> m_creator_trx_id;    <span class="comment">/* 创建该 Read View 的事务ID */</span></span><br><span class="line"></span><br><span class="line">  <span class="type">trx_id_t</span> m_low_limit_no;      <span class="comment">/* 事务 Number, 小于该 Number 的 Undo Logs 均可以被 Purge */</span></span><br><span class="line"></span><br><span class="line">  <span class="type">ids_t</span> m_ids;                  <span class="comment">/* 创建 Read View 时的活跃事务列表 */</span></span><br><span class="line"></span><br><span class="line">  m_closed;                     <span class="comment">/* 标记 Read View 是否 close */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>Read View</code> 主要是用来做可见性判断，里面保存了“当前对本事务不可见的其他活跃事务”。<strong>“活跃事务”指的就是，启动了但还没提交的事务</strong>。</p>
<p>主要有以下字段：</p>
<ul>
<li><code>m_low_limit_id</code>：目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见。</li>
<li><code>m_up_limit_id</code>：活跃事务列表 <code>m_ids</code> 中最小的事务 ID，如果 <code>m_ids</code> 为空，则 <code>m_up_limit_id</code> 为 <code>m_low_limit_id</code>。小于这个 ID 的数据版本均可见。</li>
<li><code>m_ids</code>：<code>Read View</code> 创建时其他未提交的活跃事务 ID 列表。创建 <code>Read View</code>时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。<code>m_ids</code> 不包括当前事务自己和已提交的事务（正在内存中）。</li>
<li><code>m_creator_trx_id</code>：创建该 <code>Read View</code> 的事务 ID。</li>
</ul>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905204513.png"></p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905204745.png"></p>
<p><strong>undo-log</strong></p>
<p><code>undo log</code> 主要有两个作用：</p>
<ul>
<li>当事务回滚时用于将数据恢复到修改前的样子.</li>
<li>另一个作用是 <code>MVCC</code> ，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 <code>undo log</code> 读取之前的版本数据，以此实现非锁定读。</li>
</ul>
<p>在 <code>InnoDB</code> 存储引擎中 <code>undo log</code> 分为两种：<code>insert undo log</code> 和 <code>update undo log</code>：</p>
<ul>
<li><p>**<code>insert undo log</code>**：指在 <code>insert</code> 操作中产生的 <code>undo log</code>。因为 <code>insert</code> 操作的记录只对事务本身可见，对其他事务不可见，故该 <code>undo log</code> 可以在事务提交后直接删除。不需要进行 <code>purge</code> 操作。</p>
</li>
<li><p>**<code>update undo log</code>**：<code>update</code> 或 <code>delete</code> 操作中产生的 <code>undo log</code>。该 <code>undo log</code>可能需要提供 <code>MVCC</code> 机制，因此不能在事务提交时就进行删除。提交时放入 <code>undo log</code> 链表，等待 <code>purge线程</code> 进行最后的删除。</p>
</li>
</ul>
<h4 id="read-committed和repeatable-read的差异"><a href="#read-committed和repeatable-read的差异" class="headerlink" title="read committed和repeatable read的差异"></a>read committed和repeatable read的差异</h4><p>前面提到，对于<strong>read committed(简称rc)</strong> 和 <strong>repeatable read(简称rr)</strong> 隔离级别的事务来说，它们是通过<strong>Read View</strong>来实现的，它们的区别在于创建 Read View 的时机不同。</p>
<p>举个例子：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905205828.png"></p>
<h5 id="read-committed"><a href="#read-committed" class="headerlink" title="read committed"></a>read committed</h5><p><strong>假设时间线来到T4</strong>，那么此时数据行 id &#x3D; 1 的版本链为：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905205902.png"></p>
<p>由于 RC 级别下每次查询都会生成<code>Read View</code> ，并且事务 101、102 并未提交，此时 <code>103</code> 事务生成的 <code>Read View</code> 中活跃的事务 <strong><code>m_ids</code> 为：[101,102]</strong> ，<code>m_low_limit_id</code>为：104，<code>m_up_limit_id</code>为：101，<code>m_creator_trx_id</code> 为：103。</p>
<ul>
<li>此时最新记录的 <code>DB_TRX_ID</code> 为 101，m_up_limit_id &lt;&#x3D; 101 &lt; m_low_limit_id，所以要在 <code>m_ids</code> 列表中查找，发现 <code>DB_TRX_ID</code> 存在列表中，那么这个记录不可见。</li>
<li>根据 <code>DB_ROLL_PTR</code> 找到 <code>undo log</code> 中的上一版本记录，上一条记录的 <code>DB_TRX_ID</code> 还是 101，不可见。</li>
<li>继续找上一条 <code>DB_TRX_ID</code>为 1，满足 1 &lt; m_up_limit_id，可见，所以事务 103 查询到数据为 <code>name = 菜花</code>。</li>
</ul>
<p><strong>时间线来到T6</strong> ，数据的版本链为：</p>
<p><img src="https://javaguide.cn/assets/528559e9-dae8-4d14-b78d-a5b657c88391-2ff79120.png"></p>
<p>因为在 RC 级别下，重新生成 <code>Read View</code>，这时事务 101 已经提交，102 并未提交，所以此时 <code>Read View</code> 中活跃的事务 <strong><code>m_ids</code>：[102]</strong> ，<code>m_low_limit_id</code>为：104，<code>m_up_limit_id</code>为：102，<code>m_creator_trx_id</code>为：103</p>
<ul>
<li><p>此时最新记录的 <code>DB_TRX_ID</code> 为 102，m_up_limit_id &lt;&#x3D; 102 &lt; m_low_limit_id，所以要在 <code>m_ids</code> 列表中查找，发现 <code>DB_TRX_ID</code> 存在列表中，那么这个记录不可见</p>
</li>
<li><p>根据 <code>DB_ROLL_PTR</code> 找到 <code>undo log</code> 中的上一版本记录，上一条记录的 <code>DB_TRX_ID</code> 为 101，满足 101 &lt; m_up_limit_id，记录可见，所以在 <code>T6</code> 时间点查询到数据为 <code>name = 李四</code>，与时间 T4 查询到的结果不一致，不可重复读！</p>
</li>
</ul>
<p><strong>时间线来到T9</strong>，数据的版本链为：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905210440.png"></p>
<p>重新生成 <code>Read View</code>， 这时事务 101 和 102 都已经提交，所以 <strong>m_ids</strong> 为空，则 m_up_limit_id &#x3D; m_low_limit_id &#x3D; 104，最新版本事务 ID 为 102，满足 102 &lt; m_low_limit_id，可见，查询结果为 <code>name = 赵六</code>。</p>
<p><strong>总结：</strong> <strong>在 RC 隔离级别下，事务在每次查询开始时都会生成并设置新的 Read View，所以导致不可重复读</strong>。</p>
<h5 id="repeatable-read"><a href="#repeatable-read" class="headerlink" title="repeatable read"></a>repeatable read</h5><p><strong>在T4情况</strong>下的版本链为：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905225107.png"></p>
<p>在当前执行 <code>select</code> 语句时生成一个 <code>Read View</code>，此时 <strong><code>m_ids</code>：[101,102]</strong> ，<code>m_low_limit_id</code>为：104，<code>m_up_limit_id</code>为：101，<code>m_creator_trx_id</code> 为：103</p>
<p>此时和 RC 级别下一样：</p>
<ul>
<li>最新记录的 <code>DB_TRX_ID</code> 为 101，m_up_limit_id &lt;&#x3D; 101 &lt; m_low_limit_id，所以要在 <code>m_ids</code> 列表中查找，发现 <code>DB_TRX_ID</code> 存在列表中，那么这个记录不可见</li>
<li>根据 <code>DB_ROLL_PTR</code> 找到 <code>undo log</code> 中的上一版本记录，上一条记录的 <code>DB_TRX_ID</code> 还是 101，不可见</li>
<li>继续找上一条 <code>DB_TRX_ID</code>为 1，满足 1 &lt; m_up_limit_id，可见，所以事务 103 查询到数据为 <code>name = 菜花</code></li>
</ul>
<p><strong>时间点T6</strong>情况下：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230905225241.png"></p>
<p>在 RR 级别下只会生成一次<code>Read View</code>，所以此时依然沿用 <strong><code>m_ids</code>：[101,102]</strong> ，<code>m_low_limit_id</code>为：104，<code>m_up_limit_id</code>为：101，<code>m_creator_trx_id</code> 为：103</p>
<ul>
<li><p>最新记录的 <code>DB_TRX_ID</code> 为 102，m_up_limit_id &lt;&#x3D; 102 &lt; m_low_limit_id，所以要在 <code>m_ids</code> 列表中查找，发现 <code>DB_TRX_ID</code> 存在列表中，那么这个记录不可见</p>
</li>
<li><p>根据 <code>DB_ROLL_PTR</code> 找到 <code>undo log</code> 中的上一版本记录，上一条记录的 <code>DB_TRX_ID</code> 为 101，不可见</p>
</li>
<li><p>继续根据 <code>DB_ROLL_PTR</code> 找到 <code>undo log</code> 中的上一版本记录，上一条记录的 <code>DB_TRX_ID</code> 还是 101，不可见</p>
</li>
<li><p>继续找上一条 <code>DB_TRX_ID</code>为 1，满足 1 &lt; m_up_limit_id，可见，所以事务 103 查询到数据为 <code>name = 菜花</code></p>
</li>
</ul>
<p><strong>时间点T9</strong>情况下：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906095625.png"></p>
<p>此时情况跟 T6 完全一样，由于已经生成了 <code>Read View</code>，此时依然沿用 <strong><code>m_ids</code>：[101,102]</strong> ，所以查询结果依然是 <code>name = 菜花</code></p>
<p><strong>总结：在RR隔离级别下，只会在事务开始后第一次读取数据时生成一个 Read View（m_ids 列表），所以解决不可重复读的问题</strong>。</p>
<h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>在 MySQL 里，根据加锁的范围，可以分为<strong>全局锁、表级锁和行锁</strong>三类。</p>
<p>全局锁顾名思义，就是对整个数据库上锁，执行以下指令：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flush tables <span class="keyword">with</span> read lock</span><br></pre></td></tr></table></figure>

<p>执行后，整个数据库处于<strong>只读状态</strong>，全局锁主要应用于做<strong>全库逻辑备份</strong>，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。但这样做会于阻塞当前业务，无法对数据进行更新。好在InnoDB 存储引擎默认的事务隔离级别是可重复读，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，因此可以采用这种方式来备份数据库。但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。</p>
<p>此外，MyISAM 仅仅支持表级锁(table-level locking)，一锁就锁整张表，这在并发写的情况下性非常差。InnoDB 不光支持表级锁(table-level locking)，还支持行级锁(row-level locking)，默认为行级锁。</p>
<p>行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。</p>
<p><strong>表级锁和行级锁对比</strong>：</p>
<ul>
<li><strong>表级锁：</strong> MySQL 中锁定粒度最大的一种锁（全局锁除外），是针对非索引字段加的锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。不过，触发锁冲突的概率最高，高并发下效率极低。表级锁和存储引擎无关，MyISAM 和 InnoDB 引擎都支持表级锁。</li>
<li><strong>行级锁：</strong> MySQL 中锁定粒度最小的一种锁，是 <strong>针对索引字段加的锁</strong> ，只针对当前操作的行记录进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。行级锁和存储引擎有关，是在存储引擎层面实现的。</li>
</ul>
<h4 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h4><p>MySQL 里面表级别的锁有这几种：</p>
<ul>
<li>表锁；</li>
<li>元数据锁（MDL）;</li>
<li>意向锁；</li>
<li>AUTO-INC 锁；</li>
</ul>
<p><strong>表锁</strong></p>
<p>如果我们想对学生表（t_student）加表锁，可以使用下面的命令：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>表级别的共享锁，也就是读锁；</span><br><span class="line">lock tables t_student read;</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>表级别的独占锁，也就是写锁；</span><br><span class="line">lock tables t_stuent write;</span><br></pre></td></tr></table></figure>

<p>需要注意的是，表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。</p>
<p>也就是说如果本线程对学生表加了「共享表锁」，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放。</p>
<p>要释放表锁，可以使用下面这条命令，会释放当前会话的所有表锁：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unlock tables</span><br></pre></td></tr></table></figure>

<p>另外，当会话退出后，也会释放所有表锁。不过尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能。</p>
<p><strong>元数据锁</strong></p>
<p>我们不需要显式的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：</p>
<ul>
<li>对一张表进行 CRUD 操作时，加的是 <strong>MDL 读锁</strong>；</li>
<li>对一张表做结构变更操作的时候，加的是 <strong>MDL 写锁</strong>；</li>
</ul>
<p>MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。</p>
<p>当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。</p>
<p>反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。</p>
<p>MDL 是在事务提交后才会释放，这意味着<strong>事务执行期间，MDL 是一直持有的</strong>。</p>
<p>那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：</p>
<ol>
<li>首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；</li>
<li>然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；</li>
<li>接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，</li>
</ol>
<p>那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。</p>
<p>那么为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？这是因为申请 MDL 锁的操作会形成一个队列，队列中<strong>写锁获取优先级高于读锁</strong>，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。</p>
<p>所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。</p>
<p><strong>意向锁</strong></p>
<p>所谓意向锁：</p>
<ul>
<li>在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「<strong>意向共享锁IS</strong>」；</li>
<li>在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「<strong>意向独占锁IX</strong>」；</li>
</ul>
<p>也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。</p>
<p>不过，select 也是可以对记录加共享锁和独占锁的，具体方式如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>先在表上加上意向共享锁，然后对读取的记录加共享锁</span><br><span class="line"><span class="keyword">select</span> ... lock <span class="keyword">in</span> share mode;</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>先表上加上意向独占锁，然后对读取的记录加独占锁</span><br><span class="line"><span class="keyword">select</span> ... <span class="keyword">for</span> <span class="keyword">update</span>;</span><br></pre></td></tr></table></figure>

<p><strong>意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（<em>lock tables … read</em>）和独占表锁（<em>lock tables … write</em>）发生冲突。</strong></p>
<p>表锁和行锁是满足读读共享、读写互斥、写写互斥的。如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。</p>
<p>那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。</p>
<p>所以，<strong>意向锁的目的是为了快速判断表里是否有记录被加锁</strong>。</p>
<p><strong>AUTO-INC锁</strong></p>
<p>表里的主键通常都会设置成自增的，这是通过对主键字段声明 <code>AUTO_INCREMENT</code> 属性实现的。之后在插入数据时，可以不指定主键的值，数据库会自动给主键的值递增，这主要是通过 <strong>AUTO-INC 锁</strong>实现的。</p>
<p>AUTO-INC 锁是特殊的表锁机制，锁<strong>不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。在插入数据时，会加一个表级别的 AUTO-INC 锁</strong>，然后为被 <code>AUTO_INCREMENT</code> 修饰的字段的值递增，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。</p>
<p>那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 <code>AUTO_INCREMENT</code> 修饰的字段的值是连续递增的。但是， AUTO-INC 锁在对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。</p>
<p>因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种<strong>轻量级的锁</strong>来实现自增。一样也是在插入数据的时候，会为被 <code>AUTO_INCREMENT</code> 修饰的字段加上轻量级锁，<strong>然后给该字段的值递增，接着就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁</strong>。</p>
<p>InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。</p>
<ul>
<li>当 innodb_autoinc_lock_mode &#x3D; 0，就采用 AUTO-INC 锁，语句执行结束后才释放锁；</li>
<li>当 innodb_autoinc_lock_mode &#x3D; 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。</li>
<li>当 innodb_autoinc_lock_mode &#x3D; 1：<ul>
<li>普通 insert 语句，自增锁在申请之后就马上释放；</li>
<li>类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；</li>
</ul>
</li>
</ul>
<p>当 innodb_autoinc_lock_mode &#x3D; 2 是性能最高的方式，但是当搭配 binlog 的日志格式是 statement 一起使用的时候，在「主从复制的场景」中会发生<strong>数据不一致的问题</strong>。</p>
<p>举个例子：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906115738.png"></p>
<p>session A 往表 t 中插入了 4 行数据，然后创建了一个相同结构的表 t2，然后<strong>两个 session 同时执行向表 t2 中插入数据</strong>。</p>
<p>如果 innodb_autoinc_lock_mode &#x3D; 2，意味着「申请自增主键后就释放锁，不必等插入语句执行完」。那么就可能出现这样的情况：</p>
<ul>
<li>session B 先插入了两个记录，(1,1,1)、(2,2,2)；</li>
<li>然后，session A 来申请自增 id 得到 id&#x3D;3，插入了（3,5,5)；</li>
<li>之后，session B 继续执行，插入两条记录 (4,3,3)、 (5,4,4)。</li>
</ul>
<p>可以看到，<strong>session B 的 insert 语句，生成的 id 不连续</strong>。</p>
<p>当「主库」发生了这种情况，binlog 面对 t2 表的更新只会记录这两个 session 的 insert 语句，如果 binlog_format&#x3D;statement，记录的语句就是原始语句。记录的顺序要么先记 session A 的 insert 语句，要么先记 session B 的 insert 语句。</p>
<p>但不论是哪一种，这个 binlog 拿去「从库」执行，这时从库是按「顺序」执行语句的，只有当执行完一条 SQL 语句后，才会执行下一条 SQL。因此，在<strong>从库上「不会」发生像主库那样两个 session 「同时」执行向表 t2 中插入数据的场景。所以，在备库上执行了 session B 的 insert 语句，生成的结果里面，id 都是连续的。这时，主从库就发生了数据不一致</strong>。</p>
<p>要解决这问题，binlog 日志格式要设置为 row，这样在 binlog 里面记录的是主库分配的自增值，到备库执行的时候，主库的自增值是什么，从库的自增值就是什么。</p>
<p>所以，<strong>当 innodb_autoinc_lock_mode &#x3D; 2 时，并且 binlog_format &#x3D; row，既能提升并发性，又不会出现数据一致性问题</strong>。</p>
<h4 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h4><p>InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。前面也提到，普通的 select 语句是不会对记录加锁的，因为它属于快照读。如果要在查询时对记录加行锁，可以使用下面这两个方式，这种查询会加锁的语句称为<strong>锁定读</strong>。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span>对读取的记录加共享锁</span><br><span class="line"><span class="keyword">select</span> ... lock <span class="keyword">in</span> share mode;</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span>对读取的记录加独占锁</span><br><span class="line"><span class="keyword">select</span> ... <span class="keyword">for</span> <span class="keyword">update</span>;</span><br></pre></td></tr></table></figure>

<p>上面这两条语句必须在一个事务中，<strong>因为当事务提交了，锁就会被释放</strong>，所以在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit &#x3D; 0。</p>
<p>共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906150318.png"></p>
<p>行级锁的类型主要有三类：</p>
<ul>
<li>Record Lock，记录锁，也就是仅仅把一条记录锁上；</li>
<li>Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；</li>
<li>Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。</li>
</ul>
<p><strong>Record Lock</strong></p>
<p>Record Lock 称为记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的：</p>
<ul>
<li>当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;</li>
<li>当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。</li>
</ul>
<p>举个例子，当一个事务执行了下面这条语句：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql <span class="operator">&gt;</span> <span class="keyword">begin</span>;</span><br><span class="line">mysql <span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_test <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span> <span class="keyword">for</span> <span class="keyword">update</span>;</span><br></pre></td></tr></table></figure>

<p>就是对 t_test 表中主键 id 为 1 的这条记录加上 X 型的记录锁，这样其他事务就无法对这条记录进行修改了。当事务执行 commit 后，事务过程中生成的锁都会被释放。</p>
<p><strong>Gap Lock</strong></p>
<p>Gap Lock 称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象。</p>
<p>假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id &#x3D; 4 这条记录了，这样就有效的防止幻读现象的发生。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906150536.png"></p>
<p>间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，<strong>间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的</strong>。</p>
<p><strong>Next- Key Lock</strong></p>
<p>Next-Key Lock 称为临键锁，是 Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。</p>
<p>假设，表中有一个范围 id 为（3，5] 的 next-key lock，那么其他事务即不能插入 id &#x3D; 4 记录，也不能修改 id &#x3D; 5 这条记录。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906150659.png"></p>
<p>所以，next-key lock 即能保护该记录，又能阻止其他事务将新纪录插入到被保护记录前面的间隙中。</p>
<p><strong>next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的</strong>。比如，一个事务持有了范围为 (1, 10] 的 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，就会被阻塞。</p>
<p>虽然相同范围的间隙锁是多个事务相互兼容的，但对于记录锁，我们是要考虑 X 型与 S 型关系，X 型的记录锁与 X 型的记录锁是冲突的。</p>
<p><strong>插入意向锁</strong></p>
<p>一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。如果有的话，插入操作就会发生<strong>阻塞</strong>，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个<strong>插入意向锁</strong>，表明有事务想在某个区间插入新记录，但是现在处于等待状态。</p>
<p>举个例子，假设事务 A 已经对表加了一个范围 id 为（3，5）间隙锁。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906150836.png"></p>
<p>当事务 A 还没提交的时候，事务 B 向该表插入一条 id &#x3D; 4 的新记录，这时会判断到插入的位置已经被事务 A 加了间隙锁，于是事物 B 会生成一个插入意向锁，然后将锁的状态设置为等待状态（<em>PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁</em>），此时事务 B 就会发生阻塞，直到事务 A 提交了事务。</p>
<p>插入意向锁名字虽然有意向锁，但是它并<strong>不是意向锁，它是一种特殊的间隙锁，属于行级别锁</strong>。如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。</p>
<p>插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。</p>
<h1 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h1><h2 id="Transactions"><a href="#Transactions" class="headerlink" title="Transactions"></a>Transactions</h2><p>事务中涉及的操作有： <strong>Begin</strong>, <strong>Read</strong>, <strong>Write</strong>, <strong>Commit</strong> 和 <strong>Abort</strong>。确保隔离最简单的方法就是在开始下一个事务之前，将当前事务中的所有操作完成，即<strong>串行时间表</strong>。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo20230709214624.png"></p>
<p>理想情况下，我们既希望获得与串行调度相同的结果（因为已知串行调度是正确的），又希望获得并行调度的优秀性能。基本上，我们正在寻找一个相当于串行时间表的时间表。为了使时间表等效，它们必须满足以下三个规则：</p>
<ul>
<li><p>它们涉及相同的事务。</p>
</li>
<li><p>在各个事务中操作的排序方式相同。</p>
</li>
<li><p>每个时间表都能使数据库保持在相同的状态。</p>
</li>
</ul>
<p>如果我们找到一个其结果相当于串行调度的调度，我们称该调度为<strong>可串行化的</strong>。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo20230709215052.png"></p>
<p>一个调度Sc在保证冲突操作的次序不变的情况下，通过交换两个事务不冲突操作的次序得到另一个调度Sc’，如果Sc’是串行的，称调度Sc为<strong>冲突可串行化的调度</strong>。若一个调度是冲突可串行化，则一定是可串行化的调度。可以用这种方法来判断一个调度是否是冲突可串行化。要使两个操作发生冲突，它们必须满足以下三个规则：</p>
<ul>
<li><p>这些操作来自不同的事务。</p>
</li>
<li><p>两个操作都在同一资源上运行。</p>
</li>
<li><p>至少有一个操作是写操作。</p>
</li>
</ul>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo20230709215520.png"></p>
<h2 id="Locking"><a href="#Locking" class="headerlink" title="Locking"></a>Locking</h2><p>实现并发控制有很多方法，常见的有<strong>封锁(locking)<strong>、</strong>时间戳(timestamp)<strong>、</strong>乐观控制法(optimisitc scheduler)</strong> 和 **多版本并发控制(MVCC)**。这里详细介绍封锁locking，封锁就是事务T在对某个数据对象操作之前，先向系统发出请求，对其加锁。加锁后事务T就对该数据对象有了一定控制，在事务T释放它的锁之前，其他事务不能更新此数据对象。封锁类型又分为：</p>
<ul>
<li><strong>排他锁（写锁）</strong>：若事务T对数据对象A加上X锁，则只允许T读取和修改A，其他任何事务都不能再对A加任何类型的锁，直到T释放A上的锁为止。</li>
<li><strong>共享锁（读锁）</strong>：若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁为止。</li>
</ul>
<p>不过上锁不意味着万事大吉，假设事务T1给数据R1上锁，事务T2给数据R2上锁。此时T1访问R2，T2访问R1。T1等待T2给R2解锁，T2又在等待T1给R1解锁。T1和T2两个事务永远不能结束，这就形成了<strong>死锁</strong>。在操作系统中，同时满足以下四个条件即可引起死锁：</p>
<ul>
<li><p><strong>互斥</strong>：线程对于需要的资源进行互斥的访问（例如一个线程抢到锁）。</p>
</li>
<li><p><strong>持有并等待</strong>：线程持有了资源（例如已将持有的锁），同时又在等待其他资源（例如，需要获得的锁）。</p>
</li>
<li><p><strong>非抢占</strong>：线程获得的资源（例如锁），不能被抢占。</p>
</li>
<li><p><strong>循环等待</strong>：线程之间存在一个环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的。</p>
</li>
</ul>
<p>回到数据库系统中，预防死锁并不适合数据库系统（会造成许多事务的中止），因此数据库一般采用<strong>诊断与解除死锁</strong>的方法。诊断的方法如下：</p>
<ul>
<li><p><strong>超时法</strong>：如果一个事务的等待时间超过了规定的时限，就认为发生了死锁（缺点是可能误判或者是时限设置太长死锁发生后不能及时发现）。</p>
</li>
<li><p><strong>等待图法</strong>：事务等待图是一个有向图G&#x3D;(T,U)，T是结点的集合，每个结点表示正运行的事务；U是边的集合，每条边表示事务等待的情况。若T2等待T1，则在T1、T2之间画一条有向边，从T2指向T1。并发控制子系统周期性地（比如每隔数秒）生成事务等待图，并进行检测。如果发现图中存在回路，则表示系统中出现了死锁。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230717215654.png"></p>
</li>
</ul>
<p>而解除死锁的方法则是选择一个处理死锁代价最小的事务，将其撤销，释放此事务所持有的所有的锁，使其他事务得以继续运行下去。</p>
<p>为保证并发调度的正确性，数据库管理系统的并发控制机制必须提供一定的额手段来保证调度是可串行化的，因此采用<strong>Two Phase Locking，即两段锁协议</strong>。所谓两段锁协议是指所有事务必须分两个阶段对数据项上锁和解锁。</p>
<ul>
<li>事务在读取之前必须获取 S（共享）锁，在写入之前必须获取 X（排他）锁。</li>
<li>在释放一个封锁之后，事务不再申请和获得任何其他封锁。</li>
</ul>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230717214359.png"></p>
<p>不过上面的两段锁协议存在弊端，比如说它不能防止级联中止，举个例子：</p>
<p>T1更新资源A，然后释放A上的锁；T2读取资源A；T1中止；此时T2也应该中止，因为它读取了A中uncommitted的值。</p>
<p>为了解决这个问题，我们将使用<strong>Strict Two Phase Locking</strong>。Strict Two Phase Locking和Two Phase Locking的不同之处在于，前者会在事务完成时会一起释放所有锁。</p>
<p>现在我们知道了锁的用途以及锁的类型。接下来我们就要了解<strong>Lock Manager</strong>如何管理锁定和解锁（或获取和释放）请求以及它如何决定何时授予锁定。Lock Manager会维护一个哈希表，以被锁定资源的名称为键。每个条目都包含一个授予集（一组授予的锁&#x2F;持有每个资源锁的事务）、锁类型（S 或 X 或我们尚未介绍的类型）和一个等待队列（由于与已授予的锁冲突而无法满足的锁请求队列）。参见下图：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230717220036.png"></p>
<p>当锁请求到达时，Lock Manager检查授予集中或等待队列中是否有任何 Xact 想要冲突锁。如果有，则请求者被放入等待队列。如果没有，则请求者被授予锁并放入授予集中。此外，Xacts 可以请求锁升级：此时具有共享锁的 Xact 可以请求升级为排他锁。Lock Manager会将此升级请求添加到队列的前面。</p>
<p>最后，当我们了解了锁的概念，我们还要弄清楚实际要上锁的内容。我们想要锁定包含我们想要写入的数据的元组吗？还是page？还是table？或者甚至可能是整个数据库，以便在我们处理该数据库时没有事务可以写入该数据库？我们做出的决定会根据我们所处的情况而有很大不同。这就是我们要讨论的<strong>Lock Granularity</strong>，即<strong>锁的颗粒度</strong>。让我们将数据库系统想象成下面的树：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230717220654.png"></p>
<p>最顶层是数据库。下一级是tables，后面是table的pages。最后，表中的records是树中的最低层级。请记住，当我们在一个节点上放置锁时，我们也隐式地锁定了它的所有子节点。因此，可以看到我们如何向数据库系统指定我们真正希望将锁放置在哪个层级。这种多颗粒度的锁允许我们在树的不同层级放置锁。我们将有以下新的lock modes：</p>
<ul>
<li><p><strong>IS</strong>：意图以更细的颗粒度获取 S 锁。</p>
</li>
<li><p><strong>IX</strong>：意图以更细的颗粒度获取 X 锁。注意：两个事务可以在同一资源上放置 IX 锁，此时它们并不会直接冲突，它们可以在两个不同的子事务上放置 X 锁。</p>
</li>
<li><p><strong>SIX</strong>：像S和IX的结合。如果我们想要阻止任何其他事务修改较低层级的资源但希望允许它们读取较低层级的资源，那么这非常有用。使用SIX，我们在这个层级声明了一个共享锁；现在，没有其他事务可以对该子树中的任何内容声明排他锁（但是，它可能可以对该事务未修改的内容声明共享锁，即我们不会放置 X 锁的内容。这留给数据库系统来处理。）</p>
</li>
</ul>
<p> lock modes之间的兼容性如下图所示：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230717221801.png"></p>
<p>既然有了Lock Granularity，我们也可以对前面的Two Phase Locking进行改造，获得<strong>Multiple Granularity Locking Protocol</strong>：</p>
<ul>
<li><p>每个 Xact 必须从层次结构的根节点开始。</p>
</li>
<li><p>要获得节点上的 S 或 IS ，必须在父节点上持有 IS 或 IX。</p>
</li>
<li><p>要在节点上获取 X 或 IX ，必须在父节点上保留 IX 或 SIX。</p>
</li>
<li><p>必须按自下而上的顺序释放锁。</p>
</li>
<li><p>必须满足两端锁协议和兼容性规定。</p>
</li>
<li><p>协议是正确的，因为它相当于直接在层次结构的叶层级设置锁。</p>
</li>
</ul>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><h3 id="Layers"><a href="#Layers" class="headerlink" title="Layers"></a>Layers</h3><p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230719144028.png"></p>
<ul>
<li><p><strong>LockManager</strong>：管理所有的锁，将每个资源视为独立的（不考虑资源的层次结构）。LockManager负责排队逻辑，必要时阻塞事务或解除阻塞，并且LockManager是事务是否拥有某个锁的唯一权威证明。如果说LockManager说T1拥有X(database)，那么T1就拥有这个锁。</p>
</li>
<li><p><strong>LockContext</strong>：在每一个LockManager上面都有一个LockContext对象集合，每个LockContext代表一个可锁定对象（可以是page，也可以是table）。LockContext对象根据层次结构连接（例如，表的 LockContext 将数据库上下文作为父对象，将其页面上下文作为子对象）。所有 LockContext 对象都共享一个 LockManager，每个上下文都会对其方法执行多粒度约束（例如，如果事务试图请求 X(table)而不请求 IX(database)，就会出现异常）。</p>
</li>
<li><p><strong>LockUtil</strong>：顾名思义，LockUtil是一个工具类，位于 LockContext 对象集合之上，负责获取数据库使用的每个 S 或 X 请求所需的所有意向锁（例如，如果请求 S(page)，该层将负责请求 IS(database)，必要时请求 IS(table)）。</p>
</li>
</ul>
<h3 id="Queuing"><a href="#Queuing" class="headerlink" title="Queuing"></a>Queuing</h3><h4 id="LockType"><a href="#LockType" class="headerlink" title="LockType"></a>LockType</h4><p>一个事务中的锁有如下类型：</p>
<ul>
<li><p>**S(A)**：可以读取A以及A的所有后代。</p>
</li>
<li><p>**X(A)**：可以读写A以及A的所有后代。</p>
</li>
<li><p>**IS(A)**：可以请求A的所有后代的共享锁和意向共享锁。</p>
</li>
<li><p>**IX(A)**：可以请求A的所有后代的锁。</p>
</li>
<li><p>**SIX(A)**：可以执行S(A)或IX(A)允许它执行的任何操作，除了请求 A 的后代上的 S、IS 或 SIX锁，因为这将是多余的（这与前文提及的SIX有出入，前文的SIX可以请求A的子节点上的SIX锁，而这里不允许这样做，这是因为SIX子节点的S是多余的）。</p>
</li>
</ul>
<p>需要实现以下方法：</p>
<ul>
<li><p><strong>compatible(A,B)</strong> 检查A锁和B锁是否兼容——两个事务对于同一资源，是否能一个事务拥有A锁而另一个事务拥有B锁？例如两个事务可以在同一资源上拥有 S 锁，所以 compatible(S, S) &#x3D; true，但两个事务不能在同一资源上拥有 X 锁，所以 compatible(X, X) &#x3D; false。</p>
</li>
<li><p><strong>canBeParentLock(A,B)</strong> 如果资源上的A锁允许事务获取子资源上的B锁，则返回 true。例如，要在表上获得S锁，我们必须（至少）在表的父表（即数据库）上拥有 IS 锁。因此，canBeParentLock(IS, S) &#x3D; true。</p>
</li>
<li><p><strong>substitutable(substitute,required)</strong> 检查是否可以用一种锁（”替代”）代替另一种锁（”必需”）。只有当拥有substitute的事务能做拥有required的事务能做的所有事情时，才会出现这种情况。换而言之，当一个事务请求所需的锁，如果我们偷偷给它替代锁，会有问题吗？例如，如果一个事务请求 X 锁，而我们悄悄给了它一个 S 锁，那么如果该事务试图写入资源，就会出现问题。因此，substitutable(S, X) &#x3D; false。</p>
</li>
</ul>
<h4 id="LockManager"><a href="#LockManager" class="headerlink" title="LockManager"></a>LockManager</h4><p>需要实现以下方法：</p>
<ul>
<li><strong>acquireAndRelease</strong> 该方法以原子的形式（从用户的角度）获取一个锁并释放零个或多个锁。该方法优先于任何排队的请求（即使有队列，它也应该继续进行，如果无法继续，则将其放置在队列的前面）。</li>
<li><strong>acquire</strong> 该方法是LockManager的标准获取方法。它允许事务请求一个锁，如果没有队列并且该请求与现有锁兼容，则授予该请求。否则，它应该将请求放入队列（在后面）并阻止事务。我们不允许隐式锁升级，因此在事务已经拥有 S 锁的资源上请求 X 锁是无效的。</li>
<li><strong>release</strong> 该方法是LockManager的标准释放方法。它允许事务释放它持有的一个锁。</li>
<li><strong>promote</strong> 此方法允许事务显式提升&#x2F;升级持有的锁。事务用更强的锁对该资源持有的锁进行替换。该方法优先于任何排队的请求（即使有队列，它也应该继续进行，如果无法继续，则将其放置在队列的前面）。要注意的是，我们不允许升级到 SIX，该类型的请求应发送至 acquireAndRelease。这是因为在 SIX 升级期间，我们可能还需要释放多余的锁，因此我们需要使用 acquireAndRelease 来处理这些升级。</li>
<li><strong>getLockType</strong> 这是查询LockManager的主要方式，并返回事务对特定资源的锁类型。这在上一步中已实现。</li>
</ul>
<h4 id="Queues"><a href="#Queues" class="headerlink" title="Queues"></a>Queues</h4><p>每当对锁的请求无法满足时（因为它与其它事务在资源上已有的锁冲突，或者因为该资源上存在锁请求队列并且该操作不具有高于队列的优先级），则应该被放置在该资源的队列上（除非另有指定，否则放在后面），并且发出请求的事务应该被阻止。每个资源队列都独立于其它队列进行处理，并且必须释放资源上的锁后再进行处理，具体方式如下：</p>
<ul>
<li><p>考虑队列前面的请求，如果它不与资源上的任何现有的锁冲突，则应将其从队列中删除，并且：</p>
<ul>
<li><p>发出请求的事务应该被授予锁</p>
</li>
<li><p>请求所声明应释放的所有锁均已释放</p>
</li>
<li><p>发出请求的事务应该被解锁</p>
</li>
</ul>
</li>
<li><p>应重复上一步，直到无法满足队列中的第一个请求或队列为空。</p>
</li>
</ul>
<h4 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h4><p>LockManager 的方法具有同步块，以确保对 LockManager 的调用是串行的并且没有调用的交错。应该确保方法中对LockManager状态的所有访问（查询和修改）都在一个同步块内，例如：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Correct, use a single synchronized block</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">acquire</span><span class="params">(...)</span> &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="built_in">this</span>) &#123;</span><br><span class="line">        <span class="type">ResourceEntry</span> <span class="variable">entry</span> <span class="operator">=</span> getResourceEntry(name); <span class="comment">// fetch resource entry</span></span><br><span class="line">        <span class="comment">// do stuff</span></span><br><span class="line">        entry.locks.add(...); <span class="comment">// add to list of locks</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Incorrect, multiple synchronized blocks</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">acquire</span><span class="params">(...)</span> &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="built_in">this</span>) &#123;</span><br><span class="line">        <span class="type">ResourceEntry</span> <span class="variable">entry</span> <span class="operator">=</span> getResourceEntry(name); <span class="comment">// fetch resource entry</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// first synchronized block ended: another call to LockManager can start here</span></span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="built_in">this</span>) &#123;</span><br><span class="line">        <span class="comment">// do stuff</span></span><br><span class="line">        entry.locks.add(...); <span class="comment">// add to list of locks</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Incorrect, doing work outside of the synchronized block</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">acquire</span><span class="params">(...)</span> &#123;</span><br><span class="line">    <span class="type">ResourceEntry</span> <span class="variable">entry</span> <span class="operator">=</span> getResourceEntry(name); <span class="comment">// fetch resource entry</span></span><br><span class="line">    <span class="comment">// do stuff</span></span><br><span class="line">    <span class="comment">// other calls can run while the above code runs, which means we could</span></span><br><span class="line">    <span class="comment">// be using outdated lock manager state</span></span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="built_in">this</span>) &#123;</span><br><span class="line">        entry.locks.add(...); <span class="comment">// add to list of locks</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>事务在被阻塞时会阻塞整个线程，这意味着不能在同步块内阻塞事务（这将阻止对 LockManager 的任何其他调用运行，直到事务被解除阻塞……但事实并非如此，因为 LockManager 是用来解锁事务的）。</p>
<p>要阻止事务，请在同步块内调用 Transaction#prepareBlock，然后在同步块外调用 Transaction#block。 Transaction#prepareBlock 需要位于同步块中，以避免竞争条件，即事务在离开同步块的时刻和实际阻塞的时刻之间可能会出列。</p>
<h3 id="Multigranularity"><a href="#Multigranularity" class="headerlink" title="Multigranularity"></a>Multigranularity</h3><h4 id="LockContext"><a href="#LockContext" class="headerlink" title="LockContext"></a>LockContext</h4><p>LockContext类代表层次结构中的单个资源；这是所有多粒度操作（例如在获取或执行锁升级之前强制你拥有适当的意向锁）的实现位置。</p>
<p>需要实现以下方法：</p>
<ul>
<li><p><strong>acquire</strong> 在确保满足所有多粒度约束后，此方法通过底层 LockManager 执行获取。例如，如果事务具有 IS(database)并请求X(table)，则必须抛出适当的异常（请参阅上面方法的注释）。如果事务具有SIX锁，则该事务在任何后代资源上持有 IS&#x2F;S 锁都是多余的。因此，在我们的实现中，如果祖先有SIX锁，我们就禁止获取 IS&#x2F;S 锁，并将其视为无效请求。</p>
</li>
<li><p><strong>release</strong> 在确保释放后仍然满足所有多粒度约束后，此方法通过底层 LockManager 执行释放。例如，如果事务具有X(table)并尝试释放 IX(database)，则必须抛出适当的异常（请参阅上面方法的注释）。</p>
</li>
<li><p><strong>promote</strong> 在确保满足所有多粒度约束后，此方法通过底层 LockManager 执行锁升级。例如，如果事务具有IS(database)并请求从S(table)升级到X(table)，则必须抛出适当的异常（请参阅上面方法的注释）。在升级到SIX（从IS&#x2F;IX&#x2F;S）的特殊情况下，你应该同时释放 S&#x2F;IS 类型的所有后代锁，因为当持有 SIX 锁时，我们不允许在后代上拥有 IS&#x2F;S 锁。如果祖先有SIX锁，你还应该禁止升级到SIX锁，因为这是多余的。在将祖先提升到SIX锁而后代持有SIX锁的情况下，这仍然允许在SIX锁下持有SIX锁。这虽然是多余的，但修复它既混乱（必须将所有后代SIX锁与IX锁交换）又毫无意义（无论如何，你仍然持有后代锁），所以我们就保持原样。</p>
</li>
<li><p><strong>escalate</strong> 此方法将锁升级到当前级别（有关更多详细信息，请参阅下文）。由于允许多个事务（在不同线程上运行）交错执行多个 LockManager 的调用，因此你必须确保仅使用对 LockManager 的一次变异调用，并且仅从 LockManager 请求有关当前事务的相关信息（因为与任何其他事务相关的信息在查询和获取时可能会发生变化）。</p>
</li>
<li><p><strong>getExplicitLockType</strong> 此方法返回当前级别显式持有的锁的类型。例如，如果事务持有 X(db)，则 dbContext.getExplicitLockType(transaction) 应返回 X，但 tableContext.getExplicitLockType(transaction) 应返回 NL（没有显式持有锁）。</p>
</li>
<li><p><strong>getEffectiveLockType</strong> 此方法返回当前级别隐式或显式持有的锁的类型。例如，如果一个事务有 X(db)：</p>
<ul>
<li><p>dbContext.getEffectiveLockType(transaction) 应该返回 X</p>
</li>
<li><p>tableContext.getEffectiveLockType(transaction) 还应该返回 X（因为我们在整个数据库上显式拥有 X 锁，因此在每个表上隐式拥有 X 锁）。</p>
</li>
</ul>
</li>
</ul>
<p>由于意向锁不会隐式地将获取锁的权限授予较低级别，因此如果事务只有 SIX（database），则 tableContext.getEffectiveLockType(transaction) 应该返回 S（而不是SIX），因为该事务通过以下方式在表上隐式拥有S：SIX锁，但不是SIX锁的IX部分（仅在数据库级别可用）。显式锁类型可以是一种类型，而有效锁类型可以是不同的锁类型，特别是如果祖先有SIX锁。</p>
<p>LockContext 对象都共享一个底层 LockManager 对象。 parentContext方法返回当前上下文的父级（例如调用tableContext.parentContext()时返回数据库的LockContext），childContext方法返回传入名称的子锁上下文（例如tableContext.childContext(0L)返回表的第0页的LockContext）。每个资源只有一个LockContext：多次使用相同的参数调用childContext会返回相同的对象。出于性能原因，我们不会立即为表的每个页面创建LockContext。相反，我们在创建相应的 Page 对象时才创建它们。</p>
<p>锁升级是从许多精细锁（层次结构中较低级别的锁）升级到单个较粗略锁（较高级别的锁）的过程。例如，我们可以将事务持有的多个页锁升级为表级别的单个锁。我们通过 LockContext#escalate 执行锁升级。对此方法的调用应解释为将后代上的所有锁（这些是精细锁）升级为调用上下文升级时使用的一个锁（粗略锁）的请求。精细锁可以是意向锁和常规锁的任意组合，但我们将粗略锁限制为 S 或 X。</p>
<p>例如，如果我们有以下锁：IX(database)，SIX(table)，X(page 1)，X(page 2)，X(page 4)，并调用 tableContext.escalate(transaction)，我们应该将页级锁替换为包含它们的表上的单个锁：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230720095155.png"></p>
<p>同样，如果我们调用 dbContext.escalate(transaction)，我们应该将页级锁和表级锁替换为包含它们的数据库上的单个锁：</p>
<p><img src="https://3248067225-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-MFVQnrLlCBowpNWJo1E%2Fuploads%2Fgit-blob-5ce4b3a0fe666867c554f74df85455942421c3bc%2Fproj4-escalate2%20(1)%20(1)%20(2)%20(2)%20(3)%20(3).png?alt=media&token=8427ac3e-c038-4eaf-aa4b-667865f4963f"></p>
<p>请注意，在这方面，升级到X锁总是“有效”：拥有粗略的 X 锁肯定包含拥有一堆更精细的锁。但是，这会带来其他复杂性：如果事务之前仅持有更精细的 S 锁，则它不会拥有持有 X 锁所需的 IX 锁，并且升级到 X 会不必要地减少允许的并发量。因此，我们要求仅升级到仍包含替换的更精细锁的最低许可的锁类型（S 或 X 之间）（因此，如果我们只有 IS&#x2F;S 锁，我们应该升级到 S，而不是 X）。另请注意，由于我们仅升级到 S 或 X，因此仅具有IS(database)的事务将升级到 S(database)。虽然只有IS(database)的事务在技术上没有较低级别的锁，但在此级别保持意向锁的唯一目的是获取较低级别的普通锁，而升级的目的是避免拥有较低级别的锁。因此，我们不允许升级到意向锁 (IS&#x2F;IX&#x2F;SIX)。</p>
<h4 id="LockUtil"><a href="#LockUtil" class="headerlink" title="LockUtil"></a>LockUtil</h4><p>LockContext 类为我们强制执行多粒度约束，但在我们的数据库中使用它有点麻烦：无论我们想要请求什么锁，我们都必须处理请求适当的意向锁等。为了简化将locking集成到我们的代码库中，我们定义了ensureSufficientLockHeld方法。此方法的使用方式类似于声明性语句。例如，假设我们有一些读取整个表的代码。要添加locking，我们可以这样做：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LockUtil.ensureSufficientLockHeld(tableContext, LockType.S);</span><br><span class="line"></span><br><span class="line"><span class="comment">// any code that reads the table here</span></span><br></pre></td></tr></table></figure>

<p>在ensureSufficientLockHeld行之后，我们可以假设当前事务（Transaction.getTransaction()返回的事务）有权读取tableContext表示的资源以及任何子级（所有页面）。</p>
<p>我们可以连续调用它几次：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LockUtil.ensureSufficientLockHeld(tableContext, LockType.S);</span><br><span class="line">LockUtil.ensureSufficientLockHeld(tableContext, LockType.S);</span><br><span class="line"></span><br><span class="line"><span class="comment">// any code that reads the table here</span></span><br></pre></td></tr></table></figure>

<p>或以任意顺序编写多个语句：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">LockUtil.ensureSufficientLockHeld(pageContext, LockType.S);</span><br><span class="line">LockUtil.ensureSufficientLockHeld(tableContext, LockType.S);</span><br><span class="line">LockUtil.ensureSufficientLockHeld(pageContext, LockType.S);</span><br><span class="line"></span><br><span class="line"><span class="comment">// any code that reads the table here</span></span><br></pre></td></tr></table></figure>

<p>并且不应抛出任何错误，在调用结束时，我们应该能够读取所有表。</p>
<p>请注意，调用者并不关心事务实际拥有哪些锁：如果我们为事务提供数据库上的 X 锁，则事务确实有权读取所有表。但这不允许太多的并发性（如果与2PL一起使用，实际上会强制执行串行调度），因此我们另外规定ensureSufficientLockHeld应该授予尽可能少的额外权限：如果S锁足够，我们应该让事务获取S锁，而不是X锁，但如果事务已经有X锁，我们应该不管它（ensureSufficientLockHeld永远不应该减少事务拥有的权限，在调用之前它应该让事务至少像以前一样多）。我们建议将此方法的逻辑分为两个阶段：确保我们在祖先上拥有适当的锁，并获取资源上的锁。在某些情况下你需要promote和escalate（这些情况并不相互排斥）。</p>
<h4 id="Two-Phase-Locking"><a href="#Two-Phase-Locking" class="headerlink" title="Two-Phase Locking"></a>Two-Phase Locking</h4><p>此时，你应该有一个工作系统来获取和释放数据库中不同资源的锁。在这一部分，要添加逻辑以在整个事务过程中获取和释放锁。</p>
<p><strong>Acquisition Phase</strong></p>
<p><strong>读取和写入</strong>：最简单的锁定方案是根据需要简单锁定页面。由于所有对页面的读写都是通过 Page.PageBuffer 类执行的，因此仅更改这一点就足够了。修改Page.PageBuffer中的get和put方法，以实现使用尽可能最少的许可锁类型来锁定页面（并根据需要获取层次结构上的锁）。</p>
<p><strong>扫描</strong>：如果我们知道我们将扫描表的多个页面，那么我们最好只在表页面上的许多细粒度锁的表实例上获得一个锁。修改ridIterator和recordIterator方法以便在执行扫描之前获取表上适当的锁。</p>
<p><strong>写入优化</strong>：当我们修改页面时，我们几乎总是会先读取它（获取 IS&#x2F;S 锁），然后写回对其的更新（升级到 IX&#x2F;X 锁）。如果我们提前知道要修改页面，则可以直接获取 IX&#x2F;X 锁来跳过获取 IS&#x2F;S 锁的过程。修改以下方法来预先请求适当的锁定：</p>
<ul>
<li><p>PageDirectory#getPageWithSpace</p>
</li>
<li><p>Table#updateRecord</p>
</li>
<li><p>Table#deleteRecord</p>
</li>
</ul>
<p><strong>Release Phase</strong></p>
<p>此时，事务应该获取执行查询所需的大量锁，但不会释放任何锁！我们将在数据库中使用严格的Two-Phase Locking，这意味着只有在事务完成时才会在清理方法中释放锁。修改Database.TransactionContextImpl的close方法，释放事务获取的所有锁。你应该使用 LockContext#release 而不是 LockManager#release。LockManager不会验证多粒度约束，但与此同时其他事务需要假设满足这些约束，因此需要维护这些约束。最后，需要注意不能按任意顺序释放锁，要考虑释放顺序。</p>
<h1 id="MySQL-日志"><a href="#MySQL-日志" class="headerlink" title="MySQL 日志"></a>MySQL 日志</h1><p>在前文的select语句的执行流程中提到，更新语句的流程会涉及到 undo log（回滚日志）、redo log（重做日志） 、binlog （归档日志）这三种日志：</p>
<ul>
<li><strong>undo log（回滚日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>原子性</strong>，主要<strong>用于事务回滚和 MVCC</strong>。</li>
<li><strong>redo log（重做日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>持久性</strong>，主要<strong>用于掉电等故障恢复</strong>；</li>
<li><strong>binlog （归档日志）</strong>：是 Server 层生成的日志，主要<strong>用于数据备份和主从复制</strong>；</li>
</ul>
<h2 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h2><p>我们在执行执行一条“增删改”语句的时候，虽然没有输入 begin 开启事务和 commit 提交事务，但是 MySQL 会<strong>隐式开启事务</strong>来执行“增删改”语句的，执行完就自动提交事务的，这样就保证了执行完“增删改”语句后，我们可以及时在数据库表看到“增删改”的结果了。</p>
<p>如果我们每次在事务执行过程中，都记录下回滚时需要的信息到一个日志里，那么在事务执行中途发生了 MySQL 崩溃后，就不用担心无法回滚到事务之前的数据，我们可以通过这个日志回滚到事务之前的数据。实现这一机制就是 undo log（回滚日志），它保证了事务的ACID 特性中的原子性（Atomicity）。然后我们需要在提交事务之前，将undo log写入到磁盘中。</p>
<p>每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，比如：</p>
<ul>
<li>在<strong>插入</strong>一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录<strong>删掉</strong>就好了；</li>
<li>在<strong>删除</strong>一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录<strong>插入</strong>到表中就好了；</li>
<li>在<strong>更新</strong>一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列<strong>更新为旧值</strong>就好了。</li>
</ul>
<p>一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：</p>
<ul>
<li>通过 trx_id 可以知道该记录是被哪个事务修改的；</li>
<li>通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链；</li>
</ul>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906153947.png"></p>
<p>总的来说，undo log 两大作用：</p>
<ul>
<li><strong>实现事务回滚，保障事务的原子性</strong>。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。</li>
<li><strong>实现 MVCC（多版本并发控制）关键因素之一</strong>。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。</li>
</ul>
<h2 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h2><p>为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 <strong>redo log</strong> 的形式记录下来，<strong>这个时候更新就算完成了</strong>。后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 <strong>WAL （Write-Ahead Logging）技术</strong>。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906154152.png"></p>
<p>redo log 是物理日志，记录了某个数据页做了什么修改，比如<strong>对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新</strong>，每当执行一个事务就会产生这样的一条或者多条物理日志。</p>
<p>在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。</p>
<p>值得注意的是，当开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。不过，<strong>在内存修改该 Undo 页面后，需要记录对应的 redo log</strong>。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906154452.png"></p>
<p>由于一个事务中可能会有大量的更新操作，这意味着会产生大量redo log，如果一产生redo log就写入磁盘中，这会产生大量的 I&#x2F;O 操作并且写入速度也十分慢。因此，redo log 也有自己的缓存—— <strong>redo log buffer</strong>，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘如下图：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906154805.png"></p>
<p>那么缓存在 redo log buffer 里的 redo log 什么时候刷新到磁盘？</p>
<p>主要有下面几个时机：</p>
<ul>
<li>MySQL 正常关闭时；</li>
<li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li>
<li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li>
<li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制）。</li>
</ul>
<h2 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h2><p>前面介绍的 undo log 和 redo log 这两个日志都是 Innodb 存储引擎生成的。但MySQL 在完成一条更新操作后，Server 层还会生成一条 <strong>binlog</strong>，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。</p>
<p>binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。</p>
<p>binlog和redo log区别如下：</p>
<p>1、适用对象不同：</p>
<ul>
<li>binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；</li>
<li>redo log 是 Innodb 存储引擎实现的日志；</li>
</ul>
<p>2、文件格式不同：</p>
<ul>
<li>binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：<ul>
<li>STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；</li>
<li>ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；</li>
<li>MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；</li>
</ul>
</li>
<li>redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；</li>
</ul>
<p>3、写入方式不同：</p>
<ul>
<li>binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。</li>
<li>redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。</li>
</ul>
<p>4、用途不同：</p>
<ul>
<li>binlog 用于备份恢复、主从复制；</li>
<li>redo log 用于掉电等故障恢复。</li>
</ul>
<blockquote>
<p>如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？</p>
</blockquote>
<p>不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。</p>
<p>因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。</p>
<p>binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据。</p>
<h2 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h2><p>在讲两阶段提交之前，结合前面三种日志，过一遍update语句的执行过程：</p>
<p>当优化器分析出成本最小的执行计划后，执行器就按照执行计划开始进行更新操作。具体更新一条记录 <code>UPDATE t_user SET name = &#39;xxx&#39; WHERE id = 1;</code> 的流程如下</p>
<ol>
<li>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id &#x3D; 1 这一行记录：<ul>
<li>如果 id&#x3D;1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</li>
<li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</li>
</ul>
</li>
<li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：<ul>
<li>如果一样的话就不进行后续更新流程；</li>
<li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</li>
</ul>
</li>
<li>开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。</li>
<li>InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I&#x2F;O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 <strong>WAL 技术</strong>，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。</li>
<li>至此，一条记录更新完了。</li>
<li>在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</li>
<li>事务提交，剩下的就是「两阶段提交」的事情了。</li>
</ol>
<p>事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。</p>
<p>举个例子，假设 id &#x3D; 1 这行数据的字段 name 的值原本是 ‘yyy’，然后执行 <code>UPDATE t_user SET name = &#39;xxx&#39; WHERE id = 1;</code> 如果在持久化 redo log 和 binlog 两个日志的过程中，出现了半成功状态，那么就有两种情况：</p>
<ul>
<li><strong>如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入</strong>。MySQL 重启后，通过 redo log 能将 Buffer Pool 中 id &#x3D; 1 这行数据的 name 字段恢复到新值 xxx，但是 binlog 里面没有记录这条更新语句，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行 name 字段是旧值 yyy，与主库的值不一致性；</li>
<li><strong>如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入</strong>。由于 redo log 还没写，崩溃恢复以后这个事务无效，所以 id &#x3D; 1 这行数据的 name 字段还是旧值 yyy，而 binlog 里面记录了这条更新语句，在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，那么这一行 name 字段是新值 xxx，与主库的值不一致性；</li>
</ul>
<p>可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。</p>
<p><strong>MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决</strong>，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。</p>
<p><strong>两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」</strong>，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段。</p>
<p>举个拳击比赛的例子，两位拳击手（参与者）开始比赛之前，裁判（协调者）会在中间确认两位拳击手的状态，类似于问你准备好了吗？</p>
<ul>
<li><strong>准备阶段</strong>：裁判（协调者）会依次询问两位拳击手（参与者）是否准备好了，然后拳击手听到后做出应答，如果觉得自己准备好了，就会跟裁判说准备好了；如果没有自己还没有准备好（比如拳套还没有带好），就会跟裁判说还没准备好。</li>
<li><strong>提交阶段</strong>：如果两位拳击手（参与者）都回答准备好了，裁判（协调者）宣布比赛正式开始，两位拳击手就可以直接开打；如果任何一位拳击手（参与者）回答没有准备好，裁判（协调者）会宣布比赛暂停，对应事务中的回滚操作。</li>
</ul>
<p>在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，为了保证这两个日志的一致性，MySQL 使用了<strong>内部 XA 事务</strong>（也有外部 XA 事务），内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。</p>
<p>当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，<strong>分两阶段来完成 XA 事务的提交</strong>，如下图：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230906160319.png"></p>
<p>从图中可看出，事务的提交过程有两个阶段，就是<strong>将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog</strong>，具体如下：</p>
<ul>
<li><p><strong>prepare 阶段</strong>：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit &#x3D; 1 的作用）；</p>
</li>
<li><p><strong>commit 阶段</strong>：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog &#x3D; 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；</p>
</li>
</ul>
<h1 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h1><p>在前面讲述事务的部分，我们提及了事务的四个特性，在这一部分会涉及到<strong>持久性</strong>和<strong>原子性</strong>，持久性能保证事务结果不会丢失，原子性能使数据库从一个状态到达另外一个状态，不存在中间状态。</p>
<h2 id="Policy"><a href="#Policy" class="headerlink" title="Policy"></a>Policy</h2><h3 id="Force-x2F-No-Force"><a href="#Force-x2F-No-Force" class="headerlink" title="Force&#x2F;No Force"></a>Force&#x2F;No Force</h3><p>如果我们使用<strong>强制策略</strong>，持久性是一个非常简单的属性。强制策略规定，当事务结束时，在事务提交前将所有修改过的数据页都将强制存入磁盘。这将确保持久性，因为磁盘是持久的；换而言之，页面一旦进入磁盘，就会被永久保存。这种方法的缺点是性能差，我们最终会进行大量不必要的写入。相较而言， <strong>不强制策略</strong>更加讨喜，即只有当页面需要从缓冲池中移除时才写回磁盘。虽然这有助于减少不必要的写入，但会使持久性变得复杂，因为如果数据库在事务提交后崩溃，一些页面可能尚未写入磁盘，因为内存是易失性的，所以会从内存中丢失。为了解决这个问题，我们将在恢复期间重做某些操作。</p>
<p>总结：</p>
<ul>
<li><p>强制策略：事务结束，应在事务提交前将脏页写入磁盘。</p>
</li>
<li><p>不强制策略：只有当页面要从缓冲池中被移除才写回磁盘。</p>
</li>
</ul>
<h3 id="Steal-x2F-No-Steal"><a href="#Steal-x2F-No-Steal" class="headerlink" title="Steal&#x2F;No-Steal"></a>Steal&#x2F;No-Steal</h3><p>同样，使用<strong>不偷窃策略</strong>也很容易确保原子性。不偷窃策略规定，在事务提交之前，页面不能从内存中移除（因此也不能写入磁盘）。这可以确保数据库不会处于中间状态，因为如果事务没有完成，那么它的任何更改都不会被写入磁盘并保存下来。这种策略的问题在于，它限制了我们使用内存的方式——我们必须将每个修改过的页面保留在内存中，直到事务完成。我们更倾向于使用<strong>偷窃策略</strong>，即允许在事务完成前将修改的页面写入磁盘。这将使原子性的执行变得复杂，但我们可以通过在恢复过程中撤销错误操作来解决这个问题。</p>
<p>总结：</p>
<ul>
<li><p>不偷窃策略：事务提交前，页面不能从内存中移除（也不能写入磁盘）。</p>
</li>
<li><p>偷窃策略：事务完成前，可以将脏页写入磁盘。</p>
</li>
</ul>
<h3 id="Steal-No-Force"><a href="#Steal-No-Force" class="headerlink" title="Steal, No-Force"></a>Steal, No-Force</h3><p>综上，我们将使用两种策略（偷窃、不强制），虽然很难保证原子性和耐久性，但却能获得最佳性能。</p>
<h2 id="Write-Ahead-Logging"><a href="#Write-Ahead-Logging" class="headerlink" title="Write Ahead Logging"></a>Write Ahead Logging</h2><p>为了解决以上问题，我们使用日志来解决。日志文件是用来记录事务对数据库的更新操作的文件，一般有两种格式，以记录为单位的日志文件和以数据块为单位的日志文件。</p>
<h3 id="Update-Log-Record"><a href="#Update-Log-Record" class="headerlink" title="Update Log Record"></a>Update Log Record</h3><p>一条UPDATE日志记录如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;XID, pageID, offset, length, old_data, new_data&gt;</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li><p>XID: 事务 ID——告诉我们哪个事务执行了此操作</p>
</li>
<li><p>pageID: 哪个页面被修改了</p>
</li>
<li><p>offset: 页面上数据开始更改的位置（通常以字节为单位）</p>
</li>
<li><p>length: 更改了多少数据（通常以字节为单位）</p>
</li>
<li><p>old_data: 原始数据（用于undo操作，即撤销操作）</p>
</li>
<li><p>new_data: 更新后的数据（用于redo操作，即重做操作）</p>
</li>
</ul>
<h3 id="Other-Log-Records"><a href="#Other-Log-Records" class="headerlink" title="Other Log Records"></a>Other Log Records</h3><p>我们将在日志中还使用其他一些记录类型。在整个注释中，我们将根据需要为这些日志记录添加字段。</p>
<ul>
<li><p>COMMIT：表示事务正在开始提交过程</p>
</li>
<li><p>ABORT：表示事务正在开始中止过程</p>
</li>
<li><p>END：表示事务已完成（通常表示已完成提交或中止）</p>
</li>
</ul>
<h3 id="WAL-Requirements"><a href="#WAL-Requirements" class="headerlink" title="WAL Requirements"></a>WAL Requirements</h3><p>与普通数据页一样，日志页也需要在内存中操作，但需要写入磁盘永久保存。<strong>Write Ahead Logging</strong>(WAL，预写日志)对我们何时将日志写入磁盘提出了要求。简而言之，WAL是一种策略，即在实际操作刷新到磁盘或发生之前，将描述操作（如修改数据页或提交事务）的日志记刷新到磁盘。有两条规则如下：</p>
<ul>
<li><p><strong>日志记录必须在相应的数据页写入磁盘之前先写入磁盘</strong>，这是我们实现原子性的方法。这样做的直观原因是，如果先写入数据页，然后数据库崩溃，我们就无法执行undo操作，因为我们不知道事务执行了什么操作。</p>
</li>
<li><p><strong>事务提交时，所有日志记录都必须写入磁盘</strong>，这是我们实现持久性的方法。直觉告诉我们，我们需要持续跟踪已提交的事务执行了哪些操作。否则，我们就不知道需要重做哪些操作。将所有日志写入磁盘后，如果数据库在修改的数据页写入磁盘前崩溃，我们就能准确知道需要重做哪些操作。</p>
</li>
</ul>
<h3 id="WAL-Implementation"><a href="#WAL-Implementation" class="headerlink" title="WAL Implementation"></a>WAL Implementation</h3><p>为了实现WAL，我们将在日志记录中添加一个名为 LSN 的字段，LSN 是日志序列号（Log Sequence Number）的缩写。LSN 是一个唯一的递增数字，用于表示操作的顺序（如果看到一条 LSN &#x3D; 20 的日志记录，那么该操作发生在 LSN &#x3D; 10 的记录之后）。在这个类中，LSN 每次增加 10，但这只是一种约定俗成的做法。我们还将在每条日志记录中添加一个 <strong>prevLSN</strong> 字段，用于存储同一事务中的上一次操作（这对撤销事务非常有用）。</p>
<p>数据库还将跟踪存储在 RAM 中的flushedLSN。<strong>flushedLSN会跟踪已刷新到磁盘的最后一条日志记录的LSN</strong>。当一个页面被刷新时，意味着该页面已被写入磁盘；通常也意味着我们应该将该页面从内存中移除，因为我们不再需要它了。flushedLSN告诉我们，在它之前的任何日志记录都不应写入磁盘，因为它们已经在那里了。日志页通常会追加到在磁盘上的前一个日志页，因此多次写入相同的日志将意味着我们存储了重复的数据，这也会破坏日志的连续性。</p>
<p>我们还将为每个数据页添加一段metadata，称为pageLSN。<strong>pageLSN存储了最后一次修改页面的操作的LSN</strong>。我们将利用它来帮助我们了解哪些操作实际上已被存入磁盘，哪些操作必须重做。</p>
<h3 id="Aborting-a-Transaction"><a href="#Aborting-a-Transaction" class="headerlink" title="Aborting a Transaction"></a>Aborting a Transaction</h3><p>在讨论从崩溃中恢复之前，我们先来了解一下数据库如何中止正在进行的事务。我们可能因为出现死锁而想中止事务，或者用户可能因为事务耗时过长而决定中止事务。如果某个操作违反了某些完整性约束，也可以中止事务以保证 ACID 中的C，即一致性。最后，系统崩溃也可能导致事务中止。我们需要确保在中止过程结束后，所有操作都不会被持久化到磁盘上。</p>
<p>我们要做的第一件事就是在日志中写入一条 ABORT 记录，以表示我们正在启动中止进程。然后，我们将从日志中该事务的最后一个操作开始，撤销事务中的每个操作，并为每个撤销的操作向日志中写入 CLR 记录。<strong>CLR</strong>（Compensation Log Record，补偿日志记录）是一种新型记录，表示我们正在撤销特定操作。它与 UPDATE 记录本质上是一样的（它存储了之前的状态和新状态），但它告诉我们，这次写操作是由于中止而发生的。</p>
<h2 id="Recovery-Data-Structures"><a href="#Recovery-Data-Structures" class="headerlink" title="Recovery Data Structures"></a>Recovery Data Structures</h2><p>我们将保留两张状态表，以便恢复过程更容易一些。第一个表称为事务表，存储活动事务的信息。事务表有三个字段：</p>
<ul>
<li><p>XID: 事务ID</p>
</li>
<li><p>status: 运行、提交或中止</p>
</li>
<li><p><strong>lastLSN</strong>: 该事务最近一次操作的LSN</p>
</li>
</ul>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725105849.png"></p>
<p>我们维护的另一个表叫做脏页面表（Dirty Page Table，DPT）。DPT 会记录哪些页面是脏页（脏页意味着页面在内存中被修改过，但尚未刷新到磁盘）。这些信息将非常有用，因为它将告诉我们哪些页面有操作但还没有刷新到磁盘。DPT 只有两列：</p>
<ul>
<li><p>Page ID</p>
</li>
<li><p><strong>recLSN</strong>: 弄“脏”页面的第一个操作</p>
</li>
</ul>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725110146.png"></p>
<p>需要注意的一点是，这两个表都存储在内存中；因此，从崩溃中恢复时，必须使用日志来重建表。当然，后面会讨论一种更简便的方法（具有检查点的恢复技术）。</p>
<h2 id="Undo-Logging"><a href="#Undo-Logging" class="headerlink" title="Undo Logging"></a>Undo Logging</h2><p>我们已经介绍了很多关于数据库如何写入日志以及正常运行时如何中止事务的背景信息。现在，让我们来了解一下记录日志的原因——从故障中恢复。一种可能的恢复机制是Undo Logging。请注意，Undo Logging事实上并不使用我们之前讨论过的预写日志（WAL）。此外，它在缓冲池管理方面使用了强制和偷窃机制。</p>
<p>Undo Logging背后更深层次的思考是，我们希望消除所有尚未提交的事务的影响，而不消除已提交的事务的影响。为此，我们建立了 4 种类型的记录：Start、Commit、Abort和Update（包含旧值）。我们还需要制定两条规则，分别涉及如何进行日志记录以及何时将脏数据页刷新到磁盘：</p>
<ul>
<li><p><strong>如果一个事务修改了一个数据元素，那么相应的更新日志记录必须在包含该数据元素的 dirty 页面被写入磁盘之前写入</strong>。我们之所以要这样做，是因为我们希望确保在新值永久取代旧值之前，旧值已被记录在磁盘上。</p>
</li>
<li><p><strong>如果事务提交，那么被修改的页面必须在commit record本身写入磁盘之前写入磁盘</strong>。这条规则确保了在事务本身实际提交之前，事务所做的所有更改都已写入磁盘。这一点很重要，因为如果我们在日志中看到了提交日志记录，那么我们就会认为该事务已提交，并且不会在恢复过程中撤销其更改。请注意，这与提前写入日志不同，在这里，脏页面是在提交记录写入磁盘之前写入磁盘的。</p>
</li>
</ul>
<p>请注意，第一条规则执行的是偷窃策略，因为脏页面会在事务提交前写入磁盘，而第二条规则执行的是强制策略。</p>
<p>既然已经制定了这些规则，我们就可以讨论使用Undo Logging进行恢复的问题了。当系统崩溃时，我们首先运行recovery manager。我们从头开始扫描日志，以确定每个事务是否已完成。我们根据遇到的日志记录采取的操作如下：</p>
<ul>
<li><p>COMMIT&#x2F;ABORT T: 标记T已经完成</p>
</li>
<li><p>UPDATE T, X, v: 如果T未完成，将X&#x3D;v写入磁盘，否则忽略</p>
</li>
<li><p>START T: 忽略</p>
</li>
</ul>
<p>我们将一直扫描到遇到检查点为止。</p>
<h2 id="Redo-Logging"><a href="#Redo-Logging" class="headerlink" title="Redo Logging"></a>Redo Logging</h2><p>现在，让我们来谈谈另一种基于日志的恢复形式——Redo Logging。在这里，Redo Logging实现了缓冲区管理的 “不强制、不偷窃 “策略。在Redo Logging中，我们有与Undo Logging相同类型的日志记录，唯一不同的是更新日志记录，我们不存储特定数据元素的旧值，而是存储它将要写入的新值。</p>
<p>Redo Logging想要实现的与Undo Logging类似，只是在恢复时，我们不是撤销所有未完成的事务，而是重做所有已提交事务的操作。与此同时，我们会保留所有未提交的事务。与Undo Logging一样，我们也要遵守一条规则。</p>
<ul>
<li>如果一个事务修改了数据元素X，则更新记录和提交记录都必须先于脏数据页本身写入磁盘——这就是不偷窃策略。因此，脏数据页的写入时间晚于事务提交记录，本质上属于预写日志。</li>
</ul>
<p>Redo Logging的恢复相当简单：我们只需从头开始读取日志，并重做已提交事务的所有更新。虽然这看似操作很多，但可以像Undo Logging一样，通过检查点进行优化。</p>
<h2 id="ARIES-Recovery-Algorithm"><a href="#ARIES-Recovery-Algorithm" class="headerlink" title="ARIES Recovery Algorithm"></a>ARIES Recovery Algorithm</h2><p>当数据库崩溃时，它唯一可以访问的就是写入到磁盘的日志和磁盘上的数据页。 根据此信息，它应该自行恢复，以便所有已提交的事务操作都持久化（持久性），并且在崩溃前未完成的所有事务都可以正确撤销（原子性）。 恢复算法由 3 个阶段组成，按以下顺序执行：</p>
<ul>
<li><p><strong>Analysis Phase</strong>: 重建Xact Table和DPT</p>
</li>
<li><p><strong>Redo Phase</strong>: redo以确保持久性</p>
</li>
<li><p><strong>Undo Phase</strong>: undo崩溃时正在运行的事务中的操作以确保原子性</p>
</li>
</ul>
<h3 id="Analysis-Phase"><a href="#Analysis-Phase" class="headerlink" title="Analysis Phase"></a>Analysis Phase</h3><p>分析阶段的目的是就是重建Xact表和DPT在数据库崩溃前的样子。为此，我们从头开始扫描日志中的所有记录，并根据以下规则修改表格：</p>
<ul>
<li><p>在任何不是 END 记录的记录上：将事务添加到 Xact 表（如果需要），将事务的lastLSN设置为你当前所在的记录的LSN。</p>
</li>
<li><p>如果记录是 COMMIT 或 ABORT 记录，则相应地更改 Xact 表中事务的状态。</p>
</li>
<li><p>如果该记录是一条 UPDATE 记录，该页不在 DPT 中，则将该页添加到 DPT 中，并将 recLSN 设置为LSN。</p>
</li>
<li><p>如果该记录是 END 记录，则从 Xact 表中删除该事务。</p>
</li>
</ul>
<p>在分析阶段快结束时，对于任何正在提交的事务，我们还将 END 记录写入日志并从 Xact 表中删除该事务。 此外，崩溃时正在运行的任何事务都需要中止，并且记录ABORT记录。</p>
<p>到目前为止，分析阶段有一个关键问题，那就是它需要数据库扫描整个日志。 在实际生产环境中，这是不现实的，因为可能有数百万条记录。 为了加速分析阶段，我们将使用<strong>检查点</strong>。 检查点将 Xact 表和 DPT 的内容写入日志。 这样，我们就可以从最后一个检查点开始，而不是从日志的开头开始。</p>
<p>现在我们考虑检查点的一种变体，即模糊检查点，它实际上将两条记录写入日志，一条&lt; BEGIN_CHECKPOINT &gt;记录表示检查点何时开始，一条&lt; END_CHECKPOINT &gt;记录表示我们何时完成将表写入日志。 写入日志的表可以是 &lt; BEGIN_CHECKPOINT &gt; 和 &lt; END_CHECKPOINT &gt; 之间任意点的表状态。 这意味着我们需要从 &lt; BEGIN_CHECKPOINT &gt; 开始，因为我们不确定其后面的记录是否实际反映在写入日志的表中。</p>
<p>举个例子：</p>
<p>假如数据库崩溃并有如下log，右侧的Xact Table和DPT均在&lt; END_CHECKPOINT &gt; 记录中找到。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725140527.png"></p>
<p>首先，我们从 LSN 60 处的记录开始，因为它是紧接在begin checkpoint记录之后的记录。这是一条 UPDATE 记录，并且 T3 已经在 Xact 表中，因此我们将更新 lastLSN，在DPT中page已经更新，因此DPT不需要修改。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725140946.png"></p>
<p>现在我们来到LSN 70 处的记录。它是一条ABORT 记录，因此我们需要将Xact 表中的状态更改为Aborting 并更新lastLSN。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725141339.png"></p>
<p>对于end checkpoint记录无需执行任何操作，因此我们移至 LSN 90 处的 CLR (UNDO)。T3 在 Xact 表中，因此我们更新lastLSN，并且它正在修改的页面 (P3) 已在 DPT 中，因此我们再次不必修改 DPT。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725141455.png"></p>
<p>在 LSN 100 处，我们有另一个更新操作，并且 T1 已经在 Xact 表中，因此我们将更新其lastLSN。然而，该记录正在更新的页面不在 DPT 中，因此我们将使用 100 的 recLSN 添加它，因为这是第一个脏页面的操作。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725141652.png"></p>
<p>接下来是 LSN 110，它是 COMMIT 记录。我们需要将T1的状态更改为committing并更新lastLSN。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725141728.png"></p>
<p>最后，LSN 120 是一条 END 记录，这意味着我们需要从 Xact 表中删除 T1。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725141749.png"></p>
<p>请注意，在这个问题中，我们省略了结束提交事务和中止正在运行的事务的最后一步。实际上，在重做阶段开始之前，我们会将 T2 的状态更改为中止。</p>
<h3 id="Redo-Phase"><a href="#Redo-Phase" class="headerlink" title="Redo Phase"></a>Redo Phase</h3><p>恢复的下一阶段是重做阶段，以确保持久性。我们将重演历史，以重建崩溃时的状态。我们从 DPT 中最小的 recLSN 开始，因为这是可能尚未写入磁盘的第一个操作。我们将重做所有 UPDATE 和 CLR 操作，除非满足以下条件之一：</p>
<ul>
<li><p>该页面不在 DPT 中。如果该页面不在 DPT 中，则意味着所有更改（以及这一更改）都已刷新到磁盘。</p>
</li>
<li><p>recLSN &gt; LSN。这是因为第一次弄脏页面的更新是在此操作之后发生的。这意味着我们当前所在的操作已经写入磁盘，否则它将是recLSN。</p>
</li>
<li><p>pageLSN(disk) &gt; LSN。如果将其写入磁盘的页面的最新更新发生在当前操作之后，那么我们就知道当前操作一定已将其写入磁盘。</p>
</li>
</ul>
<p>举个例子：</p>
<p>接着Analysis Phase后的结果</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725142243.png"></p>
<p>首先，我们需要从LSN10开始恢复，因为这是DPT中最小的recLSN。其次需要redo的操作如下：10，40，60，90，100。20不需要redo是因为recLSN &gt; LSN；30不需要redo是因为P2不在DPT；50，70，80，110和120不需要redo是因为它们不是UPDATE，也不是CLR。</p>
<h3 id="Undo-Phase"><a href="#Undo-Phase" class="headerlink" title="Undo Phase"></a>Undo Phase</h3><p>恢复过程的最后阶段是撤销阶段，它确保原子性。 撤销阶段将从日志末尾开始，并逐渐向日志开头延伸。 它会撤销崩溃时每个处于活跃状态（正在运行或中止）的事务的每个更新（仅更新），以确保数据库不会处于中间状态。 如果 UPDATE 已被撤销（因此 CLR 记录已存在于该 UPDATE 的日志中），那么它不会撤销 UPDATE。</p>
<p>对于撤销阶段撤销的每个 UPDATE，它都会将相应的 CLR 记录写入日志。 CLR 记录还有一个我们尚未引入的附加字段，称为 undoNextLSN。 undoNextLSN 存储该事务要撤销的下一个操作的 LSN（它来自于要撤销的操作的prevLSN，从后往前）。 撤销事务的所有操作后，将该事务的 END 记录写入日志。</p>
<p>举个例子：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725143236.png"></p>
<p>首先认识到提供的日志缺少分析阶段的一条记录。 请记住，在分析阶段的最后，我们需要为任何中止事务写入日志条目。 因此，在 LSN 130 处应该有一条中止 T2 的 ABORT 记录。 它的 prevLSN 为 30，因为这是 T2 在此 ABORT 操作之前执行的上一个操作。 为了完整性，我们将此记录包含在最终答案中，但请注意，从技术上讲，<strong>它不是在撤销阶段写入的，而是在分析阶段结束时写入的</strong>。</p>
<p>我们现在继续撤销 T2 和 T3 的操作。 T3 的最新更新发生在 LSN 60，但请注意日志中已存在该操作的 CLR (LSN 90)。 因为该操作已撤销，所以我们不需要再次撤销它。</p>
<p>下一个操作是 LSN 40 处的 UPDATE。此更新不会在日志中的其他任何位置撤销，因此我们需要撤销它并写入相应的 CLR 记录。 prevLSN 将为 90，因为该 CLR 日志记录是 T3 的上一个操作。 undoNextLSN 将为 null，因为 T3 中没有其他操作可以撤销。 由于 T3 没有更多操作可撤销，因此我们还必须写入该事务的 END 记录。</p>
<p>我们需要撤销的下一个操作是 T2 在 LSN 30 处的更新。由于我们之前编写了 ABORT 记录，该记录的 prevLSN 将为 130。 undoNextLSN 将再次为空，因为日志中没有对 T2 的其他操作。我们还需要为 T2 写入 END 记录，因为这是我们需要撤销的最后一个操作。这是最终答案：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725143632.png"></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>我们现在已经介绍了整个 ARIES 恢复算法。我们首先通过重新创建事务和脏页表并重新应用未刷新的修改来重建崩溃之前的数据库状态。然后，我们中止崩溃之前正在运行的所有事务，并通过一次高效的传递撤销它们的所有影响。下面是三个阶段如何与日志记录交互以使数据库恢复一致状态的高级视图：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230725143818.png"></p>
<p>在这一部分，我们首先介绍了数据库如何保证即使在使用窃取、非强制策略的情况下也能从故障中恢复。以下是不同类型策略的性能和日志记录影响的摘要：</p>
<p><img src="https://cs186berkeley.net/notes/assets/images/12-Recovery/logging_quadrants.png" alt="image"></p>
<p>然后，我们介绍了数据库在正确运行时如何使用预写日志记录策略来记录所有操作。我们最终介绍了数据库如何通过 3 个步骤（分析、重做、撤销）使用日志来从故障中恢复并将数据库恢复到正确的状态。</p>
<h2 id="Code-1"><a href="#Code-1" class="headerlink" title="Code"></a>Code</h2><p>在这一部分中，要实现预写日志记录并支持保存点、回滚和符合 ACID 的重启恢复。</p>
<h3 id="Manager"><a href="#Manager" class="headerlink" title="Manager"></a>Manager</h3><p>该项目将以 ARIESRecoveryManager.java 为中心，它实现了 RecoveryManager 接口。回想一下，有两种不同的操作模式：<strong>转发处理</strong>，在数据库正常操作期间执行日志记录并维护一些元数据，例如脏页表和事务表；以及<strong>重启恢复</strong>（也称为崩溃恢复），其中包括数据库再次启动时执行的过程。在正常操作期间，数据库的其余部分调用recovery manager的各种方法来表示某些操作（例如页面写入或刷新）已经发生。在重启期间，将调用restart方法，使数据库恢复到有效状态。一些比较重要的类如下：</p>
<ul>
<li><p>RecoveryManager.java：概述了要实现的每个方法以及它们何时被调用。</p>
</li>
<li><p>TransactionTableEntry.java：代表事务表中的一个条目，并跟踪诸如 LastLSN 和active savepoints之类的内容。</p>
</li>
<li><p>LogManager.java：包含日志管理器的实现，它提供了appending、fetching和flushing日志的接口</p>
</li>
<li><p>LogRecord.java：包含我们支持的所有不同类型日志的super class。每个日志都有一个类型和一个 LSN。 LogRecord 的某些子类可以选择支持额外的方法。</p>
</li>
<li><p>records：该目录下包含LogRecord的所有子类。</p>
</li>
</ul>
<p>另外一个很重要的类就是<strong>Disk Space Manager</strong>。虽然不会直接使用disk space manager（各种 LogRecord 子类将根据需要使用它），但它确实有助于理解我们的disk space manager如何在更高的层次组织数据。</p>
<p>disk space manager负责分配页，它将页划分为分区。例如，页 40000000001 是分区 4 中的第 1 页（0 索引）。分区被显式分配和释放（但当且仅当其中没有页面时才能释放），并且页面始终在分区下分配。</p>
<p>分区 0 保留用于存储日志，这就是为什么在某些地方会看到将分区号与 0 进行比较的检查。每个其他分区都包含一个表或一个序列化的 B+ 树对象。</p>
<h3 id="Forward-Processing"><a href="#Forward-Processing" class="headerlink" title="Forward Processing"></a>Forward Processing</h3><p>当数据库正常运行时——事务正常运行，读写数据——recovery manager的工作就是维护日志，添加日志记录并确保在必要时正确刷新日志，以便我们可以随时从崩溃中恢复。</p>
<p>首次创建数据库时，在运行任何事务之前，recovery manager首先要做的事情是设置日志，这是在 ARIESRecoveryManager.java 中的初始化方法中完成的。 我们将主记录作为日志中的第一个日志记录存储在LSN 0处（回想一下，主记录存储最近成功检查点的开始检查点记录的LSN）。为了简化实现重启恢复的分析阶段所需的步骤，我们还需要立即执行检查点，连续写入开始和结束检查点记录，并更新主记录。</p>
<h4 id="Transaction-Status"><a href="#Transaction-Status" class="headerlink" title="Transaction Status"></a>Transaction Status</h4><p>Forward Processing期间recovery manager的部分工作是维护正在运行的事务的状态，并记录事务状态的更新。通过三种方法向recovery manager通知事务状态的变化：</p>
<ul>
<li><p><code>commit</code>：当事务尝试进入 COMMITTING 状态时调用。</p>
</li>
<li><p><code>abort</code>：当事务尝试进入 ABORTING 状态时调用。</p>
</li>
<li><p><code>end</code>：当事务尝试进入 COMPLETE 状态时调用。</p>
</li>
</ul>
<p>在需要实现的三个方法（commit、abort、end）中，需要使事务表保持最新，设置相应事务的状态，并将适当的日志记录写入日志（检查records&#x2F;目录以了解可以创建的日志类型）。应该养成每当为事务操作添加日志时更新事务表中的lastLSN的习惯，这包括状态更改记录、更新记录和 CLR。</p>
<p>值得强调的是，在commit方法中，提交记录需要在commit调用返回之前刷新到磁盘以确保持久性。在end方法中，如果最后事务以中止结束，则必须在写入 EndTransaction 记录之前回滚所有修改。查看 rollbackToLSN，了解有关如何回滚的详细信息，并考虑可以将什么 LSN 传递到此方法中以完全回滚事务。</p>
<h4 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h4><p>在正常操作期间，当某些事件发生时会调用多个方法：</p>
<ul>
<li><p>每当有人尝试创建或删除分区或页面时，disk space manager都会调用logAllocPart、logFreePart、logAllocPage、logFreePage这些方法，并添加适当的日志记录。</p>
</li>
<li><p>每当有人尝试往页面写入时，缓冲区管理器就会调用 logPageWrite方法。 该方法创建并添加适当的日志记录，并相应地更新事务表和脏页表。</p>
</li>
</ul>
<p>所有这些方法都应该使recovery manager维护的表保持最新（脏页表和事务表）。</p>
<h4 id="Savepoints"><a href="#Savepoints" class="headerlink" title="Savepoints"></a>Savepoints</h4><p>SQL具有允许部分回滚的保存点：SAVEPOINT pomelo 为当前正在运行的事务创建一个名为 pomelo 的保存点，允许用户使用 ROLLBACK TO SAVEPOINT pomelo 回滚在保存点之后所做的所有更改，并且可以使用 RELEASE SAVEPOINT pomelo 删除保存点。</p>
<p>预写日志记录让我们可以实现保存点。 recovery manager有三个与保存点相关的方法，分别对应保存点的三条SQL语句，并遵循相应SQL语句的语义：</p>
<ul>
<li><p>savepoint 为当前事务创建具有指定名称的保存点。 与 SQL 中的 SAVEPOINT 语句一样，保存点的名称仅限于事务：例如两个不同的事务可能都有名为pomelo专属于自己的保存点。</p>
</li>
<li><p>releaseSavepoint 删除当前事务的指定保存点。它的行为与 SQL 中的 RELEASE SAVEPOINT 语句相同。</p>
</li>
<li><p>rollbackToSavepoint 将事务回滚到指定的保存点。 保存点之后所做的所有更改都应该撤销，类似于中止事务，但事务的状态不会更改。它的行为方式与 SQL 中的 ROLLBACK TO SAVEPOINT 语句相同。</p>
</li>
</ul>
<h4 id="Checkpoints"><a href="#Checkpoints" class="headerlink" title="Checkpoints"></a>Checkpoints</h4><p>在 ARIES 中，我们定期执行模糊检查点，这些检查点甚至在其他事务正在运行时也会执行，以最大程度地减少崩溃后的恢复时间，而不会在Forward Processing期间使数据库停止。</p>
<p>该方法概述如下：</p>
<p>首先，将开始检查点记录添加到日志中。然后，我们写入结束检查点记录，考虑到由于 DPT&#x2F;Xact 表条目过多，我们可能必须分解结束检查点记录。即使所有表都是空的，也应该写入一个结束检查点记录，并且只有在必要时才应该写入多个结束检查点记录。</p>
<p>具体实现如下：</p>
<ul>
<li><p>遍历 dirtyPageTable 并复制条目。如果在任何时候，复制当前记录会导致结束检查点记录太大，则应将带有复制的 DPT 条目的结束检查点记录添加到日志中。</p>
</li>
<li><p>遍历事务表，并复制status&#x2F;lastLSN，根据需要输出结束检查点记录。</p>
</li>
<li><p>输出一个最终结束检查点。</p>
</li>
</ul>
<p>最后，我们必须用新的成功检查点的开始检查点记录的LSN重写主记录。</p>
<p>举个例子：</p>
<p>如果我们有 200 个 DPT 条目和 300 个事务表条目，我们将按以下顺序输出结束检查点记录：</p>
<ul>
<li><p>具有200个DPT条目和52个事务表条目的EndCheckpoint</p>
</li>
<li><p>具有240个事务表条目的EndCheckpoint</p>
</li>
<li><p>具有8个事务表条目的EndCheckpoint</p>
</li>
</ul>
<p>（如果一个结束检查点有 200 个 DPT 条目，则剩余空间最多可容纳 52 个表条目。单个结束检查点最多可容纳 240 个事务表条目。）</p>
<p>你可能会发现 EndCheckpoint.fitsInOneRecord 静态方法对此很有用，它接受两个参数：</p>
<ul>
<li><p>记录中存储的脏页表条目数。</p>
</li>
<li><p>记录中存储的transaction number&#x2F;status&#x2F;lastLSN条目的数量并返回one page是否能装载下resulting record。</p>
</li>
</ul>
<p>比如为了记录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">EndCheckpoint&#123;</span><br><span class="line">  dpt=&#123;1 =&gt; 30000, 2 =&gt; 33000, 3 =&gt; 34000&#125;,</span><br><span class="line">  txnTable=&#123;1 =&gt; (RUNNING, 33000), 2 =&gt; (RUNNING, 34000)&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对应的调用是：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EndCheckpoint.fitsInOneRecord(<span class="number">3</span>, <span class="number">2</span>); <span class="comment">// # of dpt entries, # of txnTable entries</span></span><br></pre></td></tr></table></figure>

<h3 id="Restart-Recovery"><a href="#Restart-Recovery" class="headerlink" title="Restart Recovery"></a>Restart Recovery</h3><p>当数据库再次启动时，进入重启恢复。这涉及三个阶段：analysis, redo, 和undo。RecoveryManager 接口声明了一个用于重启恢复的方法：restart 方法，该方法在数据库启动时调用。</p>
<p>为了单独测试每个阶段，框架具有三个用于重启恢复的包私有辅助方法，需要实现它们：restartAnalysis、restartRedo 和 restartUndo，它们分别执行分析、重做和撤销阶段。</p>
<p>除了恢复的三个阶段之外，重启方法还做了两件事：</p>
<ul>
<li><p>在重做和撤销阶段之间，脏页表中任何实际上不脏的页面（内存中的更改尚未刷新）都应从脏页表中删除。 如果我们不确定一个更改是否已成功刷新到磁盘，这些页面可能会作为分析阶段的结果出现在 DPT 中。</p>
</li>
<li><p>撤销阶段结束后，恢复就完成了。为了避免在崩溃时再次中止所有事务，我们设置了一个检查点。</p>
</li>
</ul>
<h4 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h4><p><strong>Master Record</strong></p>
<p>要开始分析前，需要获取主记录，以便找到作为起点的检查点的 LSN（回想一下，在初始化时，检查点是在日志开头附近写入的，因此总是有一个作为开始的检查点）。</p>
<p><strong>Scanning the Log</strong></p>
<p>分析的目的是从日志中重建脏页表和事务表。扫描时遇到的多种类型的日志记录分为三类：事务执行操作的日志记录、检查点记录以及事务状态更改（提交&#x2F;中止&#x2F;结束）的日志记录（还有主记录，但在扫描日志时永远不应该出现）。</p>
<p><strong>Log Records for Transaction Operations</strong></p>
<p>这些是涉及事务的记录，因此每当遇到这些记录之一时，我们就需要更新事务表。 以下内容适用于 LogRecord#getTransNum() 中具有非空结果的任何记录：</p>
<ul>
<li><p>如果事务不在事务表中，则应将其添加到表中（可以使用newTransaction方法创建一个Transaction对象，将其传递给startTransaction）。</p>
</li>
<li><p>事务的lastLSN应该被更新。</p>
</li>
</ul>
<p><strong>Log Records for Page Operations</strong></p>
<p>对于某些与页面相关的日志记录，需要更新脏页表：</p>
<ul>
<li><p>UpdatePage&#x2F;UndoUpdatePage 都可能弄脏内存中的页面，从而不将更改刷新到磁盘。</p>
</li>
<li><p>FreePage&#x2F;UndoAllocPage 都使它们的更改可以立即在磁盘上可见，并且可以视为将释放的页面刷新到磁盘（从 DPT 中删除页面）。</p>
</li>
<li><p>无需为 AllocPage&#x2F;UndoFreePage 执行任何操作，如果对这种情况下如何恢复释放页面之前的数据感到好奇，我们可以通过在释放页面之前一直编写从 [old bytes] -&gt; [zeroes] 开始的更新日志记录来解决此问题。撤销空闲页面后，撤销这些更新将恢复到旧字节 ([zeroes] -&gt; [old_bytes])。</p>
</li>
</ul>
<p><strong>Log Records for Transaction Status Changes</strong></p>
<p>这三种日志记录（CommitTransaction&#x2F;AbortTransaction&#x2F;EndTransaction）都会改变事务的状态。当遇到其中一条记录时，应按照上一节所述更新事务表。事务的状态还应设置为 COMMITTING、RECOVERY_ABORTING 或 COMPLETE 之一。</p>
<p>如果该记录是EndTransaction记录，则在设置状态之前还应清理该事务，并从事务表中删除该条目。此外，你应该将结束事务的事务编号添加到结束事务集中，这对于处理结束检查点记录非常重要。</p>
<p><strong>Checkpoint Records</strong></p>
<p>当遇到 BeginCheckpoint 记录时，无需执行任何操作。</p>
<p>当遇到 EndCheckpoint 记录时，该记录中存储的表应与当前内存中的表合并：</p>
<p>对于脏页表的检查点快照中的每个条目：</p>
<ul>
<li>即使我们已经在脏页表中有一条记录，也应该始终使用检查点中页面的recLSN，因为检查点总是比我们从日志中推断出的任何内容都更准确。</li>
</ul>
<p>对于事务表的检查点快照中的每个条目：</p>
<ul>
<li><p>在更新事务表条目之前，请检查相应的事务是否已在结束事务中。如果是这样，则事务已经完成，并且可以忽略该条目，因为它包含的任何信息都不再相关。否则：</p>
<ul>
<li><p>如果我们在重建事务表时没有该事务对应的条目，则应该添加它（可以使用newTransaction函数对象创建一个Transaction对象，该对象可以传递给startTransaction）。</p>
</li>
<li><p>如果检查点中事务的lastLSN大于或等于内存事务表中事务的lastLSN，则应使用检查点中事务的lastLSN。</p>
</li>
</ul>
</li>
</ul>
<p>此外，还应更新事务状态。请记住，检查点是模糊的，这意味着它们捕获开始和结束记录之间任何时间的状态。这意味着记录中存储的某些事务状态可能已经过时，例如当我们已经知道事务正在中止时，检查点可能会说事务正在运行。事务始终会以以下两种方式之一的状态中推进：</p>
<ul>
<li><p>running -&gt; committing -&gt; complete</p>
</li>
<li><p>running -&gt; aborting -&gt; complete</p>
</li>
</ul>
<p>仅当检查点中的状态比内存中的状态更“高级”时，你才应该更新事务的状态。举些例子：</p>
<ul>
<li><p>如果检查点显示事务正在中止，而我们的内存表显示其正在运行，我们应该将内存中状态更新为恢复中止，因为它可能从运行转换为中止。</p>
</li>
<li><p>如果检查点显示事务正在运行并且我们的内存表表明其正在提交，那么我们不会更新内存表。在正常操作中，状态无法从提交更改为运行，因此检查点状态一定是过时的。</p>
</li>
</ul>
<p>如果检查点显示正在中止，请确保设置为恢复中止而不是中止</p>
<p><strong>Ending Transactions</strong></p>
<p>此时的事务表应具有处于以下状态之一的事务：RUNNING、COMMITTING 或 RECOVERY_ABORTING。</p>
<ul>
<li><p>所有处于 COMMITTING 状态的事务都应该结束（cleanup()，状态设置为 COMPLETE，写入结束事务记录，并从事务表中删除）。</p>
</li>
<li><p>所有处于 RUNNING 状态的事务都应移至 RECOVERY_ABORTING 状态，并应写入中止事务记录。</p>
</li>
<li><p>对于处于 RECOVERY_ABORTING 状态的事务无需执行任何操作。</p>
</li>
</ul>
<h4 id="Redo"><a href="#Redo" class="headerlink" title="Redo"></a>Redo</h4><p>本节仅涉及 restartRedo 方法，该方法执行重启恢复的重做过程。重做阶段从脏页表中最低的recLSN 开始。从该点开始扫描，如果记录可重做并且满足以下任一条件，我们将重做记录：</p>
<ul>
<li><p>与分区相关的记录（AllocPart、UndoAllocPart、FreePart、UndoFreePart）。</p>
</li>
<li><p>分配页面的记录（AllocPage、UndoFreePage）。</p>
</li>
<li><p>修改页面（UpdatePage、UndoUpdatePage、UndoAllocPage、FreePage）的记录，其中包含以下所有内容：</p>
<ul>
<li><p>该页面位于 DPT 中。</p>
</li>
<li><p>该记录的 LSN 大于或等于该页的 DPT 的 recLSN。</p>
</li>
<li><p>页面本身的 pageLSN 严格小于记录的 LSN。</p>
</li>
</ul>
</li>
</ul>
<p>为了检查页面的 pageLSN，需要从缓冲区管理器中获取它。可以使用以下模板代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Page</span> <span class="variable">page</span> <span class="operator">=</span> bufferManager.fetchPage(<span class="keyword">new</span> <span class="title class_">DummyLockContext</span>(), pageNum);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// Do anything that requires the page here</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    page.unpin();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>缓冲区管理器总是返回一个固定页面，这就是为什么我们使用 try-finally 块来确保页面在使用完毕后始终处于unpin的状态。请注意，我们可以在这里使用虚拟lock context，从而不必担心隔离问题，因为没有其他操作可以与重做阶段同时运行。你可能会发现 Page 类的这个方法在这里很有用。请务必考虑对空日志调用 restartRedo 的情况。</p>
<h4 id="Undo"><a href="#Undo" class="headerlink" title="Undo"></a>Undo</h4><p>本节仅涉及 restartUndo 方法，该方法执行重启恢复的撤销过程。在撤销阶段，我们不会因为产生大量随机 I&#x2F;O 而逐一中止和撤销事务。相反，我们会重复撤销具有最高 LSN 的日志记录（需要撤销的日志记录），直到完成为止，从而只遍历日志一次。撤销阶段从每个中止事务（处于 RECOVERY_ABORTING 状态）的lastLSN 集开始。</p>
<p>我们重复获取这些 LSN 中最大的日志记录，并且：</p>
<ul>
<li><p>如果记录是可撤销的，我们将 CLR 写出并撤销它。</p>
</li>
<li><p>如果有一条记录，则将集合中的 LSN 替换为该记录的 undoNextLSN，否则替换为 prevLSN。</p>
</li>
<li><p>如果上一步的 LSN 为 0，则结​​束事务，将其从集合和事务表中删除。</p>
</li>
</ul>
<p>LogRecord 的 undo 方法实际上并不撤销更改——它只是返回补偿日志记录。要实际撤销更改，需要添加返回的CLR，然后对其调用进行重做。</p>
<h2 id="Important-differences-between-code-and-theories"><a href="#Important-differences-between-code-and-theories" class="headerlink" title="Important differences between code and theories"></a>Important differences between code and theories</h2><p>在理论部分阐述的 ARIES 与项目中需要执行的recovery manager的实现之间有一些重要的区别，其中大部分都是实现细节。</p>
<h3 id="Forward-Processing-1"><a href="#Forward-Processing-1" class="headerlink" title="Forward Processing"></a>Forward Processing</h3><table>
<thead>
<tr>
<th>项目</th>
<th>理论</th>
</tr>
</thead>
<tbody><tr>
<td>Log page&#x2F;partition allocations&#x2F;frees</td>
<td>No such logging</td>
</tr>
<tr>
<td>End Checkpoint may have many records</td>
<td>End Checkpoint is one record</td>
</tr>
</tbody></table>
<ul>
<li><p>我们记录<strong>页面&#x2F;分区</strong>的<strong>分配&#x2F;释放</strong>。这只是我们的disk space manager工作方式的一个怪癖，以确保它可以在崩溃后恢复到一致的状态。</p>
</li>
<li><p>一个检查点可能有许多 end_checkpoint 记录，而在理论部分，仅使用单个 end_checkpoint 记录。这是因为我们需要一页来容纳一条日志记录，实际上我们可能有太多事务&#x2F;脏页，以至于我们无法将其全部容纳在一页中。</p>
</li>
</ul>
<h3 id="Restart-Recovery-1"><a href="#Restart-Recovery-1" class="headerlink" title="Restart Recovery"></a>Restart Recovery</h3><table>
<thead>
<tr>
<th>项目</th>
<th>理论</th>
</tr>
</thead>
<tbody><tr>
<td>Clean up dirty page table after redoing changes</td>
<td>Step does not exist</td>
</tr>
<tr>
<td>Checkpoint after undo</td>
<td>Step does not exist</td>
</tr>
<tr>
<td>Process checkpoints upon reaching end_checkpoint record (single pass)</td>
<td>Load checkpoints before starting analysis (2 passes)</td>
</tr>
<tr>
<td>Process page&#x2F;partition allocation&#x2F;free records</td>
<td>These entries do not exist</td>
</tr>
</tbody></table>
<ul>
<li><p>重做所有更改后，我们将清除缓冲区管理器中所有非脏页的脏页表，而在理论部分，省略了此步骤。我们希望脏页表能够反映实际上脏的页面（因为它们被删除的唯一时刻就是刷新页面时，如果已经刷新的页面不再被修改，则这种情况可能永远不会发生）。</p>
</li>
<li><p>我们在撤销后设置检查点，而在理论部分，省略了此步骤。这是一个相当不重要的步骤（对于正确性而言，这不是必需的——我们在撤销后已完全恢复），但出于性能原因，它是一个有用的点，也是执行检查点的一个自然点，可以避免下次崩溃时的大量工作。</p>
</li>
<li><p>我们对记录进行一次遍历，在到达结束检查点记录时处理检查点，而在理论部分，我们首先创建检查点的表，然后扫描日志。这两种方法是等效的——它们在分析后会产生完全相同的表，但处理 end_checkpoint 记录并在到达它们时将其信息添加到内存中的表中更简单、更高效，特别是因为我们有多个 end_checkpoint 记录。</p>
</li>
<li><p>在某些情况下（free page&#x2F;undo alloc page），我们会从脏页表中删除页面，而在其他情况下（allocate page&#x2F;undo free page），我们不需要将页面添加到脏页表中。这是因为这些操作都会立即更新磁盘上的数据。例如，在分区的末尾分配一个页面会立即增加磁盘上支持该分区的文件大小。</p>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://yeyuhl.github.io">夜语</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://yeyuhl.github.io/2023/09/13/SimpleDB/">https://yeyuhl.github.io/2023/09/13/SimpleDB/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://yeyuhl.github.io" target="_blank">随便写写</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/1a14e4eeedd428147c921881097b3aed8a932201.jpg%40942w_942h_progressive.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/09/27/Redis%E8%A7%A3%E6%9E%90/" title="Redis 解析"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Redis 解析</div></div></a></div><div class="next-post pull-right"><a href="/2023/09/13/RaftKV/" title="RaftKV"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">RaftKV</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/1a14e4eeedd428147c921881097b3aed8a932201.jpg%40942w_942h_progressive.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">夜语</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/yeyuhl"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">随便写写的博客</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#MySQL%E5%AD%98%E5%82%A8%E7%9B%B8%E5%85%B3"><span class="toc-text">MySQL存储相关</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AD%98%E6%94%BE"><span class="toc-text">数据存放</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A8%E7%A9%BA%E9%97%B4%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%E7%BB%84%E6%88%90"><span class="toc-text">表空间文件结构组成</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#B-%E6%A0%91%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%A1%B5"><span class="toc-text">B+树与数据页</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95%E5%88%86%E7%B1%BB"><span class="toc-text">索引分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Buffer-Pool"><span class="toc-text">Buffer Pool</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Buffer-Pool%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-text">Buffer Pool的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86Buffer-Pool"><span class="toc-text">如何管理Buffer Pool</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A9%BA%E9%97%B2%E9%A1%B5"><span class="toc-text">空闲页</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%84%8F%E9%A1%B5"><span class="toc-text">脏页</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E5%91%BD%E4%B8%AD%E7%8E%87"><span class="toc-text">缓存命中率</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95"><span class="toc-text">索引</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#DataBox"><span class="toc-text">DataBox</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RecordId"><span class="toc-text">RecordId</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Index"><span class="toc-text">Index</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MySQL%E6%9F%A5%E8%AF%A2%E7%9B%B8%E5%85%B3"><span class="toc-text">MySQL查询相关</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#select%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="toc-text">select语句执行流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5"><span class="toc-text">连接</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92"><span class="toc-text">执行计划</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#type%EF%BC%88%E9%87%8D%E8%A6%81%EF%BC%89"><span class="toc-text">type（重要）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Extra%EF%BC%88%E9%87%8D%E8%A6%81%EF%BC%89"><span class="toc-text">Extra（重要）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96"><span class="toc-text">连接和查询优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#common-x2F-iterator"><span class="toc-text">common&#x2F;iterator</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#query-x2F-QueryOperator-java"><span class="toc-text">query&#x2F;QueryOperator.java</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Join-Operators"><span class="toc-text">Join Operators</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Nested-Loop-Joins%EF%BC%88%E5%B5%8C%E5%A5%97%E5%BE%AA%E7%8E%AF%E8%BF%9E%E6%8E%A5%EF%BC%89"><span class="toc-text">1. Nested Loop Joins（嵌套循环连接）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-Hash-Joins%EF%BC%88%E5%93%88%E5%B8%8C%E8%BF%9E%E6%8E%A5%EF%BC%89"><span class="toc-text">2. Hash Joins（哈希连接）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-External-Sort"><span class="toc-text">3. External Sort</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-Sort-Merge-Join"><span class="toc-text">4. Sort Merge Join</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scan-Operators"><span class="toc-text">Scan Operators</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Special-Operators"><span class="toc-text">Special Operators</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Other-Operators"><span class="toc-text">Other Operators</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#query-x2F-QueryPlan"><span class="toc-text">query&#x2F;QueryPlan</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SelectPredicate"><span class="toc-text">SelectPredicate</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#JoinPredicate"><span class="toc-text">JoinPredicate</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Query-Optimization"><span class="toc-text">Query Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Common-Heuristics-%E5%90%AF%E5%8F%91%E5%BC%8F"><span class="toc-text">Common Heuristics(启发式)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Single-Table-Access-Selection%EF%BC%88Pass-1%EF%BC%89"><span class="toc-text">Single Table Access Selection（Pass 1）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Join-Selection-Pass-i-gt-1"><span class="toc-text">Join Selection (Pass i &gt; 1)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Optimal-Plan-Selection"><span class="toc-text">Optimal Plan Selection</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MySQL%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6"><span class="toc-text">MySQL并发控制</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E5%8F%8A%E5%85%B6%E7%89%B9%E6%80%A7"><span class="toc-text">事务及其特性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7"><span class="toc-text">事务的隔离性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MVCC"><span class="toc-text">MVCC</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#MVCC%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-text">MVCC的实现</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#read-committed%E5%92%8Crepeatable-read%E7%9A%84%E5%B7%AE%E5%BC%82"><span class="toc-text">read committed和repeatable read的差异</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#read-committed"><span class="toc-text">read committed</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#repeatable-read"><span class="toc-text">repeatable read</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%94%81"><span class="toc-text">锁</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%A8%E7%BA%A7%E9%94%81"><span class="toc-text">表级锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%8C%E7%BA%A7%E9%94%81"><span class="toc-text">行级锁</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B9%B6%E5%8F%91"><span class="toc-text">并发</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Transactions"><span class="toc-text">Transactions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Locking"><span class="toc-text">Locking</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Code"><span class="toc-text">Code</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Layers"><span class="toc-text">Layers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Queuing"><span class="toc-text">Queuing</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#LockType"><span class="toc-text">LockType</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LockManager"><span class="toc-text">LockManager</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Queues"><span class="toc-text">Queues</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Synchronization"><span class="toc-text">Synchronization</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multigranularity"><span class="toc-text">Multigranularity</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#LockContext"><span class="toc-text">LockContext</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LockUtil"><span class="toc-text">LockUtil</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Two-Phase-Locking"><span class="toc-text">Two-Phase Locking</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MySQL-%E6%97%A5%E5%BF%97"><span class="toc-text">MySQL 日志</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#undo-log"><span class="toc-text">undo log</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redo-log"><span class="toc-text">redo log</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#binlog"><span class="toc-text">binlog</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4"><span class="toc-text">两阶段提交</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%81%A2%E5%A4%8D"><span class="toc-text">恢复</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Policy"><span class="toc-text">Policy</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Force-x2F-No-Force"><span class="toc-text">Force&#x2F;No Force</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Steal-x2F-No-Steal"><span class="toc-text">Steal&#x2F;No-Steal</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Steal-No-Force"><span class="toc-text">Steal, No-Force</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Write-Ahead-Logging"><span class="toc-text">Write Ahead Logging</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Update-Log-Record"><span class="toc-text">Update Log Record</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Other-Log-Records"><span class="toc-text">Other Log Records</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WAL-Requirements"><span class="toc-text">WAL Requirements</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WAL-Implementation"><span class="toc-text">WAL Implementation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Aborting-a-Transaction"><span class="toc-text">Aborting a Transaction</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recovery-Data-Structures"><span class="toc-text">Recovery Data Structures</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Undo-Logging"><span class="toc-text">Undo Logging</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redo-Logging"><span class="toc-text">Redo Logging</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ARIES-Recovery-Algorithm"><span class="toc-text">ARIES Recovery Algorithm</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Analysis-Phase"><span class="toc-text">Analysis Phase</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redo-Phase"><span class="toc-text">Redo Phase</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Undo-Phase"><span class="toc-text">Undo Phase</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-text">Conclusion</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Code-1"><span class="toc-text">Code</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Manager"><span class="toc-text">Manager</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Forward-Processing"><span class="toc-text">Forward Processing</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Transaction-Status"><span class="toc-text">Transaction Status</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Logging"><span class="toc-text">Logging</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Savepoints"><span class="toc-text">Savepoints</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Checkpoints"><span class="toc-text">Checkpoints</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Restart-Recovery"><span class="toc-text">Restart Recovery</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Analysis"><span class="toc-text">Analysis</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redo"><span class="toc-text">Redo</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Undo"><span class="toc-text">Undo</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-differences-between-code-and-theories"><span class="toc-text">Important differences between code and theories</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Forward-Processing-1"><span class="toc-text">Forward Processing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Restart-Recovery-1"><span class="toc-text">Restart Recovery</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/05/09/%E5%88%B7%E9%A2%98%E5%96%B5/" title="刷题喵">刷题喵</a><time datetime="2024-05-09T13:29:19.000Z" title="发表于 2024-05-09 21:29:19">2024-05-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/05/09/JVM%E6%B5%85%E6%9E%90/" title="JVM浅析">JVM浅析</a><time datetime="2024-05-09T13:22:40.000Z" title="发表于 2024-05-09 21:22:40">2024-05-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/05/09/Java%E5%B9%B6%E5%8F%91%E7%9B%B8%E5%85%B3/" title="Java并发相关">Java并发相关</a><time datetime="2024-05-09T13:22:14.000Z" title="发表于 2024-05-09 21:22:14">2024-05-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/05/09/Spring%E9%83%A8%E5%88%86%E5%8E%9F%E7%90%86%E6%B5%85%E6%9E%90/" title="Spring部分原理浅析">Spring部分原理浅析</a><time datetime="2024-05-09T13:17:07.000Z" title="发表于 2024-05-09 21:17:07">2024-05-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/12/25/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/" title="计算机体系结构期末复习">计算机体系结构期末复习</a><time datetime="2023-12-25T08:52:19.000Z" title="发表于 2023-12-25 16:52:19">2023-12-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By 夜语</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>