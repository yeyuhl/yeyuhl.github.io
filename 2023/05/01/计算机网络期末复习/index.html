<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>计算机网络期末复习 | 随便写写</title><meta name="author" content="夜语"><meta name="copyright" content="夜语"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="计算机网络期末复习 教材：《计算机网络：自顶向下方法》  第一章 计算机网络和因特网 题目 P5 P6 P7 P31  1.1 什么是因特网协议（protocol）定义了在两个或多个通信实体之间交换的报文的格式和顺序，以及报文发送和&#x2F;或接收一条报文或其他事件所采取的动作。 1.2 网络边缘物理媒体分成导引型媒体和非导引型媒体。对于导引型媒体, 电波沿着固体媒体前行，如光缆、双绞铜线或同轴">
<meta property="og:type" content="article">
<meta property="og:title" content="计算机网络期末复习">
<meta property="og:url" content="https://yeyuhl.github.io/2023/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/index.html">
<meta property="og:site_name" content="随便写写">
<meta property="og:description" content="计算机网络期末复习 教材：《计算机网络：自顶向下方法》  第一章 计算机网络和因特网 题目 P5 P6 P7 P31  1.1 什么是因特网协议（protocol）定义了在两个或多个通信实体之间交换的报文的格式和顺序，以及报文发送和&#x2F;或接收一条报文或其他事件所采取的动作。 1.2 网络边缘物理媒体分成导引型媒体和非导引型媒体。对于导引型媒体, 电波沿着固体媒体前行，如光缆、双绞铜线或同轴">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/1a14e4eeedd428147c921881097b3aed8a932201.jpg%40942w_942h_progressive.webp">
<meta property="article:published_time" content="2023-05-01T13:04:51.000Z">
<meta property="article:modified_time" content="2023-05-02T07:34:04.869Z">
<meta property="article:author" content="夜语">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/1a14e4eeedd428147c921881097b3aed8a932201.jpg%40942w_942h_progressive.webp"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://yeyuhl.github.io/2023/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '计算机网络期末复习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-02 15:34:04'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/1a14e4eeedd428147c921881097b3aed8a932201.jpg%40942w_942h_progressive.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">4</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/wallhaven-p9woe3.png')"><nav id="nav"><span id="blog-info"><a href="/" title="随便写写"><span class="site-name">随便写写</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">计算机网络期末复习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-01T13:04:51.000Z" title="发表于 2023-05-01 21:04:51">2023-05-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-02T07:34:04.869Z" title="更新于 2023-05-02 15:34:04">2023-05-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="计算机网络期末复习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="计算机网络期末复习"><a href="#计算机网络期末复习" class="headerlink" title="计算机网络期末复习"></a>计算机网络期末复习</h1><blockquote>
<p>教材：《计算机网络：自顶向下方法》</p>
</blockquote>
<h2 id="第一章-计算机网络和因特网"><a href="#第一章-计算机网络和因特网" class="headerlink" title="第一章 计算机网络和因特网"></a>第一章 计算机网络和因特网</h2><blockquote>
<p>题目 P5 P6 P7 P31</p>
</blockquote>
<h3 id="1-1-什么是因特网"><a href="#1-1-什么是因特网" class="headerlink" title="1.1 什么是因特网"></a>1.1 什么是因特网</h3><p><strong>协议</strong>（protocol）定义了在两个或多个通信实体之间交换的报文的格式和顺序，以及报文发送和&#x2F;或接收一条报文或其他事件所采取的动作。</p>
<h3 id="1-2-网络边缘"><a href="#1-2-网络边缘" class="headerlink" title="1.2 网络边缘"></a>1.2 网络边缘</h3><p>物理媒体分成<strong>导引型媒体</strong>和<strong>非导引型媒体</strong>。对于导引型媒体, 电波沿着固体媒体前行，如光缆、双绞铜线或同轴电缆。对于非导引型媒体，电波在空气或外层空间中传播，例如在无线局域网或数字卫星频道中。</p>
<p><strong>双绞铜线</strong>：最便宜且最常用的导引型传输媒体，无屏蔽双绞线常用于建筑物内的计算机网络中（局域网），速度一般从10Mbps到10Gbps。</p>
<p><strong>同轴电缆</strong>：能被用作导引型共享媒体。许多端系统能够直接与该电缆相连，每个端系统都能接收由其他端系统发送的内容。 </p>
<p><strong>光纤</strong>：一种细而柔软的、能够导引光脉冲的媒体，每个脉冲表示一个比特。一根光纤能够支持极高的比特速率，高达数十甚至数百Gbps。它们不受电磁干扰，长达100km的光缆信号衰减极低，并且很难窃听。</p>
<p><strong>陆地无线电信道</strong>：无线电信道承载电磁频谱中的信号。它不需要安装物理线路，并具有穿透墙壁、提供与移动用户的连接以及长距离承载信号的能力，因而成为一种有吸引力的媒体。</p>
<p><strong>卫星无线电信道</strong>：一颗通信卫星连接地球上的两个或多个微波发射器&#x2F;接收器，它们被称为地面站。该卫星在一个频段上接收传输，使用一个转发器（下面讨论）再生信号，并在另一个频率上发射信号。</p>
<h3 id="1-3-网络核心（三种数据交换）"><a href="#1-3-网络核心（三种数据交换）" class="headerlink" title="1.3 网络核心（三种数据交换）"></a>1.3 网络核心（三种数据交换）</h3><p><strong>电路交换</strong>需要建立一条专用的数据通信路径，在通信期间该路径将被独占。</p>
<ul>
<li>优点：<ul>
<li>通信时延小。</li>
<li>线路独占，没有冲突。</li>
<li>实时性强。</li>
</ul>
</li>
<li>缺点：<ul>
<li>线路独占，利用率低。</li>
<li>连接建立时间过长。</li>
</ul>
</li>
</ul>
<p><strong>报文交换</strong>以报文作为数据传输单位，携带源地址和目的地址等信息。</p>
<ul>
<li>优点：<ul>
<li>无需建立连接。</li>
<li>动态分配线路。</li>
<li>线路利用率高。</li>
</ul>
</li>
<li>缺点：<ul>
<li>报文交换对报文大小没有限制，需要网络结点有足够缓存空间。</li>
<li>报文交换在结点处要进行存储转发，会造成一定时延。</li>
</ul>
</li>
</ul>
<p><strong>分组交换</strong>在报文交换的基础上，对大的数据块切割成小的分组，并添加源地址，目的地址和分组编号等信息。</p>
<ul>
<li>优点<ul>
<li>无需建立连接。</li>
<li>动态分配路线。</li>
<li>线路利用率高。</li>
<li>相对报文交换，分组长度固定，缓冲区容易管理。</li>
<li>分组比报文更小，并行传输其传输时间比报文交换更短。</li>
</ul>
</li>
<li>缺点<ul>
<li>仍然存在时延。</li>
<li>需要传输更多的额外信息，比如源地址，目的地址和分组编号。</li>
<li>分组可能出现失序、丢失、重复等问题。 <img src="https://pic4.zhimg.com/80/v2-c265127be7ffecc45f135140f83d7a77_720w.webp"></li>
</ul>
</li>
</ul>
<h3 id="1-4-分组交换网中的时延概述"><a href="#1-4-分组交换网中的时延概述" class="headerlink" title="1.4 分组交换网中的时延概述"></a>1.4 分组交换网中的时延概述</h3><p>当分组从一个节点(主机或路由器)沿着这条路径到后继节点(主机或路由器)，该分组在沿途的每个节点经受了几种不同类型的时延。这些时延最为重要的是<strong>节点处理时延</strong>(nodal processing delay) 、<strong>排队时延</strong>(queuing delay)、<strong>传输时延</strong>(transmission delay)和<strong>传播时延</strong>(propagation delay)，这些时延总体累加起来是<strong>节点总时延</strong>(tolal nodal delay)。</p>
<h4 id="（1）处理时延"><a href="#（1）处理时延" class="headerlink" title="（1）处理时延"></a>（1）处理时延</h4><p>检查分组首部和决定将该分组导向何处所需要的时间是处理时延的一部分。处理时延也能够包括其他因素，如检查比特级别的差错所需要的时间，该差错岀现在从上游节点向路由器A传输这些分组比特的过程中。</p>
<h4 id="（2）排队时延"><a href="#（2）排队时延" class="headerlink" title="（2）排队时延"></a>（2）排队时延</h4><p>在队列中，当分组在链路上等待传输时，它经受排队时延。</p>
<h4 id="（3）传输时延"><a href="#（3）传输时延" class="headerlink" title="（3）传输时延"></a>（3）传输时延</h4><p>假定分组以先到先服务方式传输——这在分组交换网中是常见的方式，仅当所有已经到达的分组被传输后，才能传输刚到达的分组。用L比特表示该分组的长度，用Rbps(即b&#x2F;s)表示从路由器A到路由器B的链路传输速率。例如，对于一条10Mbps的以太网链路，速率R&#x3D;10Mbps；对于100Mbps的以太网链路，速率R &#x3D; 100Mbps。<strong>传输时延是L&#x2F;R</strong>。这是将所有分组的比特推向链路(即传输，或者说发射)所需要的时间。</p>
<h4 id="（4）传播时延"><a href="#（4）传播时延" class="headerlink" title="（4）传播时延"></a>（4）传播时延</h4><p>一旦一个比特被推向链路，该比特需要向路由器B传播。从该链路的起点到路由器B传播所需要的时间是传播时延。该比特以该链路的传播速率传播。该传播速率取决于该链路的物理媒体（即光纤、双绞铜线等），其速率范围是2 * 10^8-3*10^8m&#x2F;s，这等于或略小于光速。该传播时延等于两台路由器之间的距离除以传播速率。即<strong>传播时延是d&#x2F;s</strong>，其中d是路由器A和路由器B之间的距离，s是该链路的传播速率。</p>
<h4 id="（5）传输时延和传播时延的比较"><a href="#（5）传输时延和传播时延的比较" class="headerlink" title="（5）传输时延和传播时延的比较"></a>（5）传输时延和传播时延的比较</h4><p>传输时延是路由器推出分组所需要的时间，它是分组长度和链路传输速率的函数，而与两台路由器之间的距离无关。另一方面，传播时延是一个比特从一台路由器传播到另一台路由器所需要的时间，它是两台路由器之间距离的函数，而与分组长度或链路传输速率无关。打个比方，考虑一条公路每100km有一个收费站，可认为收费站间的公路段是链路，收费站是路由器。假定汽车以100km&#x2F;h的速度（也就是说当一辆汽车离开一个收费站时，它立即加速到100km&#x2F;h并在收费站间维持该速度）在该公路上行驶（即传播）。假定这时有10辆汽车作为一个车队在行驶，并且这10辆汽车以固定的顺序互相跟随。可以认为每辆汽车是一个比特，该车队是一个分组。同时假定每个收费站以每辆车12s的速度服务（即传输）一辆汽车，并且由于时间是深夜，因此该车队是公路上唯一一批汽车。最后，假定无论该车队的第一辆汽车何时到达收费站，它在入口处等待，直到其他9辆汽车到达并整队依次前行。（因此，整个车队在它能够“转发”之前，必须存储在收费站。）<strong>收费站将整个车队推向公路所需要的时间</strong>是（10辆车）&#x2F;（5辆车&#x2F;min）&#x3D;2min该时间<strong>类比于一台路由器中的传输时延</strong>。<strong>一辆汽车从一个收费站出口行驶到下一个收费站所需要的时间</strong>是100km&#x2F;（100km&#x2F;h）&#x3D;1h这个时间<strong>类比于传播时延</strong>。因此，从该车队存储在收费站前到该车队存储在下一个收费站前的时间是“传输时延”与“传播时间”总和，在本例中为62min。</p>
<h4 id="（6）节点的总时延"><a href="#（6）节点的总时延" class="headerlink" title="（6）节点的总时延"></a>（6）节点的总时延</h4><p>节点总时延&#x3D;处理时延+排队时延+传输时延+传播时延<br>d_{nodal}&#x3D;d_{proc}+d_{queue}+d_{trans}+d_{prop}</p>
<h3 id="1-5-协议分层"><a href="#1-5-协议分层" class="headerlink" title="1.5 协议分层"></a>1.5 协议分层</h3><p>利用分层的体系结构，我们可以讨论一个大而复杂系统的定义良好的特定部分。这种简化本身由于<strong>提供模块化</strong>而具有很高价值，这使<strong>某层所提供的服务实现易于改变</strong>。只要该层对其上面的层提供相同的服务，并且使用来自下面层次的相同服务，当某层的实现变化时，该系统的其余部分保持不变。对于大而复杂且需要不断更新的系统，<strong>改变服务的实现而不影响该系统其他组件是分层</strong>是另一个重要优点。为了给网络协议的设计提供一个结构，网络设计者以分层（layer）的方式组织协议以及实现这些协议的网络硬件和软件。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501203324.png"> 应用层：直接为用户的应用进程提供服务。<br>HTTP、SMTP、FTP、DNS（报文）<br>运输层：在应用程序端口之间传送应用层报文的服务。<br>TCP、UDP（报文段）<br>网络层：将数据报从一台主机移动到另一台主机。<br>IP、ICMP、ARP、RIP（数据报）<br>链路层：将数据报封装成帧沿端到端路径上的各段链路传输。<br>以太网、WiFi（帧）</p>
<h2 id="第二章-应用层"><a href="#第二章-应用层" class="headerlink" title="第二章 应用层"></a>第二章 应用层</h2><blockquote>
<p>题目 P1 P4 P10 P22</p>
</blockquote>
<h3 id="2-2-HTTP"><a href="#2-2-HTTP" class="headerlink" title="2.2 HTTP"></a>2.2 HTTP</h3><h4 id="（1）HTTP概况"><a href="#（1）HTTP概况" class="headerlink" title="（1）HTTP概况"></a>（1）HTTP概况</h4><p>20世纪90年代初期，一个主要的新型应用即万维网（World Wide Web）登上了舞台［Berners-Lee 1994]。 Web是一个引起公众注意的因特网应用，它极大地改变了人们与工作环境内外交流的方式。</p>
<p>Web的应用层协议是<strong>超文本传输协议</strong>（HyperText Transfer Protocol, <strong>HTTP</strong>），它是Web的核心，在［RFC 1945］和［RFC 2616］中进行了定义。HTTP由两个程序实现：一个客户程序和一个服务器程序。首先来介绍一下Web的相关术语。Web页面（Webpage）（也叫文档）是由对象组成的。一个对象（object）只是一个文件，诸如一个HTML文件、一个JPEG图形、一个Java小程序或一个视频片段这样的文件,且它们可通过一个URL地址寻址。多数Web页面含有一个HTML基本文件（base HTML file）以及几个引用对象。例如，如果一个Web页面包含HTML文本和5个JPEG图形，那么这个Web页面有6个对象：一个HTML基本文件加5个图形。</p>
<p>HTTP定义了 Web客户向Web服务器请求Web页面的方式，以及服务器向客户传送Web页面的方式。当用户请求一个Web页面服务器发出对该页面中所包含对象的HTTP请求报文，服务器接收到请求并用包含这些对象的HTTP响应报文进行响应。</p>
<p><strong>HTTP</strong>使用<strong>TCP</strong>作为它的<strong>支撑运输协议</strong>，且是一个<strong>无状态协议</strong>。所谓无状态指：<strong>服务器向客户发送被请求的文件，而不存储任何关于该客户的状态信息</strong>。假如某个特定的客户在短短的几秒内两次请求同一个对象，服务器并不会因为刚刚为该客户提供了该对象就不再做出反应，而是重新发送该对象，就像服务器已经完全忘记不久之前所做过的事一样。</p>
<h4 id="（2）非持续连接和持续连接"><a href="#（2）非持续连接和持续连接" class="headerlink" title="（2）非持续连接和持续连接"></a>（2）非持续连接和持续连接</h4><p>一般客户和服务器在一个相当长的时间范围内通信，其中客户发出一系列请求并且服务器对每个请求进行响应。<strong>每个请求&#x2F;响应对是经一个单独的TCP连接发送的</strong>被称为使用<strong>非持续连接</strong>，而<strong>所有的请求及其响应经相同的TCP连接发送的</strong>被称为<strong>使用持续连接</strong>。</p>
<p>非持续连接情况下，从服务器向客户传送一个Web页面的步骤。假设该页面含有一个HTML基本文件和10个JPEG图形，并且这11个对象位于同一台服务器上。进一步假设该 HTML 文件的 URL 为：http:&#x2F;&#x2F; <a target="_blank" rel="noopener" href="http://www.someschool.edu/someDepartment/home.index%E3%80%82">www.someSchool.edu/someDepartment/home.index。</a><br>我们看看发生了什么情况：<br>1）HTTP客户进程在<strong>端口号80</strong>发起一个到服务器<a target="_blank" rel="noopener" href="http://www.someschool.edu的tcp连接,该端口号是http的默认端口.在客户和服务器上分别有一个套接字与该连接相关联./">www.someSchool.edu的TCP连接，该端口号是HTTP的默认端口。在客户和服务器上分别有一个套接字与该连接相关联。</a><br>2）HTTP客户经它的套接字向该服务器发送一个HTTP请求报文。请求报文中包含了路径名&#x2F;someDepartment&#x2F;home. index（后面我们会详细讨论HTTP报文）。<br>3）HTTP服务器进程经它的套接字接收该请求报文，从其存储器（RAM或磁盘）中检索出对象 <a target="_blank" rel="noopener" href="http://www.someschool.edu/someDepartment/home.index%EF%BC%8C%E5%9C%A8%E4%B8%80%E4%B8%AA">www.someSchool.edu/someDepartment/home.index，在一个</a> HTTP 响应报文中封装对象，并通过其套接字向客户发送响应报文。<br>4）HTTP服务器进程通知TCP断开该TCP连接。（但是直到TCP确认客户已经完整地收到响应报文为止，它才会实际中断连接。）<br>5）HTTP客户接收响应报文，TCP连接关闭。该报文指岀封装的对象是一个HTML文件，客户从响应报文中提取出该文件，检査该HTML文件，得到对10个JPEG图形的引用。<br>6）对每个引用的JPEG图形对象重复前4个步骤。<br>上面的步骤举例说明了非持续连接的使用，其中每个TCP连接在服务器发送一个对象后关闭，每个TCP连接只传输一个请求报文和一个响应报文。因此在本例中，当用户请求该Web页面时，要产生11个TCP连接。</p>
<p>此处顺势给出<strong>往返时间</strong>（Round Trip Time, RTT）的定义，该时间是指<strong>一个短分组从客户到服务器然后再返回客户所花费的时间</strong>。RTT包括分组传播时延、分组在中间路由器和交换机上的排队时延以及分组处理时延。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501203700.png"></p>
<p>非持续连接存在两个明显缺点，一是必须为每一个请求的对象建立和维护一个<strong>全新的连接</strong>，二是每一个对象经受<strong>两倍RTT</strong>的交付时延。而持续连接，对服务器在发送响应后保持该TCP连接打开。在相同的客户与服务器之间，后续的请求和响应报文能够通过相同的连接进行传送。特别是，一个完整的Web页面（上例中的HTML基本文件加上10个图形）可以用单个持续TCP连接进行传送。一般来说，如果一条连接经过一定时间间隔（一个可配置的超时间隔）仍未被使用，HTTP服务器就关闭该连接。HTTP的默认模式是使用带流水线的持续连接。</p>
<h4 id="（3）HTTP请求报文"><a href="#（3）HTTP请求报文" class="headerlink" title="（3）HTTP请求报文"></a>（3）HTTP请求报文</h4><p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501203721.png"> 在首部行（和附加的回车和换行）后有一个“实体体”（entity body）。使用GET方法时实体体为空，而使用POST方法时才使用该实体体。当用户提交表单时，HTTP客户常常使用POST方法，例如当用户向搜索引擎提供搜索关键词时。使用POST报文时，用户仍可以向服务器请求一个Web页面，但Web页面的特定内容依赖于用户在表单字段中输入的内容。如果方法字段的值为POST时，则实体体中包含的就是用户在表单字段中的输入值。（其余内容查看实验1即可）</p>
<h4 id="（4）HTTP响应报文"><a href="#（4）HTTP响应报文" class="headerlink" title="（4）HTTP响应报文"></a>（4）HTTP响应报文</h4><p>响应报文由三个部分组成：一个初始状态行（status line） , 6个首部行（headerline），然后是实体体（entity body）。实体体部分是报文的主要部分，即它包含了所请求的对象本身（表示为data data data data data）。</p>
<h4 id="（5）cookie"><a href="#（5）cookie" class="headerlink" title="（5）cookie"></a>（5）cookie</h4><p>为了简化服务器的设计，HTTP的服务器是无状态的，即协议对于交互性场景没有记忆能力，请求什么就相应什么。但我们有时希望我们能识别到连接的用户，又或者是希望把内容与用户身份联系起来。因此HTTP使用了cookie，它允许站点对用户进行跟踪。</p>
<p>cookie技术有4个组件：</p>
<p>①在HTTP响应报文中的一个cookie首部行；</p>
<p>②在HTTP请求报文中的一个cookie首部行；</p>
<p>③在用户端系统中保留有一个cookie文件（实际上是一小段文本信息，key-value格式），并由用户的浏览器进行管理；</p>
<p>④位于Web站点的一个后端数据库。</p>
<p>使客户端向服务器发起请求，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个cookie。客户端浏览器会把cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该cookie一同提交给服务器。服务器检查该cookie，以此来辨认用户状态。比如我们登录网站的时候选择记住密码，服务器记录了你的操作，给你一个cookie，下次登录浏览器将cookie给服务器，你就不需要再次输入账号密码来登录了。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501203757.png"></p>
<h4 id="（6）Web缓存"><a href="#（6）Web缓存" class="headerlink" title="（6）Web缓存"></a>（6）Web缓存</h4><p>Web缓存器有自己的磁盘存储空间，并在存储空间中保存最近请求过的对象的副本。一旦某浏览器被配置，每个对某对象的浏览器请求首先被定向到该Web缓存器。假如Web缓存器中有该对象副本，直接向客户端用HTTP响应报文返回该对象；如果没有，就往该对象初始服务器请求，并将该对象在本地存储一份副本，接着向客户端返回该副本。</p>
<p>这种代理服务器的优点是：<br>①大大减少对客户请求的响应时间。<br>②能从整体上大大减低因特网上的Web流量，从而改善了所有应用的性能（即减少了网络宽带的消耗）。</p>
<h4 id="（7）条件GET"><a href="#（7）条件GET" class="headerlink" title="（7）条件GET"></a>（7）条件GET</h4><p>为了减少对客户请求的响应时间并且减少一个机构的接入链路到因特网的通信量，我们可以布置Web缓存器。Web缓存器有自己的磁盘存储空间，并在存储空间中保存最近请求过的对象的副本。但存放在缓存器中的对象副本可能是陈旧的。换句话说，保存在服务器中的对象自该副本缓存在客户上以后可能已经被修改了。</p>
<p>而HTTP提供条件GET （conditional GET）方法，允许缓存器证实它的对象是最新的。如果：①请求报文使用GET方法；并且②请求报文中包含一个“ If Modified-Since: ”首部行。那么，这个HTTP请求报文就是一个条件GET请求报文。</p>
<h3 id="2-3-电子邮件"><a href="#2-3-电子邮件" class="headerlink" title="2.3 电子邮件"></a>2.3 电子邮件</h3><p>因特网电子邮件系统由三个部分组成：用户代理、邮件服务器和简单邮件传输协议（SMTP）。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501203812.png"> 一般来说②和⑥现在都使用HTTP协议，④使用的SMTP使用的是TCP连接，并且一般在25号端口通信。</p>
<p>HTTP主要是一个拉协议（pull protocol），即在方便的时候，某些人在Web服务器上装载信息，用户使用HTTP从该服务器拉取这些信息。特别是TCP连接是由想接收文件的机器发起的。另一方面，SMTP基本上是一个推协议（push protocol），即发送邮件服务器把文件推向接收邮件服务器。特别是，这个TCP连接是由要发送该文件的机器发起的。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501203825.png"> SMTP用来将邮件从发送方的邮件服务器传输到接收方的邮件服务器；SMTP也用来将邮件从发送方的用户代理传送到发送方的邮件服务器。如POP3这样的邮件访问协议用来将邮件从接收方的邮件服务器传送到接收方的用户代理。</p>
<p>POP3是一个极为简单的邮件访问协议，当用户代理（客户）打开了一个到邮件服务器（服务器）<strong>端口110</strong>上的TCP连接后，POP3就开始工作了。随着建立TCP连接，POP3按照三个阶段进行工作：特许（authorization）、事务处理、更新。</p>
<h3 id="2-4-DNS"><a href="#2-4-DNS" class="headerlink" title="2.4 DNS"></a>2.4 DNS</h3><p>DNS的主要功能是将用户提供的主机名解析为IP地址。DNS是：①一个由分层的DNS服务器（DNS server）实现的分布式数据库；②一个使得主机能够查询分布式数据库的应用层协议。DNS 服务器通常是运行 BIND （ Berkeley Internet Name Domain）软件的UNIX机器。而DNS协议运行在UDP之上，使用<strong>53号端口</strong>。</p>
<p>为了解决扩展性问题，DNS使用了大量DNS服务器，并且分为3种类型：根DNS服务器，顶级域（TLD）DNS服务器和权威服务器。除此以外还有一种叫做本地DNS服务器，虽然不属于服务器层次结构中，但是对于DNS层次结构十分重要。DNS的查询过程如下：</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501203843.png"> </p>
<p>简单概括就是当主机想要知道某个网址对应的IP地址时，会向本地的DNS服务器发送一个DNS查询报文，如果本地DNS服务器没有缓存这个IP地址，那么就会将报文转发到根DNS服务器，根DNS根据edu的前缀并向本地DNS服务器返回负责edu的TLD的IP地址列表。如此类推直到主机获得该地址。</p>
<p>其中，从cse. nyu. edu到dns. nyu. edu发出的查询是<strong>递归查询</strong>，因为该查询以自己的名义请求dns. nyu. edu来获得该映射。而后继的3个查询是<strong>迭代查询</strong>，因为所有的回答都是直接返回给dns. nyu. edu。</p>
<h3 id="2-5-P2P文件分发"><a href="#2-5-P2P文件分发" class="headerlink" title="2.5 P2P文件分发"></a>2.5 P2P文件分发</h3><p>在一个 <strong>P2P体系结构</strong>（P2P architecture）中，对位于数据中心的专用服务器有最小的（或者没有）依赖。相反，应用程序在间断连接的主机对之间使用直接通信，这些主机对被称为<strong>对等方</strong>。P2P体系结构的最引人入胜的特性之一是它们的<strong>自扩展性</strong>（self-scalability） 。例如，在一个P2P文件共享应用中，尽管每个对等方都由于请求文件产生工作负载，但每个对等方通过向其他对等方分发文件也为系统增加服务能力。</p>
<p>我们研究一个非常自然的P2P应用，即从单一服务器向大量主机（称为对等方）分发一个大文件。在客户-服务器文件分发中，该服务器必须向每个对等方发送该文件的一个副本，即服务器承受了极大的负担，并且消耗了大量的服务器带宽。在P2P文件分发中，每个对等方能够向任何其他对等方重新分发它已经收到的该文件的任何部分，从而在分发过程中协助该服务器。为了分析这两种结构，我们设计一个简单定量模型——将一个文件分发给一个固定对等方集合。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501203915.png"> 其中u_s表示服务器接入链路的上载速率，u_i表示第i对等方接入链路的上载速率，d_i表示了第i对等方接入链路的下载速率。还用F表示被分发的文件长度（以比特计），N表示要获得的该文件副本的对等方的数量。<strong>分发时间</strong>（distribution time）是所有N个对等方得到该文件的副本所需要的时间。</p>
<p>对于C-S体系结构，由于没有对等方参与来帮助分发文件，因此：<br>①服务器必须向N个对等方的每个传输该文件的一个副本。因此该服务器必须传输NF比特。因为该服务器的上载速率是u_s，分发该文件的时间必定是至少为NF&#x2F;u_s。<br>②令d_{min}表示具有最小下载速率的对等方的下载速率，即d_{min}&#x3D;min{d_1，d_p，…，d_N}。具有最小下载速率的对等方不可能在少于F&#x2F;d_{min}秒时间内获得该文件的所有F比特。因此最小分发时间至少为F&#x2F;d_{min}。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501203936.png"> </p>
<p>（实际计算中取等号作为于客户-服务器体系结构的最小分发时间。）</p>
<p>对于P2P体系结构，其中每个对等方能够帮助服务器分发该文件，因此：<br>①在分发的开始，只有服务器具有文件。为了使社区的这些对等方得到该文件，该服务器必须经其接入链路至少发送该文件的每个比特一次。因此，最小分发时间至少是F&#x2F;u_s（与客户-服务器方案不同，由服务器发送过一次的比特可能不必由该服务器再次发送，因为对等方在它们之间可以重新分发这些比特。）<br>②与客户-服务器体系结构相同，具有最低下载速率的对等方不能够以小于F&#x2F;d_{min}秒的分发时间获得所有F比特。因此最小分发时间至少为F&#x2F;d_{min}。<br>③最后，观察到系统整体的总上载能力等于服务器的上载速率加上每个单独的对等方的上载速率，即u_{total}&#x3D;u_s+u_1+…+u_N。系统必须向这N个对等方的每个交付（上载）F比特，因此总共交付NF比特。这不能以快于u_{total}的速率完成。因此,最小的分发时间也至少是NF&#x2F;(u_s+u_1+…+u_N)。</p>
<p> <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501203952.png"> </p>
<p>（实际计算中取等号作为于P2P体系结构的最小分发时间。）</p>
<h2 id="第三章-传输层"><a href="#第三章-传输层" class="headerlink" title="第三章 传输层"></a>第三章 传输层</h2><blockquote>
<p>题目 P1 P3 P11 P12 P23 P27 P40 P56</p>
</blockquote>
<h3 id="3-1-概述运输层"><a href="#3-1-概述运输层" class="headerlink" title="3.1 概述运输层"></a>3.1 概述运输层</h3><p><strong>网络层</strong>为网络中的两个端系统提供逻辑通信，<strong>运输层</strong>为网络中两个端系统上的应用进程提供逻辑通信。</p>
<h3 id="3-3-UDP"><a href="#3-3-UDP" class="headerlink" title="3.3 UDP"></a>3.3 UDP</h3><h4 id="UDP概述"><a href="#UDP概述" class="headerlink" title="UDP概述"></a>UDP概述</h4><p>UDP 是<strong>无连接</strong>的，因为 UDP 没有握手阶段，不会为这次 UDP 通信过程维护状态变量。</p>
<p><strong>选择 UDP 的理由</strong>:</p>
<ul>
<li><p>应用层对何时、发送什么数据可以控制得更为精细</p>
<ul>
<li><p>TCP 发送数据时，先将数据放入发送缓冲区，然后再从发送缓冲区中拿出一块数据，附上运输层首部字段成为 TCP 报文段，再进行发送。从缓冲区中拿出的数据可能会多也可能会少，这取决于 MSS、流量控制 以及拥塞控制、以及应用层往 TCP 套接字中注入数据的速率等几个方面。而 UDP 不一样，无论应用交给 UDP 多长的数据，UDP 都将它压缩在一个报文段内发送(⚠️ UDP 的首部字段中描述长度信息的域仅为两个字节，即最大 UDP 包为 65535 字节)。因此应用程序对在报文段中发送什么数据有更多的控制。</p>
</li>
<li><p>TCP 的拥塞控制会遏制发送方的速率。</p>
</li>
<li><p>发生丢包或失序时 TCP 发送方会重传而不管可靠交付需要用多长时间，因此在能容忍部分丢失和希望有最小发送速率的实时应用上，TCP 并不适合。</p>
</li>
</ul>
</li>
<li><p>无需连接建立：不会引入建立连接时延，两个RTT。</p>
</li>
<li><p>无连接状态：接收双方无需为连接状态维护状态变量，比如接收和发送缓存，拥塞控制参数、序列号、确认号参数。</p>
</li>
<li><p>分组首部开销小：TCP 20 字节首部开销，UDP 8 字节。</p>
</li>
</ul>
<p>(⚠️为了安全原因，很多防火墙被配置为阻塞 UDP 流量，因此对于图像和音视频流量，很多是建立在 TCP 之上的。) <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204007.png"></p>
<h4 id="UDP检验和"><a href="#UDP检验和" class="headerlink" title="UDP检验和"></a>UDP检验和</h4><p>UDP检验和提供了<strong>差错检测</strong>功能。这就是说，检验和用于确定当UDP报文段从源到达目的地移动时，其中的比特是否发生了改变（例如，由于链路中的噪声干扰或者存储在路由器中时引入问题）。发送方的UDP对报文段中的所有16比特字的和<strong>进行反码运算</strong>，求和时遇到的<strong>任何溢出都被回卷</strong>。得到的结果被放在UDP报文段中的检验和字段。<br>举个例子：<br>  0110011001100000<br>+ 0101010101010101<br>&#x3D; 1011101110110101<br>+ 1000111100001100<br>&#x3D; 0100101011000010(由于存在溢出，要回卷，即把溢出部分加回到最低位)</p>
<p>该和0100101011000010的反码运算结果是1011010100111101, 这就变成了检验和。在接收方，全部的4个16比特字（包括检验和）加在一起。如果该分组中没有引入差错，则显然在接收方处该和将是1111111111111111如果这些比特之一是0，那么我们就知道该分组中已经出现了差错。</p>
<h3 id="3-4-可靠数据传输原理"><a href="#3-4-可靠数据传输原理" class="headerlink" title="3.4 可靠数据传输原理"></a>3.4 可靠数据传输原理</h3><blockquote>
<p>基于假设：分组将以发送的次序进行交付，某些分组可能会丢失，但底层信道不会对分组重排序。</p>
</blockquote>
<h4 id="经完全可靠信道的可靠数据传输：rdt1-0"><a href="#经完全可靠信道的可靠数据传输：rdt1-0" class="headerlink" title="经完全可靠信道的可靠数据传输：rdt1.0"></a>经完全可靠信道的可靠数据传输：rdt1.0</h4><p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204016.png"></p>
<h4 id="经具有比特差错信道的可靠数据传输：rdt2-0"><a href="#经具有比特差错信道的可靠数据传输：rdt2-0" class="headerlink" title="经具有比特差错信道的可靠数据传输：rdt2.0"></a>经具有比特差错信道的可靠数据传输：rdt2.0</h4><h5 id="rdt2-0"><a href="#rdt2-0" class="headerlink" title="rdt2.0"></a>rdt2.0</h5><p>rdt2.0使用了<strong>肯定确认</strong>(positive acknowledgment)(“OK”)与<strong>否定确认</strong>(negative acknowledgment)(“请重复一遍)。这些控制报文使得接收方可以让发送方知道哪些内容被正确接收，哪些内容接收有误并因此需要重复。基于这样重传机制的可靠数据传输协议称为<strong>自动重传请求</strong>(Automatic Repeat reQuest, ARQ)协议。</p>
<p>ARQ协议中还需要另外三种协议功能来处理存在比特差错的情况：</p>
<ul>
<li>差错检测</li>
<li>接收方反馈</li>
<li>重传</li>
</ul>
<p>当发送方处于等待ACK或NAK的状态时，它不能从上层获得更多的数据；这就是说，rdt_send()事件不可能岀现；仅当接收到ACK并离开该状态时才能发生这样的事件。因此，发送方将不会发送一块新数据，除非发送方确信接收方已正确接收当前分组。由于这种行为，rdt2.0这样的协议被称为<strong>停等(stop and-wait)协议</strong>。此外，rdt2.0有一个致命缺点，没有考虑到<strong>ACK或NAK分组受损</strong>的可能性。</p>
<h5 id="rdt2-1"><a href="#rdt2-1" class="headerlink" title="rdt2.1"></a>rdt2.1</h5><p>rdt2.1考虑到了 ACK 和 NAK 也会损坏，那么采用的解决方法是：<strong>若发送方收到损坏的分组，就重传当前数据分组</strong>。但是这又引入了新的问题，当发送方收到损坏的分组 (可能是 ACK 也可能是 NAK)，发送方简单重传当前数据分组即可，但是<strong>在接收方看来，它并不知道上次所发送的 ACK 或 NAK 是否被发送方正确地接收到</strong> (发送方可能收到一个损坏的，或未损坏的确认，接收方对此并不知情)。因此，接收方无法判断它接收到的分组是新分组还是重传，如果接收方误判了一个新分组为重传，那么它忽略这个分组，交付给应用层的数据便产生了丢失，如果误判重传为新分组，那么交付给应用层的数据便产生了冗余，即冗余分组。</p>
<p>解决这个新问题的一个简单方法是在数据分组中添加新字段 —— <strong>序号</strong>，接收方只需检查序号便可得知到达的分组是重传还是新分组。对于停等协议，1 比特序号就足够了。这样的话，当接收方重复接收到序号为 0 的分组，它知道先前向发送方发送的对 0 分组的确认报文已经损坏，于是它重传对 0 分组的确认报文。对于发送方来说，它刚刚发送了 0 分组，但却得到接收方回传的一个损坏的确认报文，这个报文本来可能是 ACK，也可能是 NAK，发送方不能断定 0 分组是否被接收方正确接收，于是它不断重传 0 分组。直到收到一个未损坏的对 0 分组的 ACK 报文。</p>
<h5 id="rdt2-2"><a href="#rdt2-2" class="headerlink" title="rdt2.2"></a>rdt2.2</h5><p>rdt2.2是在有比特差错信道上实现的一个<strong>无NAK</strong>的可靠数据传输协议。rdt2. 1和rdt2.2之间的细微变化在于，接收方此时必须包括由一个ACK报文所确认的分组序号。</p>
<p>rdt 2.1 的接收方当收到损坏分组时向发送方回传一个 NAK，但rdt2.2不用 NAK，而是对上次正确接收的分组发送一个 ACK，也能达到同样的效果。发送方本来在等待 ACK 0，却等来了 ACK 1，那么它便知道它发送的 0 分组没有被接收端正确接收，于是它选择重传 0 分组。对于接收方，若它已经成功接收了 0 分组，但是它又收到 0 分组，它便知道它发送的 ACK 0 没有被发送方正确接收，于是它选择重传 ACK 0 报文。</p>
<h4 id="经具有比特差错的丢包信道的可靠数据传输：rdt3-0"><a href="#经具有比特差错的丢包信道的可靠数据传输：rdt3-0" class="headerlink" title="经具有比特差错的丢包信道的可靠数据传输：rdt3.0"></a>经具有比特差错的丢包信道的可靠数据传输：rdt3.0</h4><p>假设信道既会产生比特差错，也会丢包，那么此时我们的停等协议可能会永远卡死，而无法进入到下一个状态重传分组。卡死的困境可以被描述如下：发送方的分组丢失了，此时发送方等待接收方的确认信息，而接收方什么都没接收到，因此等待着发送方的分组到达，这便陷入了死锁。为了实现基于时间的重传机制，需要一个<strong>倒计数定时器</strong>（countdown timer），在一个给定的时间量过期后，可中断发送方。因此，发送方需要能做到：①每次发送一个分组（包括第一次分组和重传分组）时，便启动一个定时器。②响应定时器中断（采取适当的动作）。③终止定时器。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204032.png"></p>
<h4 id="流水线可靠数据传输协议"><a href="#流水线可靠数据传输协议" class="headerlink" title="流水线可靠数据传输协议"></a>流水线可靠数据传输协议</h4><p>虽然rdt3.0的功能完善了，但是由于是停等协议，因此其性能并不令人满意。假设这么两个端系统之间的往返传播时延RTT是30ms，彼此间通过一条发送速率R为1Gbps的信道相连，包括手段字段和分组长L为1000字节，那么发送一个分组进入1Gbps链路的所需时间为（<strong>传输时延</strong>）t_{trans}&#x3D;8us&#x2F;pkt。现发送方在t&#x3D;0时刻开始发送分组，在8us后该分组最后1bit进入链路，又经过15ms传输后，该分组最后1bit在<strong>t&#x3D;15.008ms</strong>时到达接收方。此时接收方立刻发送ACK（其发送时间忽略），ACK在<strong>t&#x3D;30.008ms</strong>时到达发送方。在30. 008ms内，发送方的发送只用了0. 008ms。如果我们定义发送方（或信道）的<strong>利用率</strong>（utilization）为：发送方实际忙于将发送比特送进信道的那部分时间与发送时间之比，那么在这个样例中停等协议的利用率为0.008&#x2F;30.008&#x3D;<strong>0.00027</strong>，十分之低。</p>
<p>因此我们采用流水线技术改善信道利用率，即不以停等方式运行，允许发送方发送多<br>个分组而无须等待确认。而采用流水线技术对可靠数据传输协议带来如下影响：</p>
<ul>
<li><p>必须增加序号范围，每个传输中的分组必须有一个唯一的序号，而且也许有许多个在输送中未确认的报文。</p>
</li>
<li><p>协议的发送方和接受两端也许必须缓存多个分组。发送方最低限度应当能缓存那些已发送但没有确认的分组。接收方或许也需要缓存那些已正确接受的分组。</p>
</li>
<li><p>所需序号范围和对缓存的要求取决于如何处理丢失、损坏及延时过大的分组。流水线差错恢复有两种基本方法：<strong>回退 N 步</strong> (Go-Back-N, GBN) 和 <strong>选择重传</strong> (Selective Repeat, SR)。</p>
</li>
</ul>
<h4 id="GBN"><a href="#GBN" class="headerlink" title="GBN"></a>GBN</h4><p><a target="_blank" rel="noopener" href="https://media.pearsoncmg.com/aw/ecs_kurose_compnetwork_7/cw/content/interactiveanimations/go-back-n-protocol/index.html">GBN交互动画</a> GBN允许发送方发送多个分组（当有多个分组可用时）而不需等待确认，但它也受限于在流水线中未确认的分组数不能超过某个最大允许数N。</p>
<p>GBN发送方必须响应三种类型的事件：</p>
<ul>
<li><p><strong>上层的调用</strong>。当上层调用rdt_send()时，发送方首先检查发送窗口是否已满，即是否有N个已发送但未被确认的分组。如果窗口未满，则产生一个分组并将其发送，并相应地更新变量。如果窗口已满，发送方只需将数据返回给上层，隐式地指示上层该窗口已满。</p>
</li>
<li><p><strong>收到一个ACK</strong>。</p>
</li>
<li><p><strong>超时事件</strong>。协议的名字“回退N步”来源于出现丢失和时延过长分组时发送方的行为。就像在停等协议中那样，定时器将再次用于恢复数据或确认分组的丢失。如果出现超时，发送方重传所有已发送但还未被确认过的分组。</p>
</li>
</ul>
<p>GBN接收方，如果正确接收到一个序号为n的分组，并且按序（即上次交付给上层的数据是序号为n-1的分组），则接收方为分组发送一个ACK，并将该分组中的数据部分交付到上层。如果<strong>该分组失序，接收方将会丢弃</strong>，直至接收到正确序号的分组。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204051.png"></p>
<h4 id="SR"><a href="#SR" class="headerlink" title="SR"></a>SR</h4><p><a target="_blank" rel="noopener" href="https://media.pearsoncmg.com/aw/ecs_kurose_compnetwork_7/cw/content/interactiveanimations/selective-repeat-protocol/index.html">SR交互动画</a> 单个分组的差错就能够引起GBN重传大量分组，许多分组根本没有必要重传。随着信道差错率的增加，流水线可能会被这些不必要重传的分组所充斥。而<strong>选择重传</strong>（SR）协议通过让发送方仅重传那些它怀疑在接收方出错（即丢失或受损）的分组而避免了不必要的重传。</p>
<p>SR 发送方的事件与动作：</p>
<ul>
<li><p><strong>从上层收到数据</strong>。若序号在窗口内，则将数据打包发送；否则要么将数据缓存，要么返回给上层以便以后传输。</p>
</li>
<li><p><strong>超时</strong>。定时器用来防止分组丢失，每个分组都有自己的定时器，因为超时发生时只能发送一个分组。</p>
</li>
<li><p><strong>收到 ACK</strong>。若分组序号在窗口内，SR 将该分组标记为已接收，如果该分组序号等于 send_base，则窗口的 send_base 移动到最小未确认序号处，如果窗口移动了并且新窗口内有未确认分组，则发送这些分组。</p>
</li>
</ul>
<p>SR 接收方的事件与动作：</p>
<ul>
<li><p>序号在 [rcv_base, rcv_base + N - 1] 内的分组被正确接收。若收到分组在窗口内，则回传一个 ACK 给发送方。如果以前没接收过，缓存该分组。若分组序号等于 recv_base，则将从 recv_base 开始连续的分组交付给上层，然后窗口向前移动。</p>
</li>
<li><p>序号在 [recv_base - N, recv_base - 1] 内的分组被正确收到。必须产生一个 ACK 给发送方，即使该分组是接收方以前已经确认过的分组。（因为窗口滑动顺序永远是接收方提前于发送方，如果接收方已经收到该分组（此时接收方的窗口也许已经滑动），但不回传 ACK 的话，发送方的窗口将永远不能向前滑动), 为什么会接受到 [recv_base - N, recv_base - 1] 范围内的分组？试想下列情况：接收方正确接收到 0 ~ k 的分组，并回传 0 ~ k 的确认，但这些确认报文丢失了序号最小的一个，或者丢失了全部，此时发送方的窗口无法向前滑动，发送方正等待超时重传，重传的分组就会落在接收方 [recv_base - N, recv_base - 1] 的范围内。</p>
</li>
<li><p>其他情况。忽略该分组<img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204135.png"></p>
</li>
</ul>
<p>SR 的问题：<br>序号范围有限时，发送方和接收方窗口缺乏同步会产生严重的后果。接收方有时无法判断一个分组是新分组还是重传。</p>
<p>解决办法：<br>限制发送方和接收方的窗口范围。由于是选择重传，我们不希望接收方窗口前缘与发送方窗口后缘重合。假设<strong>序号最大为k，窗口大小为w</strong>，接收方此时等待的最低序号为a，那么接收方的窗口为[a,a+w-1]，如果w个ACK全部丢失，那么发送方此时窗口为[a-w,a-1]，为了避免a+w-1与a-w重合，因此序号范围应该能容纳下这两个窗口，因此<strong>k&gt;&#x3D;2w</strong>。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204153.png"></p>
<h3 id="3-5-TCP"><a href="#3-5-TCP" class="headerlink" title="3.5 TCP"></a>3.5 TCP</h3><h4 id="TCP-连接"><a href="#TCP-连接" class="headerlink" title="TCP 连接"></a>TCP 连接</h4><ul>
<li><p>TCP 被称为是<strong>面向连接</strong>的，这是因为建立 TCP 连接必须先收发握手报文，发送方和接收方都在发送报文时初始化 TCP 的状态变量（比如套接字、接收缓存、发送缓存、LastByteRecved、LastByteSent、LastByteAcked、LastByteRead 等）。</p>
</li>
<li><p>TCP 面向连接仅仅指的是<strong>在端系统中维护</strong>与 TCP 连接有关的状态变量，而不是说在发送方和接收方沿途的路由器和通信链路中维护有该连接的状态信息，实际上，中间路由器对连接视而不见。</p>
</li>
<li><p>TCP 连接提供<strong>全双工服务</strong>：即 A 主机上进程 a 向 B 主机上进程 b 通过同一条 TCP 连接发送数据时，b 也可以同时在该条 TCP 连接上将数据发给 a，TCP 连接总是点对点（单个发送方和单个接收方），而非多播（一个发送方，多个接收方）。</p>
</li>
<li><p>MSS (Maximum Segment Size) 和 MTU (Maximum Transmission Unit)：<strong>MTU</strong> 指发送主机发送的最大链路层帧长度，<strong>MSS</strong> 指的是单个 TCP 报文段允许容纳的最大应用层报文长度，<strong>MSS 受制于 MTU</strong>，一般 TCP&#x2F;IP 报文首部字段总共 40 字节，所以假如 MTU 为 1500 字节，那么 MSS 为 MTU - 40 &#x3D; 1460 字节。</p>
</li>
</ul>
<h4 id="TCP-报文结构"><a href="#TCP-报文结构" class="headerlink" title="TCP 报文结构"></a>TCP 报文结构</h4><p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204216.png"></p>
<p>重点是序号和确认号，使用Telnet为学习案例讲解。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204227.png"></p>
<p><strong>一个报文段的序号就是该报文段数据字段首字节的序号</strong>。因此，客户发送的第一个报文段的序号为42, 服务器发送的第一个报文段的序号为79。<strong>确认号就是主机正在等待的数据的下一个字节序号</strong>。在TCP连接建立后但没有发送任何数据之前，该客户等待字节79, 而该服务器等待字节42。</p>
<p>假设主机A已收到一个来自主机B的包含字节0-535的报文段，以及另一个包含字节900-1000的报文段。由于某种原因，主机A还没有收到字节536-899的报文段。在这个例子中，主机A为了重新构建主机B的数据流，仍在等待字节536 （和其后的字节）。因此，A到B的下一个报文段将在确认号字段中包含536。因为TCP只确认该流中至第一个丢失字节为止的字节，所以TCP被称为提供<strong>累积确认</strong>（cumulative acknowledgment） 。</p>
<p>假设主机A在收到第二个报文段（字节536-899）之前收到第三个报文段（字节900-1000）。因此，第三个报文段失序到达。该微妙的问题是：当主机在一条TCP连接中收到失序报文段时该怎么办？TCP RFC并没有为此明确规定任何规则，因此这是由实现TCP的编程人员去处理的，实践中一般是<strong>接收方保留失序的字节，并等待缺少的字节以填补该间隔</strong>。</p>
<h4 id="往返时间的估计与超时"><a href="#往返时间的估计与超时" class="headerlink" title="往返时间的估计与超时"></a>往返时间的估计与超时</h4><p>设置超时间隔必须大于该连接的往返时间（RTT），即从一个报文段发出到它被确认的时间，否则会造成不必要的重传。</p>
<p>估计往返时间：<br>报文段的样本RTT（表示为SampleRTT）就是从某报文段被发出（即交给IP）到对该报文段的确认被收到之间的时间量。大多数TCP的实现仅在某个时刻做一次SampleRTT测量，而不是为每个发送的报文段测量一个SampleRTT。</p>
<p>TCP维持一个<strong>SampleRTT均值</strong>（称为EstimatedRTT）。 一旦获得一个新SampleRTT时，TCP就会根据下列公式来更新EstimatedRTT:<br>EstimatedRTT &#x3D;（1 - a）• EstimatedRTT + a • SampleRTT。</p>
<p>设置和管理重传超时间隔：<br>超时间隔应该大于等于EstimatedRTT，否则将造成不必要的重传。但是超时间隔不应该比 EstimatedRTT 大太多，否则当报文段丢失时，TCP 不能很快地重传该报文段，导致数据传输时延大。因此要求将超时间隔设为 EstimatedRTT 加上一定余量，当 SampleRTT 值波动大时，这个余量大一些；当波动小时，这个余量小一些。<br>TimeoutInterval &#x3D; EstimatedRTT + 4 x DevRTT<br>(DevRTT是RTT偏差，用于估算SampleRTT 一般会偏离EstimatedRTT的程度)</p>
<h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h4><p>注意<strong>流量控制</strong>和<strong>拥塞控制</strong>的区别： <strong>拥塞控制</strong>：TCP 发送方因为 IP 网络的拥塞而被遏制。 <strong>流量控制</strong>：消除发送方使接收方缓存溢出的可能性，即使发送方的发送速率和接收方接收速率相匹配。</p>
<p>TCP通过让发送方维护一个称为<strong>接收窗口</strong>(receive window)的变量来提供流量控制。通俗地说，接收窗口用于给发送方一个指示一一该接收方还有多少可用的缓存空间。因为TCP是全双工通信，在连接两端的发送方都各自维护一个接收窗口。</p>
<p>发送方需要保证发送速率在该连接的整个生命周期内满足下列不等式约束：<br>LastByteSent - LastByteAcked &lt;&#x3D; RcvBuffer - [ LastByteRcvd - LastByteRead ] 即 <strong>LastByteSent - LastByteAcked &lt;&#x3D; rwnd</strong> （假设A通过TCP往B发送一个大文件，主机B为该连接分配了一个接收缓存，并用RcvBuffer来表示其大小。LastByteRead：主机B上的应用进程从缓存读出的数据流的最后一个字节的编号，LastByteRcvd：从网络中到达的并且已放入主机B接收缓存中的数据流的最后一个字节的编号。）</p>
<p>流量控制的注意点：<br>若接收方的接收缓存已经存满，使得 rwnd &#x3D; 0, 在将 rwnd &#x3D; 0 通告给发送方后，此时假设接收方不会传送数据给发送方，那么发送方将不能知道接收方何时接收缓存中腾出了空闲空间出来。为了解决该问题，TCP 规范中要求：当接收方接收窗口为 0 时，主机 A 继续发送只有一个字节数据报文段。这些报文段将会被接收方确认。等到缓存开始清空，接收方回传的确认报文里将包含一个非 0 的 rwnd 值。</p>
<h4 id="TCP连接管理"><a href="#TCP连接管理" class="headerlink" title="TCP连接管理"></a>TCP连接管理</h4><h5 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h5><p><img src="http://c.biancheng.net/uploads/allimg/190219/1155312401-1.jpg"> </p>
<p>(1)(C-&gt;S)设置SYN标志位，客户端请求建立TCP连接，此时Seq设为1000。<br>(2)(S-&gt;C)设置SYN，ACK标志位，服务端响应建立连接请求，此时Seq设为2000，Ack设为1001。<br>(3)(C-&gt;S)设置ACK标志位，客户端确认收到服务端的报文，此时Ack设为2001。<br>注意Seq是32位的序号，Ack是32位的确认号，客户端和服务端的Seq不是同一个东西，Ack就是收到对方发送的包，在其Seq基础上+1。</p>
<h5 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h5><p><img src="http://c.biancheng.net/uploads/allimg/190219/115T13926-0.jpg"> </p>
<p>(1)(C-&gt;S)设置FIN标志位，客户端请求TCP断开连接，Seq为5000。<br>(2)(S-&gt;C)设置ACK标志位，服务端发送确认断开连接的报文，Seq为7000，Ack为5001。<br>(3)(S-&gt;C)设置FIN标志位，服务端同样发送断开连接的报文，Seq为7001，Ack为5001。<br>(4)(C-&gt;S)设置ACK标志位，客户端确认断开连接，Seq为5001，Ack为7002。<br>真实情况中(2)(3)由于数据较少，一般是合并发送的，即FIN+ACK，因此准确来说是三次挥手。</p>
<h4 id="拥塞控制原理"><a href="#拥塞控制原理" class="headerlink" title="拥塞控制原理"></a>拥塞控制原理</h4><p>丢包一般是当网络变得拥塞时由于路由器缓存溢出引起的，分组重传因此作为网络拥塞的征兆。</p>
<h5 id="拥塞原因与代价"><a href="#拥塞原因与代价" class="headerlink" title="拥塞原因与代价"></a>拥塞原因与代价</h5><ul>
<li><p>分组的到达速率接近链路容量时，分组经历巨大的排队时延。</p>
</li>
<li><p>发送方必须执行重传以补偿因为缓存溢出而丢失的分组。</p>
</li>
<li><p>发送方遇到大时延所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本，而路由器本可以利用链路的传输能力去发送另一个分组。</p>
</li>
<li><p>当一个分组沿一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费掉了，第一跳路由器所使用的将分组转发到第二条路由器的传输容量本可以用来传送不同的分组 （例如：当选择一个分组发送时，路由器最好优先考虑那些已经历过一定数量的上游路由器的分组）。</p>
</li>
</ul>
<h5 id="拥塞控制方法"><a href="#拥塞控制方法" class="headerlink" title="拥塞控制方法"></a>拥塞控制方法</h5><ul>
<li><p>端到端拥塞控制：在端到端拥塞控制方法中，网络层没有为运输层拥塞控制提供显示帮助。TCP 必须通过端到端的方法来解决拥塞，因为 IP 层不会向端系统提供有关网络拥塞的反馈信息。</p>
</li>
<li><p>网络辅助的拥塞控制：在网络辅助的拥塞控制中，网络层构件 (即路由器) 向发送方提供关于网络中拥塞状态的显式反馈信息。</p>
<ul>
<li>直接反馈信息可以由网络路由器发给发送方。</li>
<li>路由器标记或更新从发送方流向接收方的分组中某个字段来指示拥塞的产生。一旦收到一个标记的分组后，接收方就会向发送方通知该网络拥塞指示。</li>
</ul>
</li>
</ul>
<h5 id="TCP拥塞控制"><a href="#TCP拥塞控制" class="headerlink" title="TCP拥塞控制"></a>TCP拥塞控制</h5><p>如果一个 TCP 发送方感知从它到目的地之间的路径上没有拥塞，则 TCP 发送方增加其发送速率；如果发送方感知沿着该路径有拥塞，则发送方就会降低其发送速率。但是这种方法提出了三个问题：</p>
<p><strong>TCP 发送方是如何限制向其连接发送流量的？</strong> TCP 连接的每一端都由接收缓存、发送缓存和几个变量组成。TCP 通过维护一个额外变量拥塞窗口 cwnd 来限制一个 TCP 发送方能向网络中发送的流量。特别是，在一个发送方中未被确认的数据量不会超过 cwnd 与 rwnd 中的最小值，即：LastByteSent - LastByteAcked &lt;&#x3D; min{ cwnd, rwnd }。</p>
<p><strong>一个 TCP 发送方如何感知从它到目的地之间的路径上存在拥塞呢？</strong> 我们将一个 TCP 发送方的 “丢包事件” 定义为：要么出现超时，要么收到来自接收方的 3 个冗余 ACK。当出现过度拥塞时，在沿着这条路径上的一台或多台路由器的缓存会溢出，引起一个数据报（包含一个 TCP 报文段）被丢弃。丢弃的数据报会引起发送方的丢包事件（要么超时或收到 3 个冗余 ACK），发送方就认为在发送方到接收方的路径上出现了拥塞的指示。</p>
<p><strong>当发送方感知端到端的拥塞时，采用何种算法来改变其发送速率呢？</strong></p>
<ul>
<li><p><strong>慢启动</strong>。cwnd 的值以1个MSS开始并且每当传输的报文段首次被确认就增加一个 MSS，因此，TCP 发送速率起始慢，但在慢启动阶段以指数增长(1,2,4,8…,2^n)。</p>
<ul>
<li>若出现超时指示的丢包事件 —&gt; TCP发送方将cwnd设置为1并重新开始慢启动。它还将第二个状态变量的值ssthresh（”慢启动阈值”的速记）设置为cwnd&#x2F;2。</li>
<li>发送速率超过ssthresh —&gt; 进入拥塞避免。</li>
<li>监测到 3 个冗余 ACK —&gt; cwnd减半(最后+3)，ssthresh&#x3D;cwnd&#x2F;2，进入快速恢复。</li>
</ul>
</li>
<li><p><strong>拥塞避免</strong>。线性增加而非指数增加拥塞窗口（每个RTT只将cwnd的值增加一个MSS）。</p>
<ul>
<li>若出现超时指示的丢包事件 —&gt; 重新开始慢启动， cwnd设为1，ssthresh设为cwnd&#x2F;2。</li>
<li>监测到3个冗余ACK —&gt; TCP将cwnd的值减为一半（为使测量结果更好，计及已收到的3个冗余的ACK要加上3个MSS，即cwnd&#x2F;2+3），并将ssthresh的值记录为cwnd的值的一半，进入快速恢复。</li>
</ul>
</li>
<li><p><strong>快速恢复</strong>。在快速恢复中，对于引起TCP进入快速恢复状态的缺失报文段，对收到的每个冗余的ACK，cwnd的值增加一个MSS。最终当对丢失报文段的一个ACK到达时，TCP在降低cwnd后进入拥塞避免状态，</p>
<ul>
<li>若出现超时事件 —&gt; 重新开始慢启动， cwnd设为1，ssthresh设为cwnd&#x2F;2。</li>
<li>若出现丢包事件 —&gt; cwnd设为1，ssthresh设为cwnd&#x2F;2。</li>
</ul>
</li>
<li><p>注意<strong>TCP Tahoe</strong>（TCP早期版本）和<strong>TCP Reno</strong>的区别，<strong>Tahoe</strong>不管发生超时指示的丢包事件还是发生3个冗余ACK指示的丢包事件，都会无条件地将cwnd设为1，ssthresh设为cwnd&#x2F;2，并进入慢启动阶段。而<strong>Reno</strong>则是按照前文描述的方式进行拥塞控制。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204253.png"> <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204301.png"></p>
</li>
</ul>
<h2 id="第四章-网络层：数据平面"><a href="#第四章-网络层：数据平面" class="headerlink" title="第四章 网络层：数据平面"></a>第四章 网络层：数据平面</h2><blockquote>
<p>题目 P5 P8 P11 P14</p>
</blockquote>
<h3 id="4-1-概述网络层"><a href="#4-1-概述网络层" class="headerlink" title="4.1 概述网络层"></a>4.1 概述网络层</h3><p>网络层的作用就是将分组从一台发送主机移动到一台接收主机，因此网络层有两个很重要的功能，<strong>转发</strong>和<strong>路由选择</strong>。而网络层主要由两个部分组成，<strong>数据平面</strong>和<strong>控制平面</strong>。</p>
<p>数据平面功能即网络层中每台路由器的功能，该数据平面功能决定到达路由器输入链路之一的数据报（即网络层的分组）如何转发到该路由器的输出链路之一，涉及传统的IP转发和通用的转发。</p>
<p>控制平面功能即网络范围的逻辑，控制数据报沿着从源主机到目的主机的端到端路径中路由器之间的路由方式。学习路由选择算法，OSPF和BGP等路由选择协议。</p>
<h3 id="4-2-路由器工作原理"><a href="#4-2-路由器工作原理" class="headerlink" title="4.2 路由器工作原理"></a>4.2 路由器工作原理</h3><p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204311.png"></p>
<h4 id="基于目的地转发"><a href="#基于目的地转发" class="headerlink" title="基于目的地转发"></a>基于目的地转发</h4><p>一个入分组基于该分组的目的地址交换到输出端口。在32比特IP地址的情况下，转发表的蛮力实现将针对每个目的地址有一个表址。因为有超过40亿个可能的地址，选择这种方法总体上是不太行的。</p>
<p>实际上，路由器用分组目的地址的<strong>前缀</strong>与该表中的表项进行匹配，如果存在一个匹配项，则路由器向与该匹配项相关联的链路转发分组。当有多个匹配时，该路由器使用<strong>最长前缀匹配规则</strong>，即在该表中寻找最长的匹配项，并向与最长前缀匹配相关联的链路接口转发分组。</p>
<p>比如下图，假设分组的目的地址是11001000 00010111 00010110 10100001，因此该地址的21比特前缀匹配该表第一项，所以路由器向链路接口0转发该分组。而又假设地址为11001000 00010111 00011000 10101010，其前24比特与表中的第二项匹配，而该地址的前21比特与表中的第三项匹配，有多个匹配时，使用最长前缀匹配。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204330.png"></p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204337.png"></p>
<h3 id="4-3-IPv4"><a href="#4-3-IPv4" class="headerlink" title="4.3 IPv4"></a>4.3 IPv4</h3><p>IPv4数据报格式如下： <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204345.png"></p>
<p>在 TCP&#x2F;IP 网络通信时，为了保证能正常通信，每个设备都需要配置正确的 IP 地址，否则无法实现正常的通信。IP 地址（IPv4 地址）由 32 位正整数来表示，IP 地址在计算机是以二进制的方式处理的。而人类为了方便记忆采用了点分十进制的标记方式，也就是将 32 位 IP 地址以每 8 位为组，共分为 4 组，每组以「.」隔开，再将每组转换成十进制。 <img src="https://camo.githubusercontent.com/e5c13995b1b3ea71a694e4618a3bff2e1dc2db5b16747b228e45065b424e5255/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f49502f342e6a7067"></p>
<h4 id="IPv4数据报分片"><a href="#IPv4数据报分片" class="headerlink" title="IPv4数据报分片"></a>IPv4数据报分片</h4><p>由于并不是所有链路层协议都能承载相同长度的网络层分组，例如以太网帧能够承载不超过1500字节的数据，而某些广域网链路的帧可承载不超过576字节的数据。一个链路层帧能承载的最大数据量叫作<strong>最大传送单元</strong>，即<strong>MTU</strong>。因此当数据报过大时，需要对其进行分片传输，但TCP与UDP希望从网络层中接收到的是完整未分片的报文，因此IPv4需要在IP数据报首部中添加标识、标志和片偏移来方便这个数据报能重新按照顺序组装起来。</p>
<p>当生成一个数据报时，发送主机在为该数据报设置源和目的地址的同时贴上<strong>标识</strong>号。发送主机通常将它发送的每个数据报的标识号加1。由于IP是一种不可靠服务，为了让目的主机绝对地相信它已收到了初始数据报的最后一个片，最后一个片的<strong>标志</strong>比特被设为0，而所有其他片的标志比特被设为1。而<strong>片偏移</strong>则指定该片应放在初始IP数据报的哪个位置，以方便按正确的顺序重新组装片。</p>
<p>比如一个向具有700字节MTU的一条链路发送一个2400字节的数报，假定初始数据报标有标识号422。由于IP数据报首部占20字节，因此会产生(2400-20)&#x2F;(700-20)&#x3D;4个分片。前三个分片大小为700B，最后一个分片大小为360B。4个分片的标识号均为422，前三个标志为1，最后一个分片标志为0。而片偏移则分别为0，(700-20)&#x2F;8&#x3D;85，85+(700-20)&#x2F;8&#x3D;170，170+(700-20)&#x2F;8&#x3D;255(之所以除以8，是因为以8个字节为偏移单位)。</p>
<h4 id="分类编址"><a href="#分类编址" class="headerlink" title="分类编址"></a>分类编址</h4><p>在最开始制定时，要求全球因特网中的每台主机和路由器上的每个接口都必须有一个全球唯一的IP地址，然而这些地址不能随意地自由选择，一个接口的IP地址的一部分需要由其连接的子网来决定。一开始IP地址分类成了5种类型，分别是A、B、C、D、E五类。</p>
<p>ABC类主要分为两个部分，网络号和主机号。其最大主机个数就是2^(主机号位数)-2，减2是因为排除主机号全为1(指定为某个网络下所有主机，用于广播，即同一个链路中相互连接的主机之间发送数据)和主机号全为0(代表这个网络段本身)这两种特殊情况。</p>
<p>而DE类是没有主机号的，所以不可以用于主机IP，D类通常被用于多播(即将数据发送给特定组内的所有主机)，E类则是预留分类，暂未被使用。 <img src="https://camo.githubusercontent.com/ae05c8bd0289982c255b5ee6539a3a2783a3f0376bd280294fd83d43416a045d/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f49502f372e6a7067"> <img src="https://camo.githubusercontent.com/75ebffd89f984276e046463cfcf74f2bc1942564d485cf6e240131d07cda9123/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f49502f382e6a7067"></p>
<h4 id="无分类编址CIDR"><a href="#无分类编址CIDR" class="headerlink" title="无分类编址CIDR"></a>无分类编址CIDR</h4><p>分类地址虽然简单明了，选路简单，但是缺乏灵活性，同一网络下没有地址层次可以划分。并且不能很好的与现实网络匹配，比如对一家职员规模上千的公司来说，B类地址的最大主机数目过大，而C类地址的最大主机数目又太少。因此<strong>无分类地址CIDR</strong>出现了。</p>
<p>这种方式不再有分类地址的概念，32 比特的 IP 地址被划分为两部分，前面是网络号，后面是主机号。表示形式为a.b.c.d&#x2F;x，其中 &#x2F;x 表示前 x 位属于网络号， x 的范围是 0 ~ 32，这就使得 IP 地址更加具有灵活性。比如 10.100.122.2&#x2F;24，这种地址表示形式就是CIDR，&#x2F;24 表示前 24 位是网络号，剩余的 8 位是主机号。 <img src="https://camo.githubusercontent.com/f87bea88100d9e02cb2723b0258a7edf2540f5af4b0316fe595559b41a93a5ca/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f49502f31352e6a7067"></p>
<p>还有另一种划分网络号与主机号形式，那就是子网掩码，掩码的意思就是掩盖掉主机号，剩余的就是网络号。将子网掩码和 IP 地址按位计算 AND，就可得到网络号。 <img src="https://camo.githubusercontent.com/99665b4aa1b144b3fb861b0e35305a177321cc735d4f49b5c7f55472452da463/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f49502f31362e6a7067"></p>
<p>通过子网掩码划分出网络号和主机号，那实际上子网掩码还有一个作用，那就是划分子网。子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址。形式如下：</p>
<p> <img src="https://camo.githubusercontent.com/d68db035b7a0d03a6dc8052dbdd927ad1ec6ea7e5474a4ac995554ebaebade1a/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f49502f31382e6a7067"></p>
<p>假设对 C 类地址进行子网划分，网络地址 192.168.1.0，使用子网掩码 255.255.255.192 对其进行子网划分。C 类地址中前 24 位是网络号，最后 8 位是主机号，根据子网掩码可知从 8 位主机号中借用 2 位作为子网号。 <img src="https://camo.githubusercontent.com/320d13d5146abdcdd9fb1c105471cb1fa349bac8f4486c32e9e38ff1adfb7381/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f49502f31392e6a7067"></p>
<h3 id="4-4-IPv6"><a href="#4-4-IPv6" class="headerlink" title="4.4 IPv6"></a>4.4 IPv6</h3><p>由于新的子网和IP节点以惊人的增长率连到因特网上（并被分配唯一的IP地址），32比特的IP地址空间即将用尽。为了应对这种对大IP地址空间的需求，开发了一种新的IP协议，即IPv6，将IP地址长度从32比特增加到128比特。除了单播与多播地址以外，IPv6还引入了一种称为<strong>任播地址</strong>（anycast address）的新型地址，这种地址可以使数据报交付给一组主机中的任意一个。</p>
<p>将IPv4和IPv6做比较，会发现二者数据报格式会存在不同：<br>①IPv6不允许在中间路由器上进行分片与重新组装，这种操作只能在源与目的地执行。将该功能从路由器中删除并放到端系统中，大大加快了网络中的IP转发速度。<br>②IPv6去除了首部检验和，由于其他层也会进行检验操作，而且检验是一项耗时的工作，快速处理IP分组才是应该关注的重点，因此去除了首部检验和。</p>
<h2 id="第五章-网络层：控制平面"><a href="#第五章-网络层：控制平面" class="headerlink" title="第五章 网络层：控制平面"></a>第五章 网络层：控制平面</h2><blockquote>
<p>题目 P3 P5 P14</p>
</blockquote>
<h3 id="5-1-控制平面概述"><a href="#5-1-控制平面概述" class="headerlink" title="5.1 控制平面概述"></a>5.1 控制平面概述</h3><p>控制平面作为一种网络范围的逻辑，不仅控制沿着从源主机到目的主机的端到端路径间的路由器如何转发数据报，而且控制网络层组件和服务如何配置和管理。</p>
<h3 id="5-2-路由选择算法"><a href="#5-2-路由选择算法" class="headerlink" title="5.2 路由选择算法"></a>5.2 路由选择算法</h3><p>路由选择算法的目的是从发送方到接收方的过程中确定一条通过路由器网络的好的路径（等价于路由）。一般而言，路由选择算法的一种分类方式是根据该算法是集中式还是分散式来划分。</p>
<p><strong>集中式路由选择算法</strong>（centralized routing algorithm）用完整的、全局性的网络知识计算岀从源到目的地之间的最低开销路径，如<strong>链路状态（Link State, LS）算法</strong>。</p>
<p>在<strong>分散式路由选择算法</strong>（decentralized routing algorithm）中，路由器以迭代、分布式的方式计算出最低开销路径，如<strong>距离向量（Distance-Vector, DV）算法</strong>。</p>
<h4 id="链路状态路由选择算法"><a href="#链路状态路由选择算法" class="headerlink" title="链路状态路由选择算法"></a>链路状态路由选择算法</h4><p>在链路状态算法中，网络拓扑和所有的链路开销都是已知的，也就是说可用作LS算法的输入。实践中这是通过让每个节点向网络中所有其他节点广播链路状态分组来完成的，其中每个链路状态分组包含它所连接的链路的标识和开销。下面给出的链路状态路由选择算法叫作Dijkstra算法，其中： <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204404.png"></p>
<p>以一个例子来展示这个算法，计算从u到所有可能目的地的最低开销路径。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204414.png"></p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204422.png"></p>
<p>当LS算法终止时，对于每个节点，我们都得到从源节点沿着它的最低开销路径的前一节点。对于每个前一节点，我们又有它的前一节点，以此方式我们可以构建从源节点到所有目的节点的完整路径。通过对每个目的节点存放从u到目的地的最低开销路径上的下一跳节点，在一个节点（如节点u）中的转发表则能够根据此信息而构建。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204431.png"></p>
<h4 id="距离向量路由选择算法"><a href="#距离向量路由选择算法" class="headerlink" title="距离向量路由选择算法"></a>距离向量路由选择算法</h4><p>之所以说DV算法是<strong>分布式</strong>的，是因为每个节点都要从一个或多个直接相连邻居接收某些信息，执行计算，然后将其计算结果分发给邻居。而说它是<strong>迭代</strong>的，是因为此过程一直要持续到邻居之间无更多信息要交换为止。说它是<strong>异步</strong>的，是因为它不要求所有节点相互之间步伐一致地操作。最后它还是<strong>自我终止</strong>的，即没有计算应该停止的信号它就自然停止了。</p>
<p>在该分布式、异步算法中，每个节点不时地向它的每个邻居发送它的距离向量副本。当节点x从它的任何一个邻居v接收到一个新距离向量，它保存v的距离向量，然后使用Bellman-Ford方程更新它自己的距离向量如下： <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501204438.png"> 其中D_x(y)是指x到N中所有目的地y的开销估计值，即节点x的距离向量。而c(x,y)则是x到直接相连邻居v的开销为c(x,v)。</p>
<p>举个例子：<br>该图最左边一列显示了这3个节点各自的初始<strong>路由选择表</strong>(routing table)。例如，位于左上角的表是节点x的初始路由选择表。在一张特定的路由选择表中，每行是一个距离向量——特别是每个节点的路由选择表包括了它的距离向量和它的每个邻居的距离向量。 因此，在节点x的初始路由选择表中的第一行是[0, 2,7]。在该表的第二和第三行是最近分别从节点y和z收到的距离向量。因为在初始化时节点x还没有从节点y和z收到任何东西，所以第二行和第三行表项中被初始化为无穷大。</p>
<p>初始化后，每个节点向它的两个邻居发送其距离向量。图5-6中用从表的第一列到表的第二列的箭头说明了这一情况。例如，节点x向两个节点y和z发送了它的距离向量[0, 2, 7]。在接收到该更新后，每个节点重新计算它自己的距离向量。例如，节点x计算 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210011.png"> 如此类推，直到无更新报文发送为止，此时因为无更新报文发送，将不会出现进一步的路由选择表计算，该算法进入静止状态，知道一条链路的开销发生变化。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210021.png"></p>
<h4 id="LS与DV路由选择算法的比较"><a href="#LS与DV路由选择算法的比较" class="headerlink" title="LS与DV路由选择算法的比较"></a>LS与DV路由选择算法的比较</h4><p>实际运用中是LS和DV采用互补的方法来解决路由选择计算问题。</p>
<ul>
<li>报文复杂性。LS算法要求每个节点都知道网络中每条链路的开销。这就要求要发送O(|V| |E|)个报文。而且无论何时一条链路的开销改变时，必须向所有节点发送新的链路开销。DV算法仅要求在每次迭代时，在两个直接相连邻居之间交换报文。</li>
<li>收敛速度。我们已经看到LS算法的实现是一个要求O(|V| |E|)个报文的O(|N|^2)算法。DV算法收敛较慢，且在收敛时会遇到路由选择环路，DV算法还会遭遇无穷计数的问题。</li>
<li>健壮性。LS算法的全局性质，使其有一定程度的健壮性。但DV算法中一个节点的错误计算也会影响整个网络，不具备健壮性。</li>
</ul>
<h3 id="5-3-因特网中自治系统内部的路由选择：OSPF"><a href="#5-3-因特网中自治系统内部的路由选择：OSPF" class="headerlink" title="5.3 因特网中自治系统内部的路由选择：OSPF"></a>5.3 因特网中自治系统内部的路由选择：OSPF</h3><p>当网络<strong>规模</strong>变得十分庞大时，我们希望能减少因特网中路由计算的复杂性。此外，因特网是ISP的网络，其中每个ISP都有它自己的路由器网络。ISP希望按自己的意愿运行路由器，或对外部隐藏其网络的内部组织面貌，即要求<strong>管理自治</strong>。因此需要将路由器组织进<strong>自治系统(Autonomous System，AS)</strong> 来解决。</p>
<p>在相同AS中的路由器都运行相同的路由选择算法并且有彼此的信息，在一个自治系统内运行的路由选择算法叫作自治系统内部路由选择协议。自治系统中运行的协议一般有RIP、OSPF、IGRP。</p>
<p>其中RIP协议基于距离向量算法，使用“跳数”来衡量到达目标地址的路由距离。这种协议的路由器只关心自己周围的世界，只与自己相邻的路由器交换信息，范围限制在15跳(15度)之内。</p>
<p>而IGRP，即内部网关路由协议，是在RIP的基础上发展而来，也是采用距离向量算法。</p>
<p>OSPF称为开放最短路优先，被广泛用于AS内部路由选择，它是一种链路状态协议，使用洪泛链路状态信息和Dijkstra最低开销路径算法。使用OSPF，一台路由器构建了一幅关于整个自治系统的完整拓扑图（即一幅图）。于是，每台路由器在本地运行Dijkstra的最短路径算法，以确定一个以自身为根节点到所有子网的最短路径树。</p>
<p>使用OSPF时，路由器向自治系统内所有其他路由器广播路由选择信息，而不仅仅是向其相邻路由器广播。每当一条链路的状态发生变化时（如开销的变化或连接&#x2F;中断状态的变化），路由器就会广播链路状态信息。即使链路状态未发生变化，它也要周期性地（至少每隔30min一次）广播链路状态。</p>
<p>OSPF的优点包括：</p>
<ul>
<li>安全。能够鉴别OSPF路由器之间的交换。使用鉴别，仅 有受信任的路由器能参与一个AS内的OSPF协议，因此可防止恶意入侵者将不正确的信息注入路由器表内。</li>
<li>多条相同开销的路径。当到达某目的地的多条路径具有相同的开销时，OSPF允许使用多条路径。</li>
<li>对单播与多播路由选择的综合支持。</li>
<li>支持在单个AS中的层次结构。</li>
</ul>
<h3 id="5-4-ISP之间的路由选择：BGP"><a href="#5-4-ISP之间的路由选择：BGP" class="headerlink" title="5.4 ISP之间的路由选择：BGP"></a>5.4 ISP之间的路由选择：BGP</h3><p>OSPF是一个AS内部路由选择协议，而当分组跨越多个AS进行路由时，我们需要一个自治系统统间路由选择协议（inter-autonomous system routing protocol）。在因特网中，所有的AS运行相同的AS间路由选择协议，称为**边界网关协议(BGP)**。BGP是所有因特网协议中最重要的协议之一，因为它将因特网中数以千计的ISP粘合起来。它是一种分布式和异步的协议。</p>
<h4 id="BGP作用"><a href="#BGP作用" class="headerlink" title="BGP作用"></a>BGP作用</h4><p>在BGP中，分组是路由到CIDR化的前缀，其中每个前缀表示一个子网或一个子网的集合，比如目的地可以采用138.16.68&#x2F;22的形式，对于这个例子来说包括1024个IP地址。因此，一台路由器的转发表将具有形式为(x,I)的表项，其中x是一个前缀(例如138.16.68&#x2F;22)，I是该路由器的接口之一的接口号。BGP为每台路由器提供了一种完成以下任务的手段：</p>
<ul>
<li>从邻居AS中获得前缀的可达性信息。BGP允许每个子网向因特网的其余部分通告它的存在。</li>
<li>确定到该前缀的“最好的”路由。</li>
</ul>
<h4 id="通告BGP路由信息"><a href="#通告BGP路由信息" class="headerlink" title="通告BGP路由信息"></a>通告BGP路由信息</h4><p>对于每个AS，每台路由器要么是一台网关路由器器（gateway router），要么是一台内部路由器（internal router）。网关路由器是一台位于AS边缘的路由器，它直接连接到在其他AS中的一台或多台路由器。内部路由器仅连接在它自己AS中的主机和路由器。</p>
<p>在BGP中，每对路由器通过使用179端口的半永久TCP连接交换路由选择信息。每条直接连接以及所有通过该连接发送的BGP文，称为BGP连接(BGP cormection)。此外，跨越两个AS的BGP连接称为<strong>外部BGP ( eBGP)连接</strong>，而在相同AS中的两台路由器之间的BGP会话称为<strong>内部BGP (iBGP)连接</strong>。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210037.png"> 为了传播可达性信息，使用了 iBGP和eBGP会话。再次考虑向AS1和AS2中的所有路由器通告前缀x的可达性信息。在这个过程中，网关路由器3a先向网关路由器2c发送一个eBGP报文“AS3 x”。网关路由器2c然后向AS2中的所有其他路由器(包括网关路由器2a)发送iBGP报文“AS3 x”。网关路由器2a接下来向网关路由器1c发送一个eBGP报文“AS2 AS3 x”。最后，网关路由器1c使用iBGP向AS1中的所有路由器发送报文“AS2 AS3 x”。在这个过程完成后，在AS1和AS2中的每个路由器都知道了x的存在并且也都知道了通往x的AS路径。</p>
<h2 id="第六章-链路层"><a href="#第六章-链路层" class="headerlink" title="第六章 链路层"></a>第六章 链路层</h2><blockquote>
<p>题目 P14 P17 P23</p>
</blockquote>
<h3 id="6-1-链路层概述"><a href="#6-1-链路层概述" class="headerlink" title="6.1 链路层概述"></a>6.1 链路层概述</h3><p>当我们沿协议栈继续往下，从网络层到达链路层，我们自然而然地想知道分组是如何通过构成端到端通信路径的各段链路的。在链路层的讨论中，我们将看到两种截然不同类型的链路层信道。第一种类型是<strong>广播信道</strong>，这种信道用于连接有线局域网、卫星网和混合光纤同轴电缆接入网中的多台主机。第二种类型的链路层信道是<strong>点对点通信链路</strong>，这在诸如长距离链路连接的两台路由器之间，或用户办公室计算机与它们所连接的邻近以太网交换机之间等场合经常能够发现。</p>
<p>我们将运行在链路层协议的任何设备均称为节点，把沿着通信路径连接相邻节点的通信信道称为链路。假设从某无线主机之一向服务器之一发送一个数据报。该数据报将实际通过6段链路：发送主机与WiFi接入点之间的WiFi链路，接入点和链路层交换机之间的以太网链路，链路层交换机与路由器之间的链路，两台路由器之间的链路，最后是交换机和服务器之间的以太网链路。在通过特定的链路时，传输节点将数据报封装在链路层帧中，并将该帧传送到链路中。</p>
<p>举个例子，某个游客从广州出发去大阪，则旅行社安排先从广州到上海，最后去大阪，那么该游客就是一个数据报，每个运输区段就是一条链路，每种运输方式就是一种链路层协议，该游客选择的旅行社就是一个路由选择协议。</p>
<h4 id="链路层提供的服务"><a href="#链路层提供的服务" class="headerlink" title="链路层提供的服务"></a>链路层提供的服务</h4><p>链路层协议能够提供的可能服务包括：</p>
<ul>
<li>成帧。在每个网络层数据报经链路传送之前，几乎所有的链路层协议都要将其用链路层帧封装起来。</li>
<li>链路接入。媒体访问控制（Medium Access Control, MAC）协议规定了帧在链路上传输的规则。</li>
<li>可靠交付。当链路层协议提供可靠交付服务时，它保证无差错地经链路层移动每个网络层数据报。</li>
<li>差错检测和纠正。相较于运输层和网络层，链路层的差错检测通常更加复杂并且使用硬件实现。</li>
</ul>
<h4 id="链路层在何处实现"><a href="#链路层在何处实现" class="headerlink" title="链路层在何处实现"></a>链路层在何处实现</h4><p>链路层的主体部分是在网络适配器中实现的，网络适配器有时也称为网络接口卡。位于网络适配器核心的是链路层控制器，该控制器通常是一个实现了许多链路层服务（成帧、链路接入、差错检测等）的专用芯片。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210045.png"></p>
<h3 id="6-3-多路访问链路和协议"><a href="#6-3-多路访问链路和协议" class="headerlink" title="6.3 多路访问链路和协议"></a>6.3 多路访问链路和协议</h3><p>我们知道网络链路分为两种，一种是点对点，一种是广播链路。对于广播链路，它能够让多个发送和接收节点都连接到相同的、单一的、共享的广播信道上。与之对应的，我们需要协调多个发送和接收节点对一个共享广播信道的访问，这就是<strong>多路访问问题</strong>。</p>
<p>由于所有的节点都能够传输帧，所以多个节点可能会同时传输帧。当发生这种情况时，所有节点同时接到多个帧；这就是说，传输的帧在所有的接收方处<strong>碰撞</strong>。通常，当碰撞发生时，没有一个接收节点能够有效地获得任何传输的帧；在某种意义下，碰撞帧的信号纠缠在一起。因此，涉及此次碰撞的所有帧都丢失了，在碰撞时间间隔中的广播信道被浪费了。显然，如果许多节点要频繁地传输帧，许多传输将导致碰撞，广播信道的大量带宽将被浪费掉。为了解决这个问题，我们设计了<strong>多路访问协议</strong>。</p>
<p>多路访问协议总体上可以划分为三种类型，<strong>信道划分协议</strong>（channel partitioning protocol），<strong>随机接入协议</strong>（random access protocol）和<strong>轮流协议</strong>（taking-turns protocol）。同时，我们希望，理想情况下，对于速率为R bps的广播信道，多路访问协议应该具有以下所四个特性：</p>
<ul>
<li>当仅有一个节点发送数据时，该节点具有R bps的吞吐量。</li>
<li>当有M个节点发送数据时，每个节点吞吐量为R&#x2F;M bps。这不必要求M个节点中的每一个节点总是有R&#x2F;M的瞬间速率，而是每个节点在一些适当定义的时间间隔内应该有R&#x2F;M的平均传输速率。</li>
<li>协议是分散的，即不因某主节点故障而使整个系统崩溃。</li>
<li>协议是简单的，使实现不昂贵。</li>
</ul>
<h4 id="信道划分协议"><a href="#信道划分协议" class="headerlink" title="信道划分协议"></a>信道划分协议</h4><p>在第一章提及的<strong>时分多路复用（TDM）</strong> 和 <strong>频分多路复用（FDM）</strong> 就是两种能够用于在所有共享信道节点之间划分广播信道带宽的技术。</p>
<p>TDM就是将时间划分为时间帧，并进一步划分每个时间帧为N个时隙，然后把每个时隙分配给N个节点中的一个。无论何时某个节点在有分组要发送的时候，它在循环的TDM帧中指派给它的时隙内传输分组比特。由于每个节点在每个帧时间内得到了专用的传输速率R&#x2F;N bps，因此TDM<strong>消除了碰撞并且是公平的</strong>。但它也有两个显著缺点。首先，<strong>节点被限制于R&#x2F;N bps的平均速率</strong>，即使当它是唯一有分组要发送的节点时。其次，<strong>节点必须总是等待它在传输序列中的轮次</strong>，即我们再次看到，即使它是唯一一个有帧要发送的节点。</p>
<p>而FDM将R bps信道划分为不同的频段（每个频段具有R&#x2F;N带宽），并把每个频率分配给N个节点中的一个。因此FDM在单个较大的R bps信道中创建了N个较小的R&#x2F;N bps信道。FDM也有TDM同样的优点和缺点。它<strong>避免了碰撞，在N个节点之间公平地划分了带宽</strong>。然而，FDM也有TDM所具有的主要缺点，也就是限制一个节点只能使用R&#x2F;N的带宽，即使当它是唯一一个有分组要发送的节点时。</p>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210057.png"></p>
<p>第三种信道划分协议是<strong>码分多址（CDMA）</strong>，CDMA对每个节点分配一种不同的编码，每个节点用它唯一的编码来对它发送的数据进行编码。如果精心选择这些编码，CDMA网络具有一种奇妙的特性，即不同的节点能够同时传输，并且它们各自相应的接收方仍能正确接收发送方编码的数据比特（假设接收方知道发送方的编码），而不在乎其他节点的干扰传输。</p>
<h4 id="随机接入协议"><a href="#随机接入协议" class="headerlink" title="随机接入协议"></a>随机接入协议</h4><p>第二大类多访问协议是<strong>随机接入协议</strong>。在随机接入协议中，一个传输节点总是以信道的全部速率（即R bps）进行发送。当有碰撞时，涉及碰撞的每个节点反复地重发它的帧（也就是分组），到该帧无碰撞地通过为止。但是当一个节点经历一次碰撞时，它不必立刻重发该帧。<strong>相反，它在重发该帧之前等待一个随机时延</strong>。涉及碰撞的每个节点独立地选择随机时延。因为该随机时延是独立地选择的，所以下述现象是有可能的：这些节点之一所选择的时延充分小于其他碰撞节点的时延，并因此能够无碰撞地将它的帧在信道中发出。</p>
<p><strong>时隙ALOHA协议</strong> ALOHA协议中：</p>
<ul>
<li>所有帧由L比特组成。</li>
<li>时间被划分成长度为L&#x2F;R秒的时隙（这就是说，一个时隙等于传输一帧的时间）。</li>
<li>节点只在时隙起点开始传输帧。</li>
<li>节点是同步的，每个节点都知道时隙何时开始。</li>
<li>如果在一个时隙中有两个或者更多个帧碰撞，则所有节点在该时隙结束之前检测到该碰撞事件。</li>
</ul>
<p>令p是一个概率，即一个在0和1之间的数。在每个节点中，时隙ALOHA的操作是简单的:</p>
<ul>
<li>当节点有一个新帧要发送时，它等到下一个时隙开始并在该时隙传输整个帧。</li>
<li>如果没有碰撞，该节点成功地传输它的帧，从而不需要考虑重传该帧。（如果该节点有新帧，它能够为传输准备一个新帧。）</li>
<li>如果有碰撞，该节点在时隙结束之前检测到这次碰撞。该节点以概率p在后续的每个时隙中重传它的帧，直到该帧被无碰撞地传输出去。</li>
</ul>
<p>与信道划分不同，当某节点是唯一活跃的节点时（一个节点如果有帧要发送就认为它是活跃的），时隙ALOHA允许该节点以全速R连续传输。且时隙ALOHA是高度分散的，每个节点检测碰撞并独立地决定什么时候重传。但当有多个活跃节点时，一部分时隙将有碰撞，因此将被“浪费”掉了，而且所有活跃节点由于概率传输策略会节制传输，仅有37%的时隙做有用的工作，因此其有效传输速率较低。</p>
<p><strong>载波侦听多路访问CSMA协议</strong></p>
<ul>
<li><strong>载波侦听</strong>。说话之前先听。如果其他人正在说话，等到他们说完话为止。即一个节点在传输前先听信道，如果来自另一个节点的帧正向信道上发送，节点则等待直到检测到一小段时间没有传输，然后开始传输。</li>
<li><strong>碰撞检测</strong>。如果与他人同时开始说话，停止说话。即当一个传输节点在传输时一直在侦听此信道。如果它检测到另一个节点正在传输干扰帧，它就停止传输，在重复“侦听-当空闲时传输”循环之前等待一段随机时间。</li>
</ul>
<p><strong>具有碰撞检测的载波侦听多路访问（CSMA&#x2F;CD）</strong> 如图四个节点的时空图，横轴表示每个节点在空间的位置（线性），纵轴表示时间。在图6-12中，节点没有进行碰撞检测；即使已经出现了碰撞，B和D都将继续完整地传输它们的帧。图6-13中，当某节点执行碰撞检测时，一旦它检测到碰撞将立即停止传输。B和D这两个节点在检测到碰撞后很短的时间内都放弃了它们的传输。加入碰撞检测，通过不传输一个无用的、损坏的帧，将有助于改善协议的性能。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210110.png"></p>
<p>CSMA&#x2F;CD协议在节点中的运行步骤如下：<br>①适配器从网络层获得一条数据报，准备链路层帧，并将其放入帧适配器缓存中。<br>②如果适配器侦听到信道空闲（即无信号能量从信道进入适配器），它开始传输帧。在另一方面，如果适配器侦听到信道正在忙，它将等待，直到侦听到没有信号能量时才开始传输帧。<br>③在传输过程中，适配器监视来自其他使用该广播信道的适配器的信号能量的存在。<br>④如果适配器传输整个帧而未检测到来自其他适配器的信号能量，该适配器就完成了该帧。在另一方面，如果适配器在传输时检测到来自其他适配器的信号能量，它中止传输（即它停止了传输帧）。<br>⑤中止传输后，适配器<strong>等待一个随机时间量</strong>，然后返回步骤2。</p>
<p>这个步骤的关键在于随机时间量该如何确定，我们希望当碰撞节点数量较少时，时间间隔较短。当碰撞节点数量较大时，时间间隔较长。<strong>二进制指数后退算法</strong>简练地解决了这个问题。当传输一个给定帧时，在该帧经历了一连串的几次碰撞后，节点随机地从｛0, 1, 2,…，2^n -1｝中选择一个K值。因此，一个帧经历的碰撞越多，K选择的间隔越大。对于以太网，一个节点等待的实际时间量是K * 512比特时间（即发送512比特进入以太网所需时间量的K倍），n能够取的最大值在10以内。</p>
<p>举个例子，假设一个适配器首次尝试传输一个帧，并在传输中它检测到碰撞。然后该节点以概率0.5选择K&#x3D;0，以概率0.5选择K&#x3D;1。如果该节点选择K&#x3D;0，则它立即开始侦听信道。如果这个适配器选择K&#x3D;1，它在开始“侦听-当空闲时传输”。周期前等待512比特时间（例如对于100Mbps以太网来说为5.12ms）。在第2次碰撞之后，从｛0, 1, 2, 3｝中等概率地选择K。在第3次碰撞之后，从｛0, 1, 2, 3, 4, 5, 6, 7｝中等概率地选择K。在10次或更多次碰撞之后，从｛0, 1, 2, … , 1023｝中等概率地选择K。因此从中选择K的集合长度随着碰撞次数呈指数增长；正是由于这个原因，该算法被称为二进制指数后退。</p>
<p>关于CSMA&#x2F;CD的效率，我们定义为：当有大量的活跃节点，且每个节点有大量的帧要发送时，帧在信道中无碰撞地传输的那部分时间在长期运行时间中所占的份额。为了给出效率的一个闭式的近似表示，令d_{prop}表信号能量在任意两个适配器之间传播所需的最大时间。令d_{trans}表示传输一个最大长度的以太网帧的时间（对于10Mbps的以太网，该时间近似为1.2毫秒）。给出其近似式：</p>
<p> <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210119.png"> </p>
<p>当d_{prop}接近0时，效率接近1。即传播时延是0，那么碰撞的节点将立即中止而不会浪费信道。同时，当d_{trans}变得很大时，效率也近于1。即当一个帧取得信道时，它将占有信道很长时间。</p>
<h4 id="轮流协议"><a href="#轮流协议" class="headerlink" title="轮流协议"></a>轮流协议</h4><p>由于ALOHA和CSMA协议只具备多路访问协议的一个特性，即当只有一个节点活跃吋，该活跃节点具有R bps的吞吐量。而不具备当有M个节点活跃时，每个活跃节点的吞吐量接近R&#x2F;M bps这一特性。因此人们又设计了轮流协议，其中比较重要的两个协议是<strong>轮询协议</strong>（polling protocol）和<strong>令牌传递协议</strong>（token-passing protocol）。</p>
<p><strong>轮询协议</strong> 轮询协议要求这些节点之一要被指定为主节点。主节点以循环的方式轮询每个节点。特别是，主节点首先向节点1发送一个报文，告诉它（节点1）能够传输的帧的最多数量。在节点1传输了某些帧后，主节点告诉节点2它（节点2）能够传输的帧的最多数量。（主节点能够通过观察在信道上是否缺乏信号，来决定一个节点何时完成了帧的发送。）上述过程以这种方式继续进行，主节点以循环的方式轮询了每个节点。</p>
<p>轮询协议消除了随机接入协议存在的碰撞和空时隙问题，获得了更高的效率，但它也存在一些问题。一是<strong>引入了轮询时延</strong>，即通知一个节点“它可以传输”所需的时间。哪怕只有一个活跃节点，当它发送了帧后，主节点要依次轮询非活跃节点。二是如果主节点故障，那么整个信道将变得不可操作。</p>
<p><strong>令牌传递协议</strong> 在这种协议中没有主节点。一个称为令牌（token）的小的特殊帧在节点之间以某种固定的次序进行交换。例如，节点1可能总是把令牌发送给节点2 ,节点2可能总是把令牌发送给节点3，而节点N可能总是把令牌发送给节点1。当一个节点收到令牌时，仅当它有一些帧要发送时，它才持有这个令牌；否则，它立即向下一个节点转发该令牌。当一个节点收到令牌时，如果它确实有帧要传输，它发送最大数目的帧数，然后把令牌转发给下一个节点。令牌传递是分散的，具有很高的效率。但是一个节点的故障或者某个节点忘记释放令牌，会导致整个信道停摆。</p>
<h3 id="6-4-交换局域网"><a href="#6-4-交换局域网" class="headerlink" title="6.4 交换局域网"></a>6.4 交换局域网</h3><p>当传输一个IP数据报的时候，已经确定源IP地址和目标IP地址后，我们还需要链路层寻址，即MAC地址。之所以还需要MAC地址，是因为IP地址它是会发生变化的，具有层次结构，比如人的居住地址。而MAC地址是扁平寻址的结构，它是不会发生变化的（一般来说），就像人的籍贯，无论这个人搬到哪里居住，其籍贯都不会发生变化。因此一台主机具有一个网络层地址和一个MAC地址对于寻址来说是相当有用的。</p>
<p>通常MAC地址长度为6字节，共有2^{48}个可能的MAC地址，一般用十六进制表示法。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210129.png"></p>
<h4 id="地址解析协议-ARP"><a href="#地址解析协议-ARP" class="headerlink" title="地址解析协议(ARP)"></a>地址解析协议(ARP)</h4><p>因为存在网络层地址（IP地址）和链路层地址（MAC地址），所以我们需要在它们之间进行转换，这就是地址解析协议（Address Resolution Protocol, ARP）的任务。ARP通常借助<strong>ARP请求</strong>和<strong>ARP响应</strong>两种类型的报文来确定MAC地址。 <img src="https://camo.githubusercontent.com/80a6ccba2dc076391e58f35b6c6a61b203cb497ef0bc9dd2ac2f682932bd175b/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f7869616f6c696e636f6465722f496d616765486f73742f2545382541452541312545372541452539372545362539432542412545372542442539312545372542422539432f49502f33342e6a7067"></p>
<p>主机先通过广播发送ARP请求，这个报文中包含了想要知道的MAC地址的主机IP地址。当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求报文里的内容，如果 ARP 请求报文中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 ARP 响应报文返回给主机。操作系统通常会把第一次通过 ARP 获取的 MAC 地址缓存起来，即放入<strong>ARP表</strong>，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。不过，MAC 地址的缓存是有一定期限的，超过这个期限，缓存的内容将被清除。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210139.png"></p>
<p>举个例子，如图中每台主机和路由器有一个单一的1P地址和单一的MAC地址。为了便于讨论，假设交换机广播所有帧；这就是说，无论何时交换机在一个接口接收一个帧，它将在其所有其他接口上转发该帧。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210146.png"> 假设主机222. 222. 222. 220要发送一个数据报，该数据报要IP寻址到本子网上另一台主机或路由器。当ARP表中没有目的主机的表项，那么发送方先构造一个称为ARP分组（ARP packet）的特殊分组。222. 222. 222. 220向它的适配器传递一个ARP查询分组，并且指示适配器应该用MAC广播地址（即FF-FF-FF-FF-FF-FF）来发送这个分组。适配器在链路层帧中封装这个ARP分组，用广播地址作为帧的目的地址，并将该帧传输进子网中。包含该ARP查询的帧能被子网上的所有其他适配器接收到，并且（由于广播地址）每个适配器都把在该帧中的ARP分组向上传递给ARP模块。这些ARP模块中的每个都检查它的IP地址是否与ARP分组中的目的IP地址相匹配。与之匹配的一个给査询主机发送回一个带有所希望映射的响应ARP分组。然后查询主机222. 222. 222. 220能够更新它的ARP表，并发送它的IP数据报，该数据报封装在一个链路层帧中，并且该帧的目的MAC就是对先前ARP请求进行响应的主机或路由器的MAC地址。</p>
<h4 id="以太网和链路层交换机"><a href="#以太网和链路层交换机" class="headerlink" title="以太网和链路层交换机"></a>以太网和链路层交换机</h4><p>目前有线局域网技术基本由以太网一家独大，以太网帧结构如下： <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210155.png"> 其中目的地址和源地址均指MAC地址。</p>
<p>在20世纪90年代后期，局域网普遍使用一种基于<strong>集线器</strong>的星形拓扑以太网。<strong>集线器</strong>是一种<strong>物理层设备</strong>，它作用于各个比特而不是作用于帧。当表示一个0或一个1的比特到达一个接口时，集线器只是重新生成这个比特，将其能量强度放大，并将该比特向其他所有接口传输出去。集线器的问题在于，无论何时集线器从它的一个接口接收到一个比特，它向其所有其他接口发送该比特的副本，即<strong>泛洪转发</strong>。特别是，如果某集线器同时从两个不同的接口接收到帧，将出现一次碰撞，生成该帧的节点必须重新传输该帧。</p>
<p>简单来说就是集线器某个端口收到数据就会向其他所有端口转发（广播），因此连接到集线器的所有电脑都处于同一冲突域，共享一个广播域。 <img src="https://img-blog.csdnimg.cn/20200514231202295.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dvbmdfZmF5ZQ==,size_16,color_FFFFFF,t_70"></p>
<p>因此<strong>交换机</strong>诞生并取代了集线器，交换机不属于物理层设备，而是链路层设备。交换机具有<strong>转发</strong>和<strong>过滤</strong>的功能，前者是决定一个帧应该转发到某个接口还是应当将其丢弃，后者是决定一个帧应该被导向哪个接口。它们都借助交换机表来完成。并且交换机还具有<strong>自学习</strong>的功能，即自动维护交换机表。此外，交换机具有以下特性：</p>
<ul>
<li>消除碰撞。没有碰撞，交换机缓存帧决不会在网段上同时传输多于一个帧，交换机的最大聚合带宽是该交换机所有接口速率之和。</li>
<li>异质的链路。交换机将链路彼此隔离，因此局域网中的不同链路能够以不同的速率运行并且能够在不同的媒体上运行。</li>
<li>管理。交换机可以易于网络管理。如果一个适配器工作异常并持续发送以太网帧，交换机能够检测到该问题，并在内部断开异常适配器。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210213.png"></li>
</ul>
<h4 id="VLAN"><a href="#VLAN" class="headerlink" title="VLAN"></a>VLAN</h4><p>现代机构的局域网常常是配置为等级结构的，每个部门有自己的交换局域网，经过一个交换机等级结构与其他部门的交换局域网互联。这种结构存在以下问题：</p>
<ul>
<li><strong>缺乏流量隔离</strong>。局域网中存在广播流量，即影响性能也影响安全&#x2F;隐私。</li>
<li><strong>交换机的无效使用</strong>。如果一个部门只有9个人，整个公司有10个这样的部门，那么一台交换机的端口是完全可以满足的。但是出于每个部门一个局域网的考虑，还需要给每个部门单独配置一台交换机，浪费了资源。</li>
<li><strong>管理用户</strong>。如果某一员工在不同部门移动，则需要改变物理布线，而同属两个部门的员工则更加麻烦。</li>
</ul>
<p>因此我们需要通过支持<strong>虚拟局域网</strong>（Virtula Local Network, <strong>VLAN</strong>）的交换机来处理。支持VLAN的交换机允许经一个单一的物理局域网基础设施定义多个虚拟局域网。在一个VLAN内的主机彼此通信，仿佛它们（并且没有其他主机）与交换机连接。在一个基于端口的VLAN中，交换机的端口（接口）由网络管理员划分为组。每个组构成一个VLAN，在每个VLAN中的端口形成一个广播域（即来自一个端口的广播流量仅能到达该组中的其他端口），不同的VLAN帧之间互相隔离。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210221.png"></p>
<p>但完全隔离VLAN会导致一个问题，即一个VLAN的流量怎么才能发送到另外一个VLAN中？解决这个问题的一种方式是将VLAN交换机的一个端口与一台外部的路由器相连，并且将该端口配置为属于这两个VLAN共享。</p>
<p>假如两个部门的员工随机分布在两栋建筑物里办公，他们希望他们都能连上他们自己部门的VLAN，那该如何实现？一种更具扩展性互联VLAN交换机的方法称为<strong>VLAN干线连接</strong>，每台交换机上的一个特殊接口被配置为干线端口，以互联这两台VLAN交换机。该干线端口属于所有VLAN，发送到任何VLAN的帧经过干线链路转发到其他交换机。并且通过802.1Q以太网帧里的VLAN标签，来让交换机知道到达干线端口的帧属于某个特点的VLAN。 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210228.png"></p>
<h2 id="第七章-无线网络和移动网络"><a href="#第七章-无线网络和移动网络" class="headerlink" title="第七章 无线网络和移动网络"></a>第七章 无线网络和移动网络</h2><blockquote>
<p>注意与以太网帧对应的是802.11帧 <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210235.png"></p>
</blockquote>
<h3 id="7-3-WIFI-802-11-无线LAN"><a href="#7-3-WIFI-802-11-无线LAN" class="headerlink" title="7.3 WIFI:802.11 无线LAN"></a>7.3 WIFI:802.11 无线LAN</h3><h4 id="IEEE-802-11-CSMA-x2F-CA"><a href="#IEEE-802-11-CSMA-x2F-CA" class="headerlink" title="IEEE 802.11 CSMA&#x2F;CA"></a>IEEE 802.11 CSMA&#x2F;CA</h4><p>不同于<strong>以太网的CSMA&#x2F;CD</strong>（带碰撞检测CSMA），802.11无线LAN选择的是<strong>CSMA&#x2F;CA</strong>（带碰撞避免的CSMA）协议。这是因为无线网络难以检测碰撞，并且碰撞相较于以太网也更难处理，因此更倾向于避免碰撞。</p>
<p>无线网络难以检测碰撞的原因：</p>
<ul>
<li>在无线网中，信号360度发送，无法检测所有方向的碰撞。</li>
<li>存在隐藏终端的问题。如图H1、H2、AP两个无线站点和一个接入点，两个无线站点都在AP的覆盖范围内。但由于衰减，无线节点的信号范围有限，对于H1和H2来说，尽管他们对AP都不隐藏，但是双方确实隐藏的。此时假设站点H1正在传输一个帧，并且在H1传输的中途，站点H2要向AP发送一个帧。由于H2未听到来自H1的传输，它将首先等待一个DIFS间隔，然后发送该帧，导致产生了一个碰撞。从而在H1和H2的整个发送阶段，信道都被浪费了。</li>
</ul>
<p><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210244.png"></p>
<p>CSMA&#x2F;CA的机制如下：</p>
<blockquote>
<p>除一开始，会在每个帧传输之间等待短帧间间隔（SIFS）的一小段时间。</p>
</blockquote>
<p>① 检测信道：发送数据前，检测信道是否空闲；<br>② 信道空闲：如果空闲，将在分布式帧间间隔（DIFS）的短时间段后，发出短请求控制帧RTS ( Request To Send )，RTS 包括发射端地址，接收端地址，发送持续时间等信息；<br>③ 信道忙：等待；<br>④ 接收端收到 RTS：广播短允许发送控制帧CTS ( Clear To Send ) 响应 ，该CTS给发送端明确的发送许可，并且告知其他站点在预约期内不要发送。<br>⑤ 发送端收到 CTS，开始发送数据帧；<br>⑥ 接收方接收到数据后，使用 CRC 循环冗余校验码校验数据是否正确，如果数据正确，返回 ACK 确认帧 ;<br>⑦ 发送方接收到 ACK 确认帧后 , 才进行下一帧的发送 , 如果没有收到 , 则一直重传 , 直到16次失败为止 ; ( 二进制指数后退算法 ) <img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/PicGo/20230501210255.png"></p>
<p>RTS和CTS帧的使用能够在两个重要方面提高性能：<br>①隐藏终端问题被缓解了，因为长DATA帧只有在信道预约后才被传输。<br>②因为RTS和CTS帧较短，涉及RTS和CTS帧的碰撞将仅持续短RTS和CTS帧的持续期。一旦RTS和CTS帧被正确传输，后续的DATA和ACK帧应当能无碰撞地发送。</p>
<p>尽管RTS&#x2F;CTS交换有助于降低碰撞，但它同样<strong>引入了时延以及消耗了信道资源</strong>。因此，RTS&#x2F;CTS交换仅仅用于为长数据帧预约信道。在实际中，每个无线站点可以设置一个RTS门限值，仅当帧长超过门限值时，才使用RTS&#x2F;CTS序列。对许多无线站点而言，默认的RTS门限值大于最大帧长值，因此对所有发送的DATA帧，RTS&#x2F;CTS序列都被跳过。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://yeyuhl.github.io">夜语</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://yeyuhl.github.io/2023/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/">https://yeyuhl.github.io/2023/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://yeyuhl.github.io" target="_blank">随便写写</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/1a14e4eeedd428147c921881097b3aed8a932201.jpg%40942w_942h_progressive.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/05/02/Java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="Java数据结构"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Java数据结构</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/01/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AF%BC%E8%AE%BA%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/" title="操作系统导论期末复习"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">操作系统导论期末复习</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://yeyu-1313730906.cos.ap-guangzhou.myqcloud.com/%E7%89%B9%E5%AE%9A%E6%96%87%E4%BB%B6/1a14e4eeedd428147c921881097b3aed8a932201.jpg%40942w_942h_progressive.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">夜语</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">4</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/yeyuhl"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">随便写写的博客</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0"><span class="toc-text">计算机网络期末复习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%92%8C%E5%9B%A0%E7%89%B9%E7%BD%91"><span class="toc-text">第一章 计算机网络和因特网</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%A0%E7%89%B9%E7%BD%91"><span class="toc-text">1.1 什么是因特网</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E7%BD%91%E7%BB%9C%E8%BE%B9%E7%BC%98"><span class="toc-text">1.2 网络边缘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E7%BD%91%E7%BB%9C%E6%A0%B8%E5%BF%83%EF%BC%88%E4%B8%89%E7%A7%8D%E6%95%B0%E6%8D%AE%E4%BA%A4%E6%8D%A2%EF%BC%89"><span class="toc-text">1.3 网络核心（三种数据交换）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-%E5%88%86%E7%BB%84%E4%BA%A4%E6%8D%A2%E7%BD%91%E4%B8%AD%E7%9A%84%E6%97%B6%E5%BB%B6%E6%A6%82%E8%BF%B0"><span class="toc-text">1.4 分组交换网中的时延概述</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%881%EF%BC%89%E5%A4%84%E7%90%86%E6%97%B6%E5%BB%B6"><span class="toc-text">（1）处理时延</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E6%8E%92%E9%98%9F%E6%97%B6%E5%BB%B6"><span class="toc-text">（2）排队时延</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%883%EF%BC%89%E4%BC%A0%E8%BE%93%E6%97%B6%E5%BB%B6"><span class="toc-text">（3）传输时延</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%884%EF%BC%89%E4%BC%A0%E6%92%AD%E6%97%B6%E5%BB%B6"><span class="toc-text">（4）传播时延</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%885%EF%BC%89%E4%BC%A0%E8%BE%93%E6%97%B6%E5%BB%B6%E5%92%8C%E4%BC%A0%E6%92%AD%E6%97%B6%E5%BB%B6%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-text">（5）传输时延和传播时延的比较</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%886%EF%BC%89%E8%8A%82%E7%82%B9%E7%9A%84%E6%80%BB%E6%97%B6%E5%BB%B6"><span class="toc-text">（6）节点的总时延</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-%E5%8D%8F%E8%AE%AE%E5%88%86%E5%B1%82"><span class="toc-text">1.5 协议分层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E5%BA%94%E7%94%A8%E5%B1%82"><span class="toc-text">第二章 应用层</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-HTTP"><span class="toc-text">2.2 HTTP</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%881%EF%BC%89HTTP%E6%A6%82%E5%86%B5"><span class="toc-text">（1）HTTP概况</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%882%EF%BC%89%E9%9D%9E%E6%8C%81%E7%BB%AD%E8%BF%9E%E6%8E%A5%E5%92%8C%E6%8C%81%E7%BB%AD%E8%BF%9E%E6%8E%A5"><span class="toc-text">（2）非持续连接和持续连接</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%883%EF%BC%89HTTP%E8%AF%B7%E6%B1%82%E6%8A%A5%E6%96%87"><span class="toc-text">（3）HTTP请求报文</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%884%EF%BC%89HTTP%E5%93%8D%E5%BA%94%E6%8A%A5%E6%96%87"><span class="toc-text">（4）HTTP响应报文</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%885%EF%BC%89cookie"><span class="toc-text">（5）cookie</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%886%EF%BC%89Web%E7%BC%93%E5%AD%98"><span class="toc-text">（6）Web缓存</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%EF%BC%887%EF%BC%89%E6%9D%A1%E4%BB%B6GET"><span class="toc-text">（7）条件GET</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6"><span class="toc-text">2.3 电子邮件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-DNS"><span class="toc-text">2.4 DNS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-P2P%E6%96%87%E4%BB%B6%E5%88%86%E5%8F%91"><span class="toc-text">2.5 P2P文件分发</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0-%E4%BC%A0%E8%BE%93%E5%B1%82"><span class="toc-text">第三章 传输层</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E6%A6%82%E8%BF%B0%E8%BF%90%E8%BE%93%E5%B1%82"><span class="toc-text">3.1 概述运输层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-UDP"><span class="toc-text">3.3 UDP</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#UDP%E6%A6%82%E8%BF%B0"><span class="toc-text">UDP概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#UDP%E6%A3%80%E9%AA%8C%E5%92%8C"><span class="toc-text">UDP检验和</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86"><span class="toc-text">3.4 可靠数据传输原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%8F%E5%AE%8C%E5%85%A8%E5%8F%AF%E9%9D%A0%E4%BF%A1%E9%81%93%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%EF%BC%9Ardt1-0"><span class="toc-text">经完全可靠信道的可靠数据传输：rdt1.0</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%8F%E5%85%B7%E6%9C%89%E6%AF%94%E7%89%B9%E5%B7%AE%E9%94%99%E4%BF%A1%E9%81%93%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%EF%BC%9Ardt2-0"><span class="toc-text">经具有比特差错信道的可靠数据传输：rdt2.0</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#rdt2-0"><span class="toc-text">rdt2.0</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#rdt2-1"><span class="toc-text">rdt2.1</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#rdt2-2"><span class="toc-text">rdt2.2</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%8F%E5%85%B7%E6%9C%89%E6%AF%94%E7%89%B9%E5%B7%AE%E9%94%99%E7%9A%84%E4%B8%A2%E5%8C%85%E4%BF%A1%E9%81%93%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%EF%BC%9Ardt3-0"><span class="toc-text">经具有比特差错的丢包信道的可靠数据传输：rdt3.0</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE"><span class="toc-text">流水线可靠数据传输协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GBN"><span class="toc-text">GBN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SR"><span class="toc-text">SR</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-TCP"><span class="toc-text">3.5 TCP</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#TCP-%E8%BF%9E%E6%8E%A5"><span class="toc-text">TCP 连接</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TCP-%E6%8A%A5%E6%96%87%E7%BB%93%E6%9E%84"><span class="toc-text">TCP 报文结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BE%80%E8%BF%94%E6%97%B6%E9%97%B4%E7%9A%84%E4%BC%B0%E8%AE%A1%E4%B8%8E%E8%B6%85%E6%97%B6"><span class="toc-text">往返时间的估计与超时</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6"><span class="toc-text">流量控制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TCP%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86"><span class="toc-text">TCP连接管理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B"><span class="toc-text">三次握手</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B"><span class="toc-text">四次挥手</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E5%8E%9F%E7%90%86"><span class="toc-text">拥塞控制原理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8B%A5%E5%A1%9E%E5%8E%9F%E5%9B%A0%E4%B8%8E%E4%BB%A3%E4%BB%B7"><span class="toc-text">拥塞原因与代价</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E6%96%B9%E6%B3%95"><span class="toc-text">拥塞控制方法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6"><span class="toc-text">TCP拥塞控制</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E7%BD%91%E7%BB%9C%E5%B1%82%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%B9%B3%E9%9D%A2"><span class="toc-text">第四章 网络层：数据平面</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E6%A6%82%E8%BF%B0%E7%BD%91%E7%BB%9C%E5%B1%82"><span class="toc-text">4.1 概述网络层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E8%B7%AF%E7%94%B1%E5%99%A8%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-text">4.2 路由器工作原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%9B%AE%E7%9A%84%E5%9C%B0%E8%BD%AC%E5%8F%91"><span class="toc-text">基于目的地转发</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-IPv4"><span class="toc-text">4.3 IPv4</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#IPv4%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%88%86%E7%89%87"><span class="toc-text">IPv4数据报分片</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E7%BC%96%E5%9D%80"><span class="toc-text">分类编址</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%A0%E5%88%86%E7%B1%BB%E7%BC%96%E5%9D%80CIDR"><span class="toc-text">无分类编址CIDR</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-IPv6"><span class="toc-text">4.4 IPv6</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%BD%91%E7%BB%9C%E5%B1%82%EF%BC%9A%E6%8E%A7%E5%88%B6%E5%B9%B3%E9%9D%A2"><span class="toc-text">第五章 网络层：控制平面</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E6%8E%A7%E5%88%B6%E5%B9%B3%E9%9D%A2%E6%A6%82%E8%BF%B0"><span class="toc-text">5.1 控制平面概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95"><span class="toc-text">5.2 路由选择算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%93%BE%E8%B7%AF%E7%8A%B6%E6%80%81%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95"><span class="toc-text">链路状态路由选择算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B7%9D%E7%A6%BB%E5%90%91%E9%87%8F%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95"><span class="toc-text">距离向量路由选择算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LS%E4%B8%8EDV%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-text">LS与DV路由选择算法的比较</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E5%9B%A0%E7%89%B9%E7%BD%91%E4%B8%AD%E8%87%AA%E6%B2%BB%E7%B3%BB%E7%BB%9F%E5%86%85%E9%83%A8%E7%9A%84%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%EF%BC%9AOSPF"><span class="toc-text">5.3 因特网中自治系统内部的路由选择：OSPF</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-ISP%E4%B9%8B%E9%97%B4%E7%9A%84%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%EF%BC%9ABGP"><span class="toc-text">5.4 ISP之间的路由选择：BGP</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#BGP%E4%BD%9C%E7%94%A8"><span class="toc-text">BGP作用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E5%91%8ABGP%E8%B7%AF%E7%94%B1%E4%BF%A1%E6%81%AF"><span class="toc-text">通告BGP路由信息</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0-%E9%93%BE%E8%B7%AF%E5%B1%82"><span class="toc-text">第六章 链路层</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E9%93%BE%E8%B7%AF%E5%B1%82%E6%A6%82%E8%BF%B0"><span class="toc-text">6.1 链路层概述</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%93%BE%E8%B7%AF%E5%B1%82%E6%8F%90%E4%BE%9B%E7%9A%84%E6%9C%8D%E5%8A%A1"><span class="toc-text">链路层提供的服务</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%93%BE%E8%B7%AF%E5%B1%82%E5%9C%A8%E4%BD%95%E5%A4%84%E5%AE%9E%E7%8E%B0"><span class="toc-text">链路层在何处实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-%E5%A4%9A%E8%B7%AF%E8%AE%BF%E9%97%AE%E9%93%BE%E8%B7%AF%E5%92%8C%E5%8D%8F%E8%AE%AE"><span class="toc-text">6.3 多路访问链路和协议</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E9%81%93%E5%88%92%E5%88%86%E5%8D%8F%E8%AE%AE"><span class="toc-text">信道划分协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%8E%A5%E5%85%A5%E5%8D%8F%E8%AE%AE"><span class="toc-text">随机接入协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%AE%E6%B5%81%E5%8D%8F%E8%AE%AE"><span class="toc-text">轮流协议</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-4-%E4%BA%A4%E6%8D%A2%E5%B1%80%E5%9F%9F%E7%BD%91"><span class="toc-text">6.4 交换局域网</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%B0%E5%9D%80%E8%A7%A3%E6%9E%90%E5%8D%8F%E8%AE%AE-ARP"><span class="toc-text">地址解析协议(ARP)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A5%E5%A4%AA%E7%BD%91%E5%92%8C%E9%93%BE%E8%B7%AF%E5%B1%82%E4%BA%A4%E6%8D%A2%E6%9C%BA"><span class="toc-text">以太网和链路层交换机</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#VLAN"><span class="toc-text">VLAN</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%83%E7%AB%A0-%E6%97%A0%E7%BA%BF%E7%BD%91%E7%BB%9C%E5%92%8C%E7%A7%BB%E5%8A%A8%E7%BD%91%E7%BB%9C"><span class="toc-text">第七章 无线网络和移动网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-WIFI-802-11-%E6%97%A0%E7%BA%BFLAN"><span class="toc-text">7.3 WIFI:802.11 无线LAN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#IEEE-802-11-CSMA-x2F-CA"><span class="toc-text">IEEE 802.11 CSMA&#x2F;CA</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/12/Java%E5%9F%BA%E7%A1%80%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" title="Java基础常见问题">Java基础常见问题</a><time datetime="2023-05-12T07:40:22.000Z" title="发表于 2023-05-12 15:40:22">2023-05-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/02/Java%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="Java数据结构">Java数据结构</a><time datetime="2023-05-02T10:14:48.000Z" title="发表于 2023-05-02 18:14:48">2023-05-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/" title="计算机网络期末复习">计算机网络期末复习</a><time datetime="2023-05-01T13:04:51.000Z" title="发表于 2023-05-01 21:04:51">2023-05-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/05/01/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AF%BC%E8%AE%BA%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/" title="操作系统导论期末复习">操作系统导论期末复习</a><time datetime="2023-05-01T11:23:47.000Z" title="发表于 2023-05-01 19:23:47">2023-05-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 夜语</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>